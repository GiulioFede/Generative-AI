{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Vl2iyPidU0Xd",
        "x9gUhQLwVFI0",
        "hlA1ddleVKi1",
        "6fV1kpO2w29t"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6gWV5mb0UzHr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.datasets import load_digits\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "import math\n",
        "from torchvision import transforms\n",
        "from torch.linalg import multi_dot\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init\n",
        "\n"
      ],
      "metadata": {
        "id": "Vl2iyPidU0Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Controlla la disponibilità della GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Imposta il dispositivo sulla GPU\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Se la GPU non è disponibile, utilizza la CPU\n",
        "\n"
      ],
      "metadata": {
        "id": "of0uWRh0VBOO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUmfBgZZaHJR",
        "outputId": "45c7294d-9a1b-4f04-ad09-c14483797e61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ink originale: https://drive.google.com/file/d/0B7EVK8r0v71pZjFTYXZWM3FlRnM/view?usp=drive_link&resourcekey=0-dYn9z10tMJOBAkviAcfdyQ\n",
        "#spostatelo nel vostro drive e copiatelo in locale (perchè il dataloader carica più velocemente le immagini leggendo da qui che dal vostro drive)\n",
        "!cp '/content/drive/MyDrive/Generative_AI/datasets/celebA/img_align_celeba.zip' celebA.zip"
      ],
      "metadata": {
        "id": "6h5nQ953YpPL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"celebA.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')"
      ],
      "metadata": {
        "id": "jqEVBayxZTVg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Priors"
      ],
      "metadata": {
        "id": "x9gUhQLwVFI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#-------------------------------------- Mixture of Gaussians (MoG)\n",
        "class MoG(nn.Module):\n",
        "  def __init__(self, latent_dimension, num_components=1,):\n",
        "    super(MoG, self).__init__()\n",
        "\n",
        "    self.num_components = num_components\n",
        "    self.latent_dimension = latent_dimension\n",
        "\n",
        "    #inizializzo dei tensori \"da imparare\" che sono le medie delle K componenti\n",
        "    # di dimensione (Num_components, latent_dimension)\n",
        "    self.means = nn.Parameter(torch.randn((num_components, latent_dimension),dtype=torch.float32))\n",
        "\n",
        "    #inizializzo K matrici di covarianza diagonali di ognuna delle K componenti\n",
        "    #li tratto come log_var cosi che se anche fossero negativi, una volta fatto l'exp e quindi convertiti in var diventano positivi\n",
        "    self.log_vars = nn.Parameter(torch.randn((num_components,latent_dimension),dtype=torch.float32))\n",
        "\n",
        "    #inizializzo i pesi di ogni gaussiana e li normalizzo affinchè la somma faccia 1\n",
        "    self.weights = nn.Parameter(torch.ones(num_components)/num_components )\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "\n",
        "    #campiono una camponente in base ai pesi\n",
        "    component_index =  torch.multinomial(F.softmax(self.weights, dim=0), 1)\n",
        "\n",
        "    #scelgo la media e la matrice di covarianza della componente scelta\n",
        "    mean = self.means[component_index]\n",
        "    log_var = self.log_vars[component_index]\n",
        "\n",
        "    #creo la matrice di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrix = torch.diag_embed(torch.exp(log_var))\n",
        "\n",
        "    #creo la multivariance\n",
        "    m = MultivariateNormal(mean,cov_matrix)\n",
        "\n",
        "    #campiono lo z\n",
        "    z_sample = m.sample().to(device)\n",
        "\n",
        "    return z_sample.to(torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "  def log_prob(self,z_samples):\n",
        "\n",
        "    #creo le matrici di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrices = torch.diag_embed(torch.exp(self.log_vars))\n",
        "\n",
        "    #creo K gaussiane mixate\n",
        "    MoG = MultivariateNormal(self.means.to(torch.float32),cov_matrices.to(torch.float32))\n",
        "\n",
        "    #reshape da (L, N, latent) in (N, latent)\n",
        "    z_reshaped = z_samples.view(-1, self.latent_dimension)\n",
        "\n",
        "    #Calcolo per ogni z le k log_prob (N, k)\n",
        "    k_log_probs_for_z = MoG.log_prob(z_reshaped.unsqueeze(1).to(torch.float32))\n",
        "\n",
        "    #Reshape originale (L, N, k)\n",
        "    k_log_probs_for_z_reshaped = k_log_probs_for_z.view(z_samples.shape[0],z_samples.shape[1], self.num_components).to(torch.float32)\n",
        "\n",
        "    #normalizzo i pesi affinchè la loro somma faccia 1\n",
        "    probabilities_weights = F.softmax(self.weights, dim=0)\n",
        "\n",
        "    #per ciascuno moltiplico le k probabilità per i rispettivi pesi\n",
        "    weigthed_log_probs = k_log_probs_for_z_reshaped * probabilities_weights\n",
        "\n",
        "    #sommo tutte le log_probs pesate di ogni z (L, N)\n",
        "    sum_weigthed_log_probs = weigthed_log_probs.sum(-1)\n",
        "\n",
        "    return sum_weigthed_log_probs.to(torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#---------------------VampPrior: Variational Mixture of Posterior Prior\n",
        "class VampPrior(nn.Module):\n",
        "  def __init__(self, input_shape, latent_dimension, possible_pixel_values,encode= None, num_components=1):\n",
        "    super(VampPrior, self).__init__()\n",
        "\n",
        "    #sarebbe la dimensione D*D dell'ingresso originale a cui le immagini appartengono\n",
        "    self.input_shape = input_shape\n",
        "    self.num_components = num_components\n",
        "    self.latent_dimension = latent_dimension\n",
        "    self.encode = encode\n",
        "\n",
        "    #inizializzo gli pseudo-input\n",
        "    #creo N pseudo input u (N, sqrt(input_shape), sqrt(input_shape))\n",
        "    u = torch.rand((num_components, int(math.sqrt(input_shape)), int(math.sqrt(input_shape))))*possible_pixel_values\n",
        "    #li rendo learnable\n",
        "    self.u = nn.Parameter(u)\n",
        "\n",
        "    #inizializzo i pesi di ogni gaussiana e li normalizzo affinchè la somma faccia 1\n",
        "    self.weights = nn.Parameter(torch.ones(num_components)/num_components )\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "\n",
        "    #campiono una camponente in base ai pesi\n",
        "    component_index =  torch.multinomial(F.softmax(self.weights, dim=0), 1)\n",
        "\n",
        "    #do all'encoder gli pseudo-input ottenendo le medie e le log_std\n",
        "    mean_vectors, log_std_vectors = self.encode(self.u)\n",
        "\n",
        "    #scelgo la media e la matrice di covarianza della componente scelta\n",
        "    mean_vector = mean_vectors[component_index]\n",
        "    log_std_vector = log_std_vectors[component_index]\n",
        "\n",
        "    #creo la matrice di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrix = torch.diag_embed(torch.exp(log_std_vector))\n",
        "\n",
        "    #creo la multivariance\n",
        "    m = MultivariateNormal(mean_vector, cov_matrix)\n",
        "\n",
        "    #campiono lo z\n",
        "    z_sample = m.sample().to(device)\n",
        "\n",
        "    return z_sample\n",
        "\n",
        "\n",
        "\n",
        "  def log_prob(self,z_samples):\n",
        "\n",
        "    #do all'encoder gli pseudo-input ottenendo le medie e le log_std\n",
        "\n",
        "    mean_vectors, log_std_vectors = self.encode(self.u)\n",
        "\n",
        "    #creo le matrici di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrices = torch.diag_embed(torch.exp(log_std_vectors))\n",
        "\n",
        "    #creo K gaussiane mixate\n",
        "    MoG = MultivariateNormal(mean_vectors,cov_matrices)\n",
        "\n",
        "    #reshape da (L, N, latent) in (N, latent)\n",
        "    z_reshaped = z_samples.view(-1, self.latent_dimension)\n",
        "\n",
        "    #Calcolo per ogni z le k log_prob (N, k)\n",
        "    k_log_probs_for_z = MoG.log_prob(z_reshaped.unsqueeze(1))\n",
        "\n",
        "    #Reshape originale (L, N, k)\n",
        "    k_log_probs_for_z_reshaped = k_log_probs_for_z.view(z_samples.shape[0],z_samples.shape[1], self.num_components)\n",
        "\n",
        "    #normalizzo i pesi affinchè la loro somma faccia 1\n",
        "    probabilities_weights = F.softmax(self.weights, dim=0)\n",
        "\n",
        "    #per ciascuno moltiplico le k probabilità per i rispettivi pesi\n",
        "    weigthed_log_probs = k_log_probs_for_z_reshaped * probabilities_weights\n",
        "\n",
        "    #sommo tutte le log_probs pesate di ogni z (L, N)\n",
        "    sum_weigthed_log_probs = weigthed_log_probs.sum(-1)\n",
        "\n",
        "    return sum_weigthed_log_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#----------------------- GTM-VampPrior:  Generative Topographic Mapping and Variational Mixture of Posterior Prior\n",
        "class GTM_VampPrior(nn.Module):\n",
        "  def __init__(self, input_shape, latent_dimension, possible_pixel_values,encode= None, num_components=1, u_dim=10):\n",
        "    super(GTM_VampPrior, self).__init__()\n",
        "\n",
        "    #sarebbe la dimensione D*D dell'ingresso originale a cui le immagini appartengono\n",
        "    self.input_shape = input_shape\n",
        "    self.num_components = num_components\n",
        "    self.latent_dimension = latent_dimension\n",
        "    self.encode = encode\n",
        "\n",
        "    #creo la rete che implementerà la funzione g che opera sui pseudo inputs\n",
        "    self.g_net = nn.Sequential(nn.Linear(u_dim*u_dim,number_of_hidden_neurons*2),\n",
        "                                 nn.BatchNorm1d(number_of_hidden_neurons*2),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 nn.Linear(number_of_hidden_neurons*2,number_of_hidden_neurons),\n",
        "                                 nn.BatchNorm1d(number_of_hidden_neurons),\n",
        "                                 nn.Tanh(),\n",
        "                                 #moltiplico per 2 perchè voglio sia il vettore di media che std (diagonale)\n",
        "                                 nn.Linear(number_of_hidden_neurons,input_shape),\n",
        "                                 nn.Sigmoid()\n",
        "                                 )\n",
        "\n",
        "    #inizializzo gli pseudo-input\n",
        "    #creo N pseudo input u (N, 10,10)\n",
        "    u = torch.rand((num_components, u_dim,u_dim))\n",
        "    #li rendo learnable\n",
        "    self.u = nn.Parameter(u)\n",
        "\n",
        "    #inizializzo i pesi di ogni gaussiana e li normalizzo affinchè la somma faccia 1\n",
        "    self.weights = nn.Parameter(torch.ones(num_components)/num_components )\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "\n",
        "    #campiono una camponente in base ai pesi\n",
        "    component_index =  torch.multinomial(F.softmax(self.weights, dim=0), 1)\n",
        "\n",
        "    #do all'encoder gli pseudo-input ottenendo le medie e le log_std\n",
        "    #processo gli pseudo-input con una funzion g\n",
        "    x = torch.flatten(self.u,1)\n",
        "    pseudo_input_after_g = self.g_net(x)\n",
        "\n",
        "    mean_vectors, log_std_vectors = self.encode(pseudo_input_after_g*possible_pixel_values)\n",
        "\n",
        "\n",
        "    #scelgo la media e la matrice di covarianza della componente scelta\n",
        "    mean_vector = mean_vectors[component_index]\n",
        "    log_std_vector = log_std_vectors[component_index]\n",
        "\n",
        "    #creo la matrice di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrix = torch.diag_embed(torch.exp(log_std_vector))\n",
        "\n",
        "    #creo la multivariance\n",
        "    m = MultivariateNormal(mean_vector,cov_matrix)\n",
        "\n",
        "    #campiono lo z\n",
        "    z_sample = m.sample().to(device)\n",
        "\n",
        "    return z_sample\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def log_prob(self,z_samples):\n",
        "\n",
        "    #do all'encoder gli pseudo-input ottenendo le medie e le log_std\n",
        "    #processo gli pseudo-input con una funzion g\n",
        "    x = torch.flatten(self.u,1)\n",
        "    pseudo_input_after_g = self.g_net(x)\n",
        "\n",
        "    mean_vectors, log_std_vectors = self.encode(pseudo_input_after_g*possible_pixel_values)\n",
        "\n",
        "    #creo le matrici di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrices = torch.diag_embed(torch.exp(log_std_vectors))\n",
        "\n",
        "    #creo K gaussiane mixate\n",
        "    MoG = MultivariateNormal(mean_vectors,cov_matrices)\n",
        "\n",
        "    #reshape da (L, N, latent) in (N, latent)\n",
        "    z_reshaped = z_samples.view(-1, self.latent_dimension)\n",
        "\n",
        "    #Calcolo per ogni z le k log_prob (N, k)\n",
        "    k_log_probs_for_z = MoG.log_prob(z_reshaped.unsqueeze(1))\n",
        "\n",
        "    #Reshape originale (L, N, k)\n",
        "    k_log_probs_for_z_reshaped = k_log_probs_for_z.view(z_samples.shape[0],z_samples.shape[1], self.num_components)\n",
        "\n",
        "    #normalizzo i pesi affinchè la loro somma faccia 1\n",
        "    probabilities_weights = F.softmax(self.weights, dim=0)\n",
        "\n",
        "    #per ciascuno moltiplico le k probabilità per i rispettivi pesi\n",
        "    weigthed_log_probs = k_log_probs_for_z_reshaped * probabilities_weights\n",
        "\n",
        "    #sommo tutte le log_probs pesate di ogni z (L, N)\n",
        "    sum_weigthed_log_probs = weigthed_log_probs.sum(-1)\n",
        "\n",
        "    return sum_weigthed_log_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#--------------------Flow-based prior\n",
        "class Flow_Based_prior(nn.Module):\n",
        "  def __init__(self, latent_dimension):\n",
        "    super(Flow_Based_prior, self).__init__()\n",
        "\n",
        "    #divideremo l'input Z a metà, quindi prenderemo metà delle componenti\n",
        "    self.input_dimension = latent_dimension //2\n",
        "\n",
        "    self.number_of_neurons = 128\n",
        "    self.number_of_flows = 8\n",
        "\n",
        "    self.scale_net = nn.Sequential(nn.Linear(self.input_dimension,self.number_of_neurons),\n",
        "                                   nn.ELU(),\n",
        "                                   nn.Linear(self.number_of_neurons,self.number_of_neurons*2),\n",
        "                                   nn.ELU(),\n",
        "                                   nn.Linear(self.number_of_neurons*2,self.number_of_neurons*2),\n",
        "                                   nn.Tanh(),\n",
        "                                   nn.Linear(self.number_of_neurons*2,self.input_dimension),\n",
        "                                   nn.Tanh()\n",
        "                                   )\n",
        "    #neo creo 8\n",
        "    self.scale_nets = torch.nn.ModuleList([self.scale_net for _ in range(self.number_of_flows)])\n",
        "\n",
        "    self.translation_net = nn.Sequential(nn.Linear(self.input_dimension,self.number_of_neurons),\n",
        "                                nn.LeakyReLU(),\n",
        "                                nn.Linear(self.number_of_neurons,self.number_of_neurons*2),\n",
        "                                nn.ELU(),\n",
        "                                nn.Linear(self.number_of_neurons*2,self.number_of_neurons*2),\n",
        "                                nn.Tanh(),\n",
        "                                nn.Linear(self.number_of_neurons*2,self.input_dimension),\n",
        "                                )\n",
        "\n",
        "    #neo creo 8\n",
        "    self.translation_nets = torch.nn.ModuleList([self.translation_net for _ in range(self.number_of_flows)])\n",
        "\n",
        "    #la distribuzione iniziale da cui partire, ossia N(0,I)\n",
        "    self.p0 = MultivariateNormal(torch.zeros(latent_dimension).to(device), torch.eye(latent_dimension).to(device))\n",
        "\n",
        "\n",
        "  def coupling_layer(self, z, index, forward=True):\n",
        "\n",
        "    #divido l'input in due parti\n",
        "    (za,zb) = torch.chunk(z,2,1)\n",
        "\n",
        "    #inizializzo i due output del coupling layer\n",
        "    ya = 0,\n",
        "    yb = 0\n",
        "\n",
        "    #print(\" calcolo s e t con ingresso di dimensione \", za.shape)\n",
        "    s = self.scale_nets[index](za)\n",
        "    t = self.translation_nets[index](za)\n",
        "\n",
        "    ya= za\n",
        "\n",
        "    if forward == False:\n",
        "      yb = torch.exp(s)*zb + t\n",
        "    else:\n",
        "      yb = (zb-t)*torch.exp(-s)\n",
        "\n",
        "    return torch.cat((ya,yb), 1), s\n",
        "\n",
        "  def permute(self, z):\n",
        "    return z.flip(1)\n",
        "\n",
        "  def log_prob(self,z):\n",
        "    '''\n",
        "      Io voglio calcolare il log(p(z)) e so che questo è calcolabile come:\n",
        "        log(p(z)) = ln(p0(z0=f^-1(x)) ) - sum(ln(det(J_fi(z_i-1))))\n",
        "    '''\n",
        "    #in ingresso ho (L, N, latent), lo converto in (L*N, latent)\n",
        "    L = z.shape[0]\n",
        "    N = z.shape[1]\n",
        "    z = z.view((L*N,z.shape[2]))\n",
        "    #se ho N z allora ho N log_det_J da memorizzare, uno per ogni z\n",
        "    log_det_J = z.new_zeros(z.shape[0])\n",
        "\n",
        "    output = z\n",
        "    #vado da p(x) a p0\n",
        "    for flow_i in range(self.number_of_flows):\n",
        "      output, s = self.coupling_layer(output, flow_i, forward=True)\n",
        "      output = self.permute(output)\n",
        "      log_det_J = log_det_J + s.sum(dim=1)\n",
        "\n",
        "    #adesso ho ottenuto che output=z0=f^-1(x) e ho la somma dei logaritmi dei determinanti\n",
        "    ln_p_z = self.p0.log_prob(output) - log_det_J\n",
        "\n",
        "    #ritorno nel formato previsto (L, N)\n",
        "    return ln_p_z.view((L,N))\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "\n",
        "    #campiono dalla prior\n",
        "    z0 = self.p0.sample()\n",
        "\n",
        "    z = z0.unsqueeze(0)\n",
        "\n",
        "    #procedo da p0 a p(x)\n",
        "    for flow_i in reversed(range(self.number_of_flows)):\n",
        "      z = self.permute(z)\n",
        "      z,_ = self.coupling_layer(z, flow_i, forward=False)\n",
        "\n",
        "    #ritorno un campione di p(x)\n",
        "    return z\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O_ZHlI9mVHIc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sylvester-Householder flow"
      ],
      "metadata": {
        "id": "TPZZME0nZZmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SylvesterFlow(nn.Module):\n",
        "  def __init__(self, latent_space_dimension, number_of_flows):\n",
        "    super(SylvesterFlow,self).__init__()\n",
        "\n",
        "    self.number_of_flows = number_of_flows\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "\n",
        "    #questa rete neurale calcola K vettori b (flattati, poi si fa il reshape)\n",
        "    self.b_net = nn.Linear(2*latent_space_dimension, latent_space_dimension*number_of_flows)\n",
        "\n",
        "    #questa rete neurale calcola K vettori diagonali per le matrici R1 (flattati, poi si fa il reshape)\n",
        "    self.r1_diag_net = nn.Sequential(\n",
        "                                      nn.Linear(2*latent_space_dimension, latent_space_dimension*number_of_flows),\n",
        "                                      nn.Tanh()\n",
        "                                    )\n",
        "\n",
        "    #questa rete neurale calcola K vettori diagonali per le matrici R2 (flattati, poi si fa il reshape)\n",
        "    self.r2_diag_net = nn.Sequential(\n",
        "                                      nn.Linear(2*latent_space_dimension, latent_space_dimension*number_of_flows),\n",
        "                                      nn.Tanh()\n",
        "                                    )\n",
        "\n",
        "    #questa rete neurale calcola K matrici che faranno da base per poi ottenere R1 e R2 (flattati, poi si fa il reshape)\n",
        "    self.mat_net = nn.Linear(2*latent_space_dimension, latent_space_dimension*latent_space_dimension*number_of_flows)\n",
        "\n",
        "    #mi creo una lista degli indici delle diagonali di R1 e R2\n",
        "    self.diag_indexes = torch.arange(latent_space_dimension)\n",
        "\n",
        "    #creo il modulo per effettuare l'Householder Flow\n",
        "    self.householderTransformation = HouseholderFlow(latent_space_dimension, number_of_flows)\n",
        "\n",
        "  '''\n",
        "    In ingresso ho i vari z0 campionati (L, N, latent_space) e i rispettivi\n",
        "    vettori v0 (N, latent_space) e p=[u,log_std] (N, 2*latent_space)\n",
        "  '''\n",
        "  def forward(self, z0, v0, p ):\n",
        "    #print(\"Z shape\", z0.shape)\n",
        "    #print(\" V0 shape\", v0.shape)\n",
        "    #print(\" p shape\", p.shape)\n",
        "\n",
        "  #1) Calcolo K vettori b\n",
        "    #(N, latent_space*number_of_flows)\n",
        "    b = self.b_net(p)\n",
        "    #print(\"b-net: \", b.shape)\n",
        "    #reshape in (N, k, latent_space)\n",
        "    b = b.reshape(b.shape[0],self.number_of_flows, self.latent_space_dimension)\n",
        "    #print(\"b-net reshape: \", b.shape)\n",
        "\n",
        "  #2) Calcolo K vettori per le diagonali delle K matrici R1\n",
        "    #(N, latent_space*number_of_flows)\n",
        "    diag_R1 = self.r1_diag_net(p)\n",
        "    #print(\"diag_R1-net: \", diag_R1.shape)\n",
        "    #reshape in (N, k, latent_space)\n",
        "    diag_R1 = diag_R1.reshape(diag_R1.shape[0],self.number_of_flows, self.latent_space_dimension)\n",
        "    #print(\"diag_R1-net reshape: \", diag_R1)\n",
        "\n",
        "  #3) Calcolo K vettori per le diagonali delle K matrici R2\n",
        "    #(N, latent_space*number_of_flows)\n",
        "    diag_R2 = self.r2_diag_net(p)\n",
        "    #print(\"diag_R2-net: \", diag_R2.shape)\n",
        "    #reshape in (N, k, latent_space)\n",
        "    diag_R2 = diag_R2.reshape(diag_R2.shape[0],self.number_of_flows, self.latent_space_dimension)\n",
        "    #print(\"diag_R2-net reshape: \",diag_R2,\"  \", diag_R2.shape)\n",
        "\n",
        "  #4) Calcolo K matrici che faranno da base per poi costruire R1 e R2\n",
        "    #(N, latent_space**latent_space*number_of_flows)\n",
        "    mat = self.mat_net(p)\n",
        "    #print(\"Mat-net: \", mat.shape)\n",
        "    #reshape in (N, k, latent_space, latent_space)\n",
        "    mat = mat.reshape(mat.shape[0],self.number_of_flows, self.latent_space_dimension, self.latent_space_dimension)\n",
        "    #print(\"Mat-net reshape: \",mat,\"  \", mat.shape)\n",
        "\n",
        "    #4.1) crezione di R2 a partire da mat\n",
        "    #prendo la matrice ottenuta e ne estraggo solo la parte triangolare superiore (lasciando zero altrove)\n",
        "    R2 = torch.triu(mat)\n",
        "    #print(\"R2 triangolare\",R2, \"  \", R2.shape)\n",
        "    #sostituisco alle K matrici triangolari ottenute le loro diagonali con quelle ottenute nel punto 3)\n",
        "    R2[...,self.diag_indexes,self.diag_indexes] = diag_R2\n",
        "    #print(\"R2 triangolare con diagonale cambiata\",R2, \"  \", R2.shape)\n",
        "\n",
        "    #4.2) crezione di R1 a partire da mat\n",
        "    #effettuo trasposta\n",
        "    mat = torch.transpose(mat,2,3)\n",
        "    #prendo la matrice ottenuta e ne estraggo solo la parte triangolare superiore (lasciando zero altrove)\n",
        "    R1 = torch.triu(mat)\n",
        "    #print(\"R1 triangolare\",R1, \"  \", R1.shape)\n",
        "    #sostituisco alle K matrici triangolari ottenute le loro diagonali con quelle ottenute nel punto 2)\n",
        "    R1[...,self.diag_indexes,self.diag_indexes] = diag_R1\n",
        "    #print(\"R1 triangolare con diagonale cambiata\",R1, \"  \", R1.shape)\n",
        "\n",
        "    #adesso che ho tutti i K elementi, effettuo un ciclo di Householder in cui mi calcolo ad ogni iterazione\n",
        "    #la Q i-esima e sfrutto gli i-esimi parametri trovati prima per calcolare la i-esima trasformazione di\n",
        "    #di z0 e nel contempo anche la sommatoria dei logaritmi dei determinanti\n",
        "\n",
        "    zk, sum_log_det = self.householderTransformation(z0,v0,b,R1,R2)\n",
        "\n",
        "    return zk, sum_log_det\n",
        "\n",
        "\n",
        "class HouseholderFlow(nn.Module):\n",
        "  def __init__(self, latent_space_dimension, number_of_flows):\n",
        "    super(HouseholderFlow,self).__init__()\n",
        "\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "    self.number_of_flows = number_of_flows\n",
        "\n",
        "    #creo number_of_flows dense layer, ciascuno elaborerà un suo Householder vector\n",
        "    self.linears = nn.ModuleList([nn.Linear(latent_space_dimension, latent_space_dimension) for i in range(number_of_flows)])\n",
        "\n",
        "    #la funzione h\n",
        "    self.h = nn.Tanh()\n",
        "\n",
        "  #la funzione h' (sarebbe la derivata di Tanh())\n",
        "  def d_h(self, x):\n",
        "    return 1 - self.h(x) ** 2\n",
        "\n",
        "    '''\n",
        "      Ricordo che dato un vi (Householder vector) la relativa matrice di Householder\n",
        "      Hi si trova come:\n",
        "                          H_i = I - 2* vi^T v / v v^T\n",
        "      per noi H_i=Q_i in quanto soddisfa l'ortogonalità.\n",
        "      Ad ogni flow i calcoleremo la trasformazione di z_(i-1) come:\n",
        "                  z_i = z_(i-1) + Q_i*R1_i*h(R2_i*Q_i^T*z_(i-1) + b)\n",
        "      e il determinante della trasformazione come:\n",
        "          det_i = prod_j=1-L(diag(h'(R2_i*Q_i^T*z_(i-1) + b))_jj*R2_i_jj*R1_i_jj+1))\n",
        "    '''\n",
        "\n",
        "  #in ingresso prende gli z0 samples e il primo Householder vector v0\n",
        "  def forward(self, z, v,b,R1,R2):\n",
        "\n",
        "    # print(\"Z0\", z, \"  \", z.shape)\n",
        "    # print(\" V0\", v,\"  \",v.shape)\n",
        "    # print(\" b \",b, \"  \", b.shape)\n",
        "    # print(\" R1 \",R1, \"  \", R1.shape)\n",
        "    # print(\" R2 \",R2, \"  \", R2.shape)\n",
        "\n",
        "    #creo la matrice identità (una volta, tanto è la stessa per ogni flow)\n",
        "    I = torch.eye(self.latent_space_dimension).to(device)\n",
        "\n",
        "    #salvo la somma dei log det delle trasformate in ogni flow\n",
        "    sum_log_det = 0\n",
        "\n",
        "    for k in np.arange(self.number_of_flows):\n",
        "      #print(\"Householder flow \",k,\"__________________________________________________\")\n",
        "      #calcolo per ogni z la matrice di Householder Hi usando v_(i-1)\n",
        "      #per ogni householder vector vi calcolo calcolo ||vi||^2\n",
        "      norms = torch.norm(v, dim=-1, keepdim=True)\n",
        "      dot_product = torch.pow(norms,2)\n",
        "\n",
        "      #per ogni householder vector vi calcolo l'outer product con se stesso\n",
        "      outer_product = torch.matmul(v.unsqueeze(2), v.unsqueeze(1))\n",
        "\n",
        "      #adesso posso calcolare vi^T vi / ||vi||^2\n",
        "      normalized_outer_product = outer_product / dot_product[:,None]\n",
        "\n",
        "      #per ogni householder vector vi calcolo la relativa matrice di Householder Hi\n",
        "      # (N, latent_space, latent_space)\n",
        "      Q = I-2*normalized_outer_product\n",
        "      #print(\"Q \",Q, \"  \",Q.shape)\n",
        "\n",
        "      '''\n",
        "                              Calcolo h(R2*Q*z+b)\n",
        "      '''\n",
        "      #calcolo R2*Q (selezionando per ogni x solo la R2 del k-esimo flow)\n",
        "      RQ = torch.bmm(R2[:,k,:],torch.transpose(Q,1,2))\n",
        "      #calcolo R2*Q*z+b (selezionando per ogni x solo la b del k-esimo flow)\n",
        "      RQz_plus_b = torch.matmul(RQ.unsqueeze(0),torch.transpose(z.unsqueeze(2),2,3)).squeeze(-1)+b[:,k,:]\n",
        "      #adesso applico la funzione h() ad ogni elemento del vettore ottenuto\n",
        "      h_RQz_plus_b = self.h(RQz_plus_b)\n",
        "      #print(\"h(RQz + b)\",h_RQz_plus_b, \"  \", h_RQz_plus_b.unsqueeze(3).shape)\n",
        "\n",
        "      '''\n",
        "                        Calcolo zk = z(k-1) + Q*R*h(R2*Q*z(k-1) + b)\n",
        "      '''\n",
        "      #calcolo Q*R (selezionando per ogni x solo la R1 del k-esimo flow)\n",
        "      QR = torch.bmm(Q,R1[:,k,:])\n",
        "      QR_per_h = torch.matmul(QR,h_RQz_plus_b.unsqueeze(3) ).squeeze(3)\n",
        "      #print(\"QR*h\",QR_per_h, \"  \",QR_per_h.shape)\n",
        "      #trovo la trasformazione zk\n",
        "      z = torch.add(z,QR_per_h)\n",
        "      #print(\"z + QR*h(...)\", z,\"  \",z.shape)\n",
        "\n",
        "      '''\n",
        "                  Calcolo log(|det(dF/dz)|) del flusso corrente e lo\n",
        "                            sommo a quello precedente\n",
        "      '''\n",
        "      #mi calcolo h'(RQz+b)\n",
        "      d_h_RQz_plus_b =self.d_h(RQz_plus_b)\n",
        "\n",
        "      '''\n",
        "      #per prova______________________________________________________\n",
        "      #trasformo h'(RQz+b) in diagonale\n",
        "      diag_d_h_RQz_plus_b = torch.diag_embed(d_h_RQz_plus_b)\n",
        "      print(\"diag h' \",diag_d_h_RQz_plus_b, \"   \",diag_d_h_RQz_plus_b.shape)\n",
        "      R2R1 = torch.bmm(R2[:,k,:],R1[:,k,:])\n",
        "      print(\"R2R1\",R2R1, \"  \", R2R1.shape)\n",
        "      diag_d_h_per_R2R1 = torch.matmul(diag_d_h_RQz_plus_b.unsqueeze(0), R2R1 ).squeeze(0)\n",
        "      print(\"diag(h'())*R2R1\",diag_d_h_per_R2R1, \"   \", diag_d_h_per_R2R1.shape)\n",
        "      I= torch.eye(self.latent_space_dimension, dtype=torch.float32)\n",
        "      I_plus_d_h_per_R2R1 = diag_d_h_per_R2R1 + I.unsqueeze(0).unsqueeze(0).unsqueeze(0)\n",
        "      print(\"I_plus_d_h_per_R2R1\",I_plus_d_h_per_R2R1,\"  \",I_plus_d_h_per_R2R1.shape)\n",
        "      print(\"det vero\", torch.det(I_plus_d_h_per_R2R1))\n",
        "      #fine prova___________________________________________________\n",
        "      '''\n",
        "\n",
        "      #ho già le diagonali di diag(h')\n",
        "      #estraggo le diagonali di R2 e poi di R1\n",
        "      R2_diag = R2[:,k,:][:,torch.arange(self.latent_space_dimension),torch.arange(self.latent_space_dimension)]\n",
        "      R1_diag = R1[:,k,:][:,torch.arange(self.latent_space_dimension),torch.arange(self.latent_space_dimension)]\n",
        "      # print(\"h'() \",d_h_RQz_plus_b, \"  \",d_h_RQz_plus_b.shape)\n",
        "      # print(\"R1_diag() \",R1_diag, \"  \",R1_diag.shape)\n",
        "      # print(\"R2_diag() \",R2_diag, \"   \", R2_diag.shape)\n",
        "      #moltiplico ogni elemento i di R2 per quello i di R1\n",
        "      R2_i_per_R1_i = R2_diag*R1_diag\n",
        "      #print(\"R2*R1\",R2_i_per_R1_i, \"  \",R2_i_per_R1_i.shape)\n",
        "      #moltiplico h'()_i*R2_i*R1_i\n",
        "      d_h_i_per_R2_i_per_R1_i = d_h_RQz_plus_b*R2_i_per_R1_i\n",
        "      #print(\"h'()_i*R2_i*R1_i\",d_h_i_per_R2_i_per_R1_i, \"  \",d_h_i_per_R2_i_per_R1_i.shape)\n",
        "      #aggiungo a tutti + 1\n",
        "      d_h_i_per_R2_i_per_R1_i_plus_1 = d_h_i_per_R2_i_per_R1_i + 1\n",
        "      #print(\"h'()_i*R2_i*R1_i + 1\",d_h_i_per_R2_i_per_R1_i_plus_1, \"  \",d_h_i_per_R2_i_per_R1_i_plus_1.shape)\n",
        "      #calcolo il determinante come prodotto di tutti gli elementi in ciascun vettore\n",
        "      det_trasformata_i = torch.prod(d_h_i_per_R2_i_per_R1_i_plus_1,dim=-1)\n",
        "      # print(\"determinanti calcolati \",det_trasformata_i)\n",
        "      # print(\"log abs determinanti calcolati \",torch.log(torch.abs(det_trasformata_i)))\n",
        "      sum_log_det = sum_log_det + torch.log(torch.abs(det_trasformata_i))\n",
        "      #print(\"Sum \", sum_log_det)\n",
        "\n",
        "\n",
        "      #calcolo nuovo vettore di Householder\n",
        "      v = self.linears[k](v)\n",
        "\n",
        "    #ritorno gli z trasformati e la somma dei log det\n",
        "    return z, sum_log_det\n",
        "\n"
      ],
      "metadata": {
        "id": "ez7kILXmZbaa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "hlA1ddleVKi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#--------------- Encoder\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_shape_image, latent_space_dimension, number_of_hidden_neurons, L, number_of_flows):\n",
        "    super(Encoder,self).__init__()\n",
        "\n",
        "    #numero di campioni per l'approssimazione Monte-Carlo dell'Expected Value\n",
        "    self.L = L\n",
        "\n",
        "    self.input_shape_image = input_shape_image\n",
        "\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "\n",
        "    out_channels = 14\n",
        "    kernel_size = 4\n",
        "\n",
        "    '''\n",
        "        NEW scompongo l'encoder in 3 parti cosi da poter utilizzare l'output di un layer\n",
        "        specifico senza fare girare due volte l'encoder\n",
        "    '''\n",
        "    self.encoder_0 = nn.Sequential(\n",
        "                   nn.Conv2d(1,out_channels,kernel_size, stride=2),\n",
        "                   nn.BatchNorm2d(out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "\n",
        "                   nn.Conv2d(out_channels,2*out_channels,kernel_size, stride=2),\n",
        "                   nn.BatchNorm2d(2*out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "\n",
        "                   nn.Conv2d(2*out_channels,2*out_channels,kernel_size,stride=2),\n",
        "                   nn.BatchNorm2d(2*out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "\n",
        "                   nn.Conv2d(2*out_channels,3*out_channels,kernel_size, stride=2),\n",
        "                   nn.BatchNorm2d(3*out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "\n",
        "                   nn.Flatten()\n",
        "                   )\n",
        "\n",
        "    #QUESTO è il nuovo layer che useremo per estrarre il primo Householder vector v cosi\n",
        "    #da renderlo in funzione dell'input x\n",
        "    self.encoder_1 = nn.LazyLinear(latent_space_dimension)\n",
        "\n",
        "    self.encoder_2 = nn.Linear(latent_space_dimension, 2*latent_space_dimension)\n",
        "\n",
        "    self.prior = None\n",
        "\n",
        "    self.sylvesterFlow = SylvesterFlow(latent_space_dimension, number_of_flows)\n",
        "\n",
        "\n",
        "  def set_prior(self,prior):\n",
        "    #associo la prior scelta\n",
        "    self.prior = prior\n",
        "\n",
        "  def encode(self,x):\n",
        "    #trasformo il batch da (64, 28, 28) in (64,1,28,28)\n",
        "    x = x.unsqueeze(1)\n",
        "    #do alla rete x e prelevo vettore di media e std (diagonale)\n",
        "    output_0 = self.encoder_0(x.to(torch.float32))\n",
        "    output_1 = self.encoder_1(output_0)\n",
        "    output = self.encoder_2(output_1)\n",
        "\n",
        "    #divido il risultato in due parti: media e std (diagonale)(logaritmica)\n",
        "    mean_vector, log_std_vector = torch.chunk(output, 2, dim=1)\n",
        "\n",
        "    return mean_vector, log_std_vector\n",
        "\n",
        "\n",
        "  def KL_loss(self,log_std_vector,mean_vector,v0, batch_length):\n",
        "\n",
        "    L = self.L\n",
        "\n",
        "    #trasformo i logaritmi delle std in std\n",
        "    std_vector = torch.exp(log_std_vector)\n",
        "\n",
        "    #siccome devo avere una matrice positiva definita (cholesky decomposition) devo\n",
        "    #assicurarmi che i valori nelle diagonali non siano proprio zero\n",
        "    EPS = 1.e-5\n",
        "    std_vector = torch.clamp(std_vector, EPS,1. - EPS)\n",
        "\n",
        "    #trasformo le sequenze di varianze in matrici diagonali (covarianza)\n",
        "    covariance_matrixes = torch.diag_embed(std_vector)\n",
        "\n",
        "    #calcolo N distribuzioni  multivariate q(z|x) creata da ognuno degli N x\n",
        "    #QUESTA E' LA DISTRIBUZIONE q(z0|x) DI PARTENZA\n",
        "    q_z_x = MultivariateNormal(mean_vector, covariance_matrixes)\n",
        "\n",
        "\n",
        "    '''\n",
        "      per ciascuna distribuzione campiono L vettori z0\n",
        "      Nota però che anche se campiono L vettori da ciascuna, il risultato\n",
        "      conterrà i primi N vettori z0 campionati, poi i secondi N e cosi via fino\n",
        "      agli L-esimi. Per esempio i primi due z0_1 e z0_2 sono stati campionati da due\n",
        "      distribuzioni diverse! Quindi non ho blocchi da L vettori z0 appartenenti\n",
        "      alla stessa distribuzione!\n",
        "    '''\n",
        "    #dimensione (L, num_distribuzioni, dim_latente)\n",
        "    z_samples = q_z_x.rsample((L,)) #r sta per \"reparametrization trick\"\n",
        "\n",
        "\n",
        "    '''\n",
        "        Devo trasformare gli z0 campionati in zk tramite il flusso di Sylvester\n",
        "        e calcolare per ciascuno anche la somma dei log det\n",
        "    '''\n",
        "\n",
        "    #passo z0, v0 e anche p=[mean, log_std]\n",
        "    #ottengo zk_ samples (L,N,latent) e sum_log_det (L,N)\n",
        "    zk_samples, sum_log_det = self.sylvesterFlow(z_samples, v0, torch.cat((mean_vector,log_std_vector),1))\n",
        "\n",
        "\n",
        "    '''\n",
        "      Per gli z0 (campionati dalla distribuzione di base) calcolo ln(q(z0|x))\n",
        "    '''\n",
        "    z_log_probs = q_z_x.log_prob(z_samples)\n",
        "\n",
        "    '''\n",
        "      mentre per gli zk calcolo ln(p(zk))\n",
        "    '''\n",
        "\n",
        "    ln_p_z = self.prior.log_prob(zk_samples)\n",
        "\n",
        "    '''\n",
        "      Ora per ogni immagine x io ho campionato L vettori z0, li ho trasformati in zk e per ciascuno ho\n",
        "      valutato sia ln(q(z0|x)) che ln(p(zk)). Per ogni immagine io volevo calcolare\n",
        "      l'expected value approssimandolo (Monte Carlo) come:\n",
        "\n",
        "                        KL = [Sum(ln(q(z0|x)))/L - Sum(ln(p(zk))/L)\n",
        "\n",
        "      Per ottenere la prima sommatoria, sommo le colonne di z_log_probs, mentre\n",
        "      per la seconda sommo le colonne della matrice ln_p_z. Dopodichè, ottenuti\n",
        "      due vettori, li divido per L e li sottraggo tra cosi da ottenere l'approssimazione\n",
        "      della KL per ogni immagine x in ingresso\n",
        "    '''\n",
        "\n",
        "    KL_per_image = z_log_probs.sum(0)/L - ln_p_z.sum(0)/L\n",
        "\n",
        "    #NB: adesso devo ritornare gli z_k in quanto il decoder calcolerò RE con gli zk e la sum log det\n",
        "    return KL_per_image, zk_samples, sum_log_det\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "    z_sample = self.prior.sample()\n",
        "    return z_sample\n",
        "\n",
        "\n",
        "  #La rete ritorna il vettore di media, std (diagonale) e la z campionata\n",
        "  def forward(self, x):\n",
        "\n",
        "    #trasformo il batch da (64, 28, 28) in (64,1,28,28)\n",
        "    x = x.unsqueeze(1)\n",
        "\n",
        "    #do alla rete x e prelevo vettore di media e std (diagonale)\n",
        "    output_0 = self.encoder_0(x.to(torch.float32))\n",
        "    #v0 è il primo Householder vector (N, latent)\n",
        "    v0 = self.encoder_1(output_0)\n",
        "    output = self.encoder_2(v0)\n",
        "\n",
        "    #divido il risultato in tre parti: media e std (diagonale)(logaritmica)\n",
        "    mean_vector, log_std_vector = torch.chunk(output, 2, dim=1)\n",
        "\n",
        "    '''\n",
        "      Ottengo un KL_error (N,) contenente per ogni immagine il relativo KL_error,\n",
        "      e poi una matrice zk_samples (L, N, dim_latente) trasformati per Householder\n",
        "    '''\n",
        "    KL_per_image, zk_samples, sum_log_det = self.KL_loss(log_std_vector,mean_vector,v0, x.shape[0])\n",
        "\n",
        "\n",
        "    return KL_per_image, zk_samples, sum_log_det\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-------- Decoder\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_shape_image,latent_space_dimension, number_of_hidden_neurons, possible_pixel_values, L):\n",
        "    super(Decoder,self).__init__()\n",
        "\n",
        "    self.L = L\n",
        "\n",
        "    self.input_shape_image = input_shape_image\n",
        "\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "\n",
        "    self.possible_pixel_values = possible_pixel_values\n",
        "\n",
        "    kernel_size = 3\n",
        "    out_channels = 14\n",
        "\n",
        "    self.decoder = nn.Sequential(nn.Linear(latent_space_dimension,4096),\n",
        "                          nn.Unflatten(2, (int(math.sqrt(4096)),int(math.sqrt(4096)))),\n",
        "                          nn.Upsample(size=[8,8], mode='bilinear', align_corners=False),\n",
        "                          nn.Conv2d(in_channels=1, out_channels=3*out_channels, kernel_size=kernel_size),\n",
        "                          nn.BatchNorm2d(3*out_channels),\n",
        "                          nn.LeakyReLU(),\n",
        "\n",
        "                          nn.Upsample(size=[16,16], mode='bilinear', align_corners=False),\n",
        "                          nn.Conv2d(in_channels=3*out_channels, out_channels=2*out_channels, kernel_size=kernel_size),\n",
        "                          nn.BatchNorm2d(2*out_channels),\n",
        "                          nn.LeakyReLU(),\n",
        "\n",
        "                          nn.Upsample(size=[16,16], mode='bilinear', align_corners=False),\n",
        "                          nn.Conv2d(in_channels=2*out_channels, out_channels=out_channels, kernel_size=kernel_size),\n",
        "                          nn.BatchNorm2d(out_channels),\n",
        "                          nn.LeakyReLU(),\n",
        "\n",
        "                          nn.Flatten(),\n",
        "                          nn.LazyLinear(input_shape_image*possible_pixel_values),\n",
        "                          nn.Unflatten(1,(input_shape_image,possible_pixel_values))\n",
        "\n",
        "                          )\n",
        "\n",
        "  def decode_sample(self,z_sample):\n",
        "\n",
        "    #inietto nel decoder:\n",
        "    z_sample = z_sample.reshape(1,1,z_sample.shape[1])\n",
        "\n",
        "    logits = self.decoder(z_sample.to(torch.float32))\n",
        "\n",
        "    #(1,W*H,possible_pixel_values)\n",
        "    logits = logits.reshape(1, self.input_shape_image, self.possible_pixel_values )\n",
        "\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    #non applico la softmax per convertirli in probabilità perchè\n",
        "    probabilities = probabilities.view(-1, self.possible_pixel_values)\n",
        "\n",
        "    sample = torch.multinomial(probabilities, num_samples=1)\n",
        "\n",
        "    x = sample.view(self.input_shape_image)\n",
        "    return x\n",
        "\n",
        "\n",
        "  def forward(self, z, x):\n",
        "    #z è una matrice (L, N, dim_latente), la inietto nel decoder per ottenere le logits\n",
        "    z=z.reshape(self.L*z.shape[1], 1,z.shape[2])\n",
        "\n",
        "    logits = self.decoder(z.to(torch.float32))\n",
        "\n",
        "    logits = logits.reshape(self.L, int(logits.shape[0]//self.L), logits.shape[1]*logits.shape[2])\n",
        "\n",
        "    '''\n",
        "      Prima di convertire le logits in probabilità, ciascun vettore del tensore\n",
        "      contiene i logits di TUTTI i pixel [px1-v=v1,...,px1-v=vk, px2-v=1,....], quindi\n",
        "      devo prima fare un reshape del genere [[px1-v=v1,...,px1-v=vk], [...]] isolando\n",
        "      solo le probabilità di ogni pixel\n",
        "\n",
        "    '''\n",
        "    #(L, N, numero_pixel, possibili_valori)\n",
        "    logits = logits.reshape((logits.shape[0],logits.shape[1],self.input_shape_image,self.possible_pixel_values))\n",
        "    #applico la softmax per convertire le logits in probabilità\n",
        "    probabilities = torch.softmax(logits,3)\n",
        "\n",
        "    #correggo (per questioni di stabilità) le probabilità troppo basse\n",
        "    #Devono stare tra 0+EPS < p < 1-EPS\n",
        "    EPS = 1.e-5\n",
        "    probabilities = torch.clamp(probabilities, EPS,1. - EPS)\n",
        "\n",
        "    '''\n",
        "      Per ogni z iniettato ho ottenuto delle probabilità. Siccome voglio valutare\n",
        "      l'expected value seguente:\n",
        "                              E[ln(p(x|z))]\n",
        "      e sicome lo voglio approssimare con gli L ln(p(x|z)) ottenuti, ossia:\n",
        "                              E[ln(p(x|z))] = 1/L*Sum(ln(p(x|z)))\n",
        "      allora tutti i calcoli seguenti servono solo a poter ottenere per ciascuna\n",
        "      immagine x tutti i ln(p(x|z)), in particolare:\n",
        "      1) Per ogni z ho una matrice di dimensione(numero_pixel, probabilità_valori)\n",
        "         e quindi estraggo la probabilità che ha quella particolare componente xi\n",
        "         in ingresso.\n",
        "      2) Alla fine per ogni coppia x e z ho un vettore di probabilità per xi, quindi\n",
        "         quella di x è calcolabile come:\n",
        "                              p(x|z)=p(x1|z)*p(x2|z)*...*p(xk|z)\n",
        "         Se però calcolo il logaritmo, che è quello che voglio posso sommarli:\n",
        "                              ln(p(x|z))=ln(p(x1|z))+ln(p(x2|z))+...+ln(p(xk|z))\n",
        "      3) Avendone L li sommo e li divido per L\n",
        "\n",
        "    '''\n",
        "\n",
        "    #converto ogni pixel in un vettore one_hot\n",
        "    x_one_hot = F.one_hot(x.long(), num_classes = self.possible_pixel_values)\n",
        "    x_one_hot = x_one_hot.reshape(x_one_hot.shape[0],x_one_hot.shape[1]*x_one_hot.shape[2]*x_one_hot.shape[3])\n",
        "    probabilities = probabilities.reshape(probabilities.shape[0],probabilities.shape[1],probabilities.shape[2]*probabilities.shape[3])\n",
        "    #li converto in logaritmi\n",
        "    log_probabilities = torch.log(probabilities)\n",
        "\n",
        "    selected_log_probabilities = x_one_hot * log_probabilities\n",
        "    #adesso in un unico vettore ho tutti le ln(p(x_i|z)) per lo z.\n",
        "    #li sommo (L,N), ossia ogni vettore contiene gli ln(p(x|z)) per gli N x\n",
        "    ln_p_x_z = selected_log_probabilities.sum(2)\n",
        "\n",
        "\n",
        "    #ogni colonna contiene quindi gli ln(p(x|z)) per lo stesso x.\n",
        "    #li sommo e li divido per L ottenenedo il reconstruction error per ogni x\n",
        "    RE_per_image = ln_p_x_z.sum(0) / self.L\n",
        "\n",
        "    return RE_per_image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#------------ Variational AutoEncoder\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, possible_pixel_values, input_shape_image, latent_space_dimension, number_of_hidden_neurons,L,number_of_flows, type_of_prior=0, mog_components=1):\n",
        "    super(VAE, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(input_shape_image,latent_space_dimension,number_of_hidden_neurons,L,number_of_flows)\n",
        "    self.decoder = Decoder(input_shape_image,latent_space_dimension,number_of_hidden_neurons,possible_pixel_values,L)\n",
        "\n",
        "    prior = None\n",
        "    if type_of_prior == 1:\n",
        "      #creo una mixture of gaussian a 15 componenti come prior p(z)\n",
        "      prior = MoG(latent_space_dimension, mog_components)\n",
        "    elif type_of_prior == 2:\n",
        "      prior = VampPrior(input_shape_image, latent_space_dimension, possible_pixel_values, self.encoder.encode, num_components= mog_components )\n",
        "    elif type_of_prior == 3:\n",
        "      prior = GTM_VampPrior(input_shape_image, latent_space_dimension, possible_pixel_values, self.encoder.encode, num_components= mog_components )\n",
        "    elif type_of_prior == 4:\n",
        "      prior = Flow_Based_prior(latent_space_dimension)\n",
        "    else:\n",
        "      #p(z)=N(0,I)\n",
        "      prior = MultivariateNormal(torch.zeros(self.latent_space_dimension), torch.eye(self.latent_space_dimension))\n",
        "\n",
        "    self.prior = prior\n",
        "    self.L = L\n",
        "\n",
        "  def initialize(self):\n",
        "    #aggiorno il riferimento della prior per l'encoder\n",
        "    self.encoder.set_prior(self.prior)\n",
        "\n",
        "  def sample(self):\n",
        "    z_sample = self.encoder.sample()\n",
        "    return self.decoder.decode_sample(z_sample)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    #inietto x nell'encoder per ottenere la KL loss, i vettori z campionati (Monte-Carlo) trasformati e la loro log sum det\n",
        "    KL_loss_per_image, z_samples_per_image, sum_log_det = self.encoder.forward(x)\n",
        "\n",
        "    #inietto nel decoder x per essere ricostruito attraverso gli stessi campioni z\n",
        "    #e per ottenere il reconstruction error\n",
        "    RE_loss_per_image = self.decoder.forward(z_samples_per_image,x)\n",
        "\n",
        "    '''\n",
        "        Alla classica KL-RE devo anche togliere E[sum(log(det(dF/dz)))]. Essendo\n",
        "        log_sum_det di dimensione (L,N) allora ogni colonna contiene la sum(log(det(dF/dz)))\n",
        "        dei campionamenti z relativi allo stesso x, quindi medio per colonna\n",
        "    '''\n",
        "    #sommo per ottenere una approssimazione del ln(p(x)) per ogni immagine\n",
        "    ln_p = KL_loss_per_image - RE_loss_per_image - sum_log_det.sum(0)/self.L\n",
        "\n",
        "    #calcolo la media del batch\n",
        "    ln_p_mean = ln_p.mean()\n",
        "\n",
        "    return ln_p_mean\n"
      ],
      "metadata": {
        "id": "1VgklM8sVJ7K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "VwoaF43RVQp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################### GPU + Path ##########################################\n",
        "\n",
        "# Controlla la disponibilità della GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Imposta il dispositivo sulla GPU\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Se la GPU non è disponibile, utilizza la CPU\n",
        "\n",
        "print(\"Device utilizzato:\", device)\n",
        "print(\"Numero di GPU disponibili:\", torch.cuda.device_count())\n",
        "\n",
        "\n",
        "#path dove salvare il modello migliore e i vari output di ogni epoca valida\n",
        "path_to_model = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/model/model_prior_mog_new_net1_Sy_HF.pth\"\n",
        "path_to_output = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/output/prior_mog_posterior_new_net_1_Sy_HF_\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################### Dataloader ##########################################\n",
        "\n",
        "#per motivi di efficienza, scegliere il rescaling e il massimo valore che ogni pixel può assumere\n",
        "resize_to = 64\n",
        "max_pixel_value = 20\n",
        "\n",
        "input_shape_image = resize_to*resize_to\n",
        "possible_pixel_values = max_pixel_value+1\n",
        "\n",
        "\n",
        "def load_data():\n",
        "\n",
        "\n",
        "    # Definisci le trasformazioni da applicare alle immagini durante il caricamento\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize( (resize_to, resize_to) ), #rescaling di ogni immagine\n",
        "        transforms.Grayscale(),  # Trasforma l'immagine in bianco e nero\n",
        "        transforms.ToTensor(),# Converte l'immagine in un tensore\n",
        "        transforms.Lambda(lambda x: torch.round(x*(max_pixel_value))), #normalizzo i valori dei pixel e li forzo ad essere interi\n",
        "        transforms.Lambda(lambda x: x.to(torch.float32))\n",
        "    ])\n",
        "\n",
        "    # Crea un oggetto ImageFolder per caricare le immagini dalla cartella specificata e applica le trasformazioni definite\n",
        "    dataset = datasets.ImageFolder('/content/dataset/', transform=transform)\n",
        "\n",
        "    # Calcola l'indice per dividere il dataset tra training set e validation set\n",
        "    split_ratio = 0.8  # Ratio di suddivisione (80% per il training set, 20% per il validation set)\n",
        "    dataset_size = len(dataset)\n",
        "    split_index = int(split_ratio * dataset_size)\n",
        "\n",
        "    # Crea due sottoinsiemi distinti per il training set e il validation set\n",
        "    train_dataset = Subset(dataset, range(0, split_index))\n",
        "    val_dataset = Subset(dataset, range(split_index, dataset_size))\n",
        "\n",
        "    # Crea i DataLoader per il training set e il validation set\n",
        "    batch_size = 32\n",
        "    training_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "    validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return training_loader, validation_loader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################### Training + validation #####################################\n",
        "\n",
        "def train_model_on_given_gpu():\n",
        "\n",
        "    #definisco la dimensione dello spazio latente\n",
        "    latent_space_dimension = 64 #deve essere pari se utilizzi il Flow-based\n",
        "    #nuumero di hidden neurons nell'encoder e decoder\n",
        "    number_of_hidden_neurons = 64 #la sua radice quadrata deve essere intera altrimenti ci sarà un errore\n",
        "    #numero componenti gaussiane per il MoG o VampPrior\n",
        "    mog_components = 20\n",
        "    #Monte-Carlo approximations\n",
        "    L = 2\n",
        "    #number of Householder flows\n",
        "    number_of_flows = 10\n",
        "\n",
        "    #---- creazione del modello\n",
        "    #decide il numero di campioni per l'approssimazione Monte-Carlo dell'expected value\n",
        "    print(\"Memoria GPU prima della creazione del modello:\", torch.cuda.memory_allocated())\n",
        "\n",
        "    model =  VAE( possible_pixel_values, input_shape_image, latent_space_dimension, number_of_hidden_neurons, L,number_of_flows,type_of_prior=1, mog_components=mog_components)\n",
        "    model.to(device)\n",
        "    model.initialize()\n",
        "    print(\"Memoria GPU dopo la creazione del modello:\", torch.cuda.memory_allocated())\n",
        "\n",
        "    # Esegui un passaggio di inoltro dummy per il LazyLinear\n",
        "    inputs = torch.round(torch.rand((5, resize_to, resize_to),dtype=torch.float32)*max_pixel_value).to(device)\n",
        "    dummy_output = model(inputs).item()\n",
        "\n",
        "    print(\"Numero parametri modello: \",sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    del inputs\n",
        "    del dummy_output\n",
        "    gc.collect()\n",
        "\n",
        "    model = torch.nn.parallel.DataParallel(model)\n",
        "\n",
        "    #parametri per il learning\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    parameters_to_optimize = [p for p in model.parameters() if p.requires_grad == True]\n",
        "\n",
        "    optimizer = torch.optim.Adamax(parameters_to_optimize, lr=learning_rate)\n",
        "\n",
        "\n",
        "    #------ Funzione per salvare una griglia di campioni decodificati dallo spazio latente ogni volta che la validation è migliore\n",
        "    def sample_and_save(model, name, input_shape):\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      #voglio campionare 16 immagini e le voglio in una griglia 4x4\n",
        "      n=4\n",
        "      number_of_grid_cells = n*n\n",
        "      #quindi dico al modello di campionarmi 16 immagini\n",
        "      xs = np.zeros((number_of_grid_cells,input_shape))\n",
        "      for i in np.arange(number_of_grid_cells):\n",
        "        generated_sample = model.module.sample().cpu() # il .module serve per andare oltre il wrapping di DataParallel\n",
        "        #lo stacco dal grafo di computazione\n",
        "        generated_sample = generated_sample.detach().numpy()\n",
        "        xs[i,:] = generated_sample\n",
        "\n",
        "\n",
        "      fig, ax = plt.subplots(n, n)\n",
        "      for i, ax in enumerate(ax.flatten()):\n",
        "          plottable_image = np.reshape(xs[i], (int(math.sqrt(input_shape)), int(math.sqrt(input_shape))))\n",
        "          ax.imshow(plottable_image, cmap='gray')\n",
        "          ax.axis('off')\n",
        "\n",
        "      plt.savefig(path_to_output+'epoca_' +str(name)+ '.pdf', bbox_inches='tight')\n",
        "      plt.close()\n",
        "\n",
        "\n",
        "\n",
        "    #---- Training e validation\n",
        "    number_of_epochs = 1000\n",
        "    #fisso il limite massimo di batch di training e validazione\n",
        "    max_batch_for_training = 800\n",
        "    max_batch_for_validation = 170\n",
        "\n",
        "\n",
        "    #qui salvo il migliore modello, ossia quello che ha la loss sulla validazione migliore\n",
        "    best_model = model\n",
        "    best_validation_loss = 1000000\n",
        "\n",
        "    patience = 0\n",
        "    max_patience = 30\n",
        "\n",
        "    training_loader, validation_loader = load_data()\n",
        "\n",
        "    grd_acc = 1 #significa che prima di backpropagare l'errore accumulerò il gradiente di batch_size*grd_acc (ees. 8*4=32 è come se processassi batch da 32)\n",
        "\n",
        "    for epoch in range(number_of_epochs):\n",
        "      model.train()\n",
        "      print(\"Epoca \"+str(epoch)+\" _____________________________________________________________________\")\n",
        "\n",
        "      num_batch = 1\n",
        "      for batch, _ in training_loader:\n",
        "\n",
        "        #reshaping di ogni batch da (N, 1, W, H) a (N, W, H)\n",
        "        batch = batch.squeeze(1)\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        #print(\"             Memoria GPU utilizzata prima loss per batch:\",num_batch,\"  -> \", round(torch.cuda.memory_allocated()*(1e-9),5),\" GB\")\n",
        "        #batch = batch.to(torch.float32)\n",
        "\n",
        "        loss = model.forward(batch)\n",
        "        #print(\"             Memoria GPU utilizzata dopo loss per batch:\",num_batch,\"  -> \", round(torch.cuda.memory_allocated()*(1e-9),5),\" GB\")\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        #calcolo le derivate parziali della loss rispetto ogni parametro NB: LA mean() E' PERCHE' UTILIZZO N GPU E CIASCUNA RITORNA LA SUA LOSS\n",
        "        (loss.mean()/grd_acc).backward(retain_graph=True)\n",
        "        torch.cuda.empty_cache()\n",
        "        #print(\"             Memoria GPU utilizzata dopo backward per batch:\",num_batch,\"  -> \", round(torch.cuda.memory_allocated()*(1e-9),5),\" GB\")\n",
        "        #se ho accumulato il gradiente di un numero sufficiente di batch, allora backpropago\n",
        "        if ( (num_batch % grd_acc) == 0):\n",
        "            #adesso ogni parametro ha in .grad il gradiente. Aggiorno il suo valore\n",
        "            optimizer.step()\n",
        "\n",
        "            #resetto il .grad di ogni parametro (altrimenti sommo quello attuale al successivo che calcoleremo nell'epoca dopo)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        print(\"   Loss batch: \",str(num_batch),\": \", loss, \"          Memoria GPU utilizzata  -> \", round(torch.cuda.memory_allocated()*(1e-9),4), \"GB\")\n",
        "\n",
        "            #se ho superato il numero massimo di batch per il training, esco\n",
        "        if num_batch >= max_batch_for_training:\n",
        "            break\n",
        "        else:\n",
        "            num_batch = num_batch + 1\n",
        "\n",
        "      #alla fine di ogni epoca, valuto come si comporta la loss col validation set\n",
        "      print(\"   ___________________________\")\n",
        "      model.eval()\n",
        "      validation_loss = 0\n",
        "      N = 0\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      num_batch = 1\n",
        "      for batch, _ in validation_loader:\n",
        "\n",
        "        batch = batch.squeeze(1)\n",
        "        batch = batch.to(device)\n",
        "        #batch = batch.to(torch.float32)\n",
        "        loss_i = model.forward(batch)\n",
        "        validation_loss = validation_loss + loss_i.mean().item()# NB: .mean() SOLO PERCH' UTILIZZO N GPU E QUINDI VOGLIO LA MEDIA DI OGNI LOSS RITORNATA DA OGNI GPU\n",
        "        N = N +  1\n",
        "\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(\"   Loss validation batch \",str(num_batch),\": \",loss_i)\n",
        "        #se ho superato il numero massimo di batch per il validation, esco\n",
        "        if num_batch >= max_batch_for_validation:\n",
        "            break\n",
        "        else:\n",
        "            num_batch = num_batch + 1\n",
        "\n",
        "        del loss_i\n",
        "\n",
        "      validation_loss = validation_loss/N\n",
        "      print(\"   Loss media validation: \",str(validation_loss))\n",
        "\n",
        "      #se tale modello ha una loss migliore di quella attualmente migliore..\n",
        "      if validation_loss < best_validation_loss:\n",
        "        patience = 0\n",
        "        best_validation_loss = validation_loss\n",
        "        print(\"   la loss risulta essere migliore\")\n",
        "        torch.save(model.state_dict(), path_to_model)\n",
        "        #campiono e salvo\n",
        "        sample_and_save(model, epoch, input_shape_image)\n",
        "      else:\n",
        "        print(\"   patience= \"+ str(patience+1))\n",
        "        patience = patience + 1\n",
        "\n",
        "      if patience > max_patience:\n",
        "        print(\"\")\n",
        "        print(\"Patience massimo superato. Fine del training\")\n",
        "        break\n",
        "\n",
        "      del validation_loss\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "\n",
        "    train_model_on_given_gpu()"
      ],
      "metadata": {
        "id": "uBa71JKDVSPN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
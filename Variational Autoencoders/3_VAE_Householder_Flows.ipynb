{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "kkUBSP_FkoJK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6gWV5mb0UzHr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.datasets import load_digits\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "import math\n",
        "from torchvision import transforms\n",
        "from torch.linalg import multi_dot\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init\n",
        "\n"
      ],
      "metadata": {
        "id": "Vl2iyPidU0Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Controlla la disponibilità della GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Imposta il dispositivo sulla GPU\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Se la GPU non è disponibile, utilizza la CPU\n",
        "\n"
      ],
      "metadata": {
        "id": "of0uWRh0VBOO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUmfBgZZaHJR",
        "outputId": "bc61da7d-813c-4292-f19d-7c597c4096be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ink originale: https://drive.google.com/file/d/0B7EVK8r0v71pZjFTYXZWM3FlRnM/view?usp=drive_link&resourcekey=0-dYn9z10tMJOBAkviAcfdyQ\n",
        "#spostatelo nel vostro drive e copiatelo in locale (perchè il dataloader carica più velocemente le immagini leggendo da qui che dal vostro drive)\n",
        "!cp '/content/drive/MyDrive/Generative_AI/datasets/celebA/img_align_celeba.zip' celebA.zip"
      ],
      "metadata": {
        "id": "6h5nQ953YpPL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"celebA.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')"
      ],
      "metadata": {
        "id": "jqEVBayxZTVg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Priors"
      ],
      "metadata": {
        "id": "x9gUhQLwVFI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#-------------------------------------- Mixture of Gaussians (MoG)\n",
        "class MoG(nn.Module):\n",
        "  def __init__(self, latent_dimension, num_components=1,):\n",
        "    super(MoG, self).__init__()\n",
        "\n",
        "    self.num_components = num_components\n",
        "    self.latent_dimension = latent_dimension\n",
        "\n",
        "    #inizializzo dei tensori \"da imparare\" che sono le medie delle K componenti\n",
        "    # di dimensione (Num_components, latent_dimension)\n",
        "    self.means = nn.Parameter(torch.randn((num_components, latent_dimension),dtype=torch.float32))\n",
        "\n",
        "    #inizializzo K matrici di covarianza diagonali di ognuna delle K componenti\n",
        "    #li tratto come log_var cosi che se anche fossero negativi, una volta fatto l'exp e quindi convertiti in var diventano positivi\n",
        "    self.log_vars = nn.Parameter(torch.randn((num_components,latent_dimension),dtype=torch.float32))\n",
        "\n",
        "    #inizializzo i pesi di ogni gaussiana e li normalizzo affinchè la somma faccia 1\n",
        "    self.weights = nn.Parameter(torch.ones(num_components)/num_components )\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "\n",
        "    #campiono una camponente in base ai pesi\n",
        "    component_index =  torch.multinomial(F.softmax(self.weights, dim=0), 1)\n",
        "\n",
        "    #scelgo la media e la matrice di covarianza della componente scelta\n",
        "    mean = self.means[component_index]\n",
        "    log_var = self.log_vars[component_index]\n",
        "\n",
        "    #creo la matrice di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrix = torch.diag_embed(torch.exp(log_var))\n",
        "\n",
        "    #creo la multivariance\n",
        "    m = MultivariateNormal(mean,cov_matrix)\n",
        "\n",
        "    #campiono lo z\n",
        "    z_sample = m.sample().to(device)\n",
        "\n",
        "    return z_sample.to(torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "  def log_prob(self,z_samples):\n",
        "\n",
        "    #creo le matrici di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrices = torch.diag_embed(torch.exp(self.log_vars))\n",
        "\n",
        "    #creo K gaussiane mixate\n",
        "    MoG = MultivariateNormal(self.means.to(torch.float32),cov_matrices.to(torch.float32))\n",
        "\n",
        "    #reshape da (L, N, latent) in (N, latent)\n",
        "    z_reshaped = z_samples.view(-1, self.latent_dimension)\n",
        "\n",
        "    #Calcolo per ogni z le k log_prob (N, k)\n",
        "    k_log_probs_for_z = MoG.log_prob(z_reshaped.unsqueeze(1).to(torch.float32))\n",
        "\n",
        "    #Reshape originale (L, N, k)\n",
        "    k_log_probs_for_z_reshaped = k_log_probs_for_z.view(z_samples.shape[0],z_samples.shape[1], self.num_components).to(torch.float32)\n",
        "\n",
        "    #normalizzo i pesi affinchè la loro somma faccia 1\n",
        "    probabilities_weights = F.softmax(self.weights, dim=0)\n",
        "\n",
        "    #per ciascuno moltiplico le k probabilità per i rispettivi pesi\n",
        "    weigthed_log_probs = k_log_probs_for_z_reshaped * probabilities_weights\n",
        "\n",
        "    #sommo tutte le log_probs pesate di ogni z (L, N)\n",
        "    sum_weigthed_log_probs = weigthed_log_probs.sum(-1)\n",
        "\n",
        "    return sum_weigthed_log_probs.to(torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#---------------------VampPrior: Variational Mixture of Posterior Prior\n",
        "class VampPrior(nn.Module):\n",
        "  def __init__(self, input_shape, latent_dimension, possible_pixel_values,encode= None, num_components=1):\n",
        "    super(VampPrior, self).__init__()\n",
        "\n",
        "    #sarebbe la dimensione D*D dell'ingresso originale a cui le immagini appartengono\n",
        "    self.input_shape = input_shape\n",
        "    self.num_components = num_components\n",
        "    self.latent_dimension = latent_dimension\n",
        "    self.encode = encode\n",
        "\n",
        "    #inizializzo gli pseudo-input\n",
        "    #creo N pseudo input u (N, sqrt(input_shape), sqrt(input_shape))\n",
        "    u = torch.rand((num_components, int(math.sqrt(input_shape)), int(math.sqrt(input_shape))))*possible_pixel_values\n",
        "    #li rendo learnable\n",
        "    self.u = nn.Parameter(u)\n",
        "\n",
        "    #inizializzo i pesi di ogni gaussiana e li normalizzo affinchè la somma faccia 1\n",
        "    self.weights = nn.Parameter(torch.ones(num_components)/num_components )\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "\n",
        "    #campiono una camponente in base ai pesi\n",
        "    component_index =  torch.multinomial(F.softmax(self.weights, dim=0), 1)\n",
        "\n",
        "    #do all'encoder gli pseudo-input ottenendo le medie e le log_std\n",
        "    mean_vectors, log_std_vectors = self.encode(self.u)\n",
        "\n",
        "    #scelgo la media e la matrice di covarianza della componente scelta\n",
        "    mean_vector = mean_vectors[component_index]\n",
        "    log_std_vector = log_std_vectors[component_index]\n",
        "\n",
        "    #creo la matrice di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrix = torch.diag_embed(torch.exp(log_std_vector))\n",
        "\n",
        "    #creo la multivariance\n",
        "    m = MultivariateNormal(mean_vector, cov_matrix)\n",
        "\n",
        "    #campiono lo z\n",
        "    z_sample = m.sample().to(device)\n",
        "\n",
        "    return z_sample\n",
        "\n",
        "\n",
        "\n",
        "  def log_prob(self,z_samples):\n",
        "\n",
        "    #do all'encoder gli pseudo-input ottenendo le medie e le log_std\n",
        "\n",
        "    mean_vectors, log_std_vectors = self.encode(self.u)\n",
        "\n",
        "    #creo le matrici di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrices = torch.diag_embed(torch.exp(log_std_vectors))\n",
        "\n",
        "    #creo K gaussiane mixate\n",
        "    MoG = MultivariateNormal(mean_vectors,cov_matrices)\n",
        "\n",
        "    #reshape da (L, N, latent) in (N, latent)\n",
        "    z_reshaped = z_samples.view(-1, self.latent_dimension)\n",
        "\n",
        "    #Calcolo per ogni z le k log_prob (N, k)\n",
        "    k_log_probs_for_z = MoG.log_prob(z_reshaped.unsqueeze(1))\n",
        "\n",
        "    #Reshape originale (L, N, k)\n",
        "    k_log_probs_for_z_reshaped = k_log_probs_for_z.view(z_samples.shape[0],z_samples.shape[1], self.num_components)\n",
        "\n",
        "    #normalizzo i pesi affinchè la loro somma faccia 1\n",
        "    probabilities_weights = F.softmax(self.weights, dim=0)\n",
        "\n",
        "    #per ciascuno moltiplico le k probabilità per i rispettivi pesi\n",
        "    weigthed_log_probs = k_log_probs_for_z_reshaped * probabilities_weights\n",
        "\n",
        "    #sommo tutte le log_probs pesate di ogni z (L, N)\n",
        "    sum_weigthed_log_probs = weigthed_log_probs.sum(-1)\n",
        "\n",
        "    return sum_weigthed_log_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#----------------------- GTM-VampPrior:  Generative Topographic Mapping and Variational Mixture of Posterior Prior\n",
        "class GTM_VampPrior(nn.Module):\n",
        "  def __init__(self, input_shape, latent_dimension, possible_pixel_values,encode= None, num_components=1, u_dim=10):\n",
        "    super(GTM_VampPrior, self).__init__()\n",
        "\n",
        "    #sarebbe la dimensione D*D dell'ingresso originale a cui le immagini appartengono\n",
        "    self.input_shape = input_shape\n",
        "    self.num_components = num_components\n",
        "    self.latent_dimension = latent_dimension\n",
        "    self.encode = encode\n",
        "\n",
        "    #creo la rete che implementerà la funzione g che opera sui pseudo inputs\n",
        "    self.g_net = nn.Sequential(nn.Linear(u_dim*u_dim,number_of_hidden_neurons*2),\n",
        "                                 nn.BatchNorm1d(number_of_hidden_neurons*2),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 nn.Linear(number_of_hidden_neurons*2,number_of_hidden_neurons),\n",
        "                                 nn.BatchNorm1d(number_of_hidden_neurons),\n",
        "                                 nn.Tanh(),\n",
        "                                 #moltiplico per 2 perchè voglio sia il vettore di media che std (diagonale)\n",
        "                                 nn.Linear(number_of_hidden_neurons,input_shape),\n",
        "                                 nn.Sigmoid()\n",
        "                                 )\n",
        "\n",
        "    #inizializzo gli pseudo-input\n",
        "    #creo N pseudo input u (N, 10,10)\n",
        "    u = torch.rand((num_components, u_dim,u_dim))\n",
        "    #li rendo learnable\n",
        "    self.u = nn.Parameter(u)\n",
        "\n",
        "    #inizializzo i pesi di ogni gaussiana e li normalizzo affinchè la somma faccia 1\n",
        "    self.weights = nn.Parameter(torch.ones(num_components)/num_components )\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "\n",
        "    #campiono una camponente in base ai pesi\n",
        "    component_index =  torch.multinomial(F.softmax(self.weights, dim=0), 1)\n",
        "\n",
        "    #do all'encoder gli pseudo-input ottenendo le medie e le log_std\n",
        "    #processo gli pseudo-input con una funzion g\n",
        "    x = torch.flatten(self.u,1)\n",
        "    pseudo_input_after_g = self.g_net(x)\n",
        "\n",
        "    mean_vectors, log_std_vectors = self.encode(pseudo_input_after_g*possible_pixel_values)\n",
        "\n",
        "\n",
        "    #scelgo la media e la matrice di covarianza della componente scelta\n",
        "    mean_vector = mean_vectors[component_index]\n",
        "    log_std_vector = log_std_vectors[component_index]\n",
        "\n",
        "    #creo la matrice di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrix = torch.diag_embed(torch.exp(log_std_vector))\n",
        "\n",
        "    #creo la multivariance\n",
        "    m = MultivariateNormal(mean_vector,cov_matrix)\n",
        "\n",
        "    #campiono lo z\n",
        "    z_sample = m.sample().to(device)\n",
        "\n",
        "    return z_sample\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def log_prob(self,z_samples):\n",
        "\n",
        "    #do all'encoder gli pseudo-input ottenendo le medie e le log_std\n",
        "    #processo gli pseudo-input con una funzion g\n",
        "    x = torch.flatten(self.u,1)\n",
        "    pseudo_input_after_g = self.g_net(x)\n",
        "\n",
        "    mean_vectors, log_std_vectors = self.encode(pseudo_input_after_g*possible_pixel_values)\n",
        "\n",
        "    #creo le matrici di covarianza a partire dai vettori che ne definiscono le diagonali\n",
        "    cov_matrices = torch.diag_embed(torch.exp(log_std_vectors))\n",
        "\n",
        "    #creo K gaussiane mixate\n",
        "    MoG = MultivariateNormal(mean_vectors,cov_matrices)\n",
        "\n",
        "    #reshape da (L, N, latent) in (N, latent)\n",
        "    z_reshaped = z_samples.view(-1, self.latent_dimension)\n",
        "\n",
        "    #Calcolo per ogni z le k log_prob (N, k)\n",
        "    k_log_probs_for_z = MoG.log_prob(z_reshaped.unsqueeze(1))\n",
        "\n",
        "    #Reshape originale (L, N, k)\n",
        "    k_log_probs_for_z_reshaped = k_log_probs_for_z.view(z_samples.shape[0],z_samples.shape[1], self.num_components)\n",
        "\n",
        "    #normalizzo i pesi affinchè la loro somma faccia 1\n",
        "    probabilities_weights = F.softmax(self.weights, dim=0)\n",
        "\n",
        "    #per ciascuno moltiplico le k probabilità per i rispettivi pesi\n",
        "    weigthed_log_probs = k_log_probs_for_z_reshaped * probabilities_weights\n",
        "\n",
        "    #sommo tutte le log_probs pesate di ogni z (L, N)\n",
        "    sum_weigthed_log_probs = weigthed_log_probs.sum(-1)\n",
        "\n",
        "    return sum_weigthed_log_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#--------------------Flow-based prior\n",
        "class Flow_Based_prior(nn.Module):\n",
        "  def __init__(self, latent_dimension):\n",
        "    super(Flow_Based_prior, self).__init__()\n",
        "\n",
        "    #divideremo l'input Z a metà, quindi prenderemo metà delle componenti\n",
        "    self.input_dimension = latent_dimension //2\n",
        "\n",
        "    self.number_of_neurons = 128\n",
        "    self.number_of_flows = 8\n",
        "\n",
        "    self.scale_net = nn.Sequential(nn.Linear(self.input_dimension,self.number_of_neurons),\n",
        "                                   nn.ELU(),\n",
        "                                   nn.Linear(self.number_of_neurons,self.number_of_neurons*2),\n",
        "                                   nn.ELU(),\n",
        "                                   nn.Linear(self.number_of_neurons*2,self.number_of_neurons*2),\n",
        "                                   nn.Tanh(),\n",
        "                                   nn.Linear(self.number_of_neurons*2,self.input_dimension),\n",
        "                                   nn.Tanh()\n",
        "                                   )\n",
        "    #neo creo 8\n",
        "    self.scale_nets = torch.nn.ModuleList([self.scale_net for _ in range(self.number_of_flows)])\n",
        "\n",
        "    self.translation_net = nn.Sequential(nn.Linear(self.input_dimension,self.number_of_neurons),\n",
        "                                nn.LeakyReLU(),\n",
        "                                nn.Linear(self.number_of_neurons,self.number_of_neurons*2),\n",
        "                                nn.ELU(),\n",
        "                                nn.Linear(self.number_of_neurons*2,self.number_of_neurons*2),\n",
        "                                nn.Tanh(),\n",
        "                                nn.Linear(self.number_of_neurons*2,self.input_dimension),\n",
        "                                )\n",
        "\n",
        "    #neo creo 8\n",
        "    self.translation_nets = torch.nn.ModuleList([self.translation_net for _ in range(self.number_of_flows)])\n",
        "\n",
        "    #la distribuzione iniziale da cui partire, ossia N(0,I)\n",
        "    self.p0 = MultivariateNormal(torch.zeros(latent_dimension).to(device), torch.eye(latent_dimension).to(device))\n",
        "\n",
        "\n",
        "  def coupling_layer(self, z, index, forward=True):\n",
        "\n",
        "    #divido l'input in due parti\n",
        "    (za,zb) = torch.chunk(z,2,1)\n",
        "\n",
        "    #inizializzo i due output del coupling layer\n",
        "    ya = 0,\n",
        "    yb = 0\n",
        "\n",
        "    #print(\" calcolo s e t con ingresso di dimensione \", za.shape)\n",
        "    s = self.scale_nets[index](za)\n",
        "    t = self.translation_nets[index](za)\n",
        "\n",
        "    ya= za\n",
        "\n",
        "    if forward == False:\n",
        "      yb = torch.exp(s)*zb + t\n",
        "    else:\n",
        "      yb = (zb-t)*torch.exp(-s)\n",
        "\n",
        "    return torch.cat((ya,yb), 1), s\n",
        "\n",
        "  def permute(self, z):\n",
        "    return z.flip(1)\n",
        "\n",
        "  def log_prob(self,z):\n",
        "    '''\n",
        "      Io voglio calcolare il log(p(z)) e so che questo è calcolabile come:\n",
        "        log(p(z)) = ln(p0(z0=f^-1(x)) ) - sum(ln(det(J_fi(z_i-1))))\n",
        "    '''\n",
        "    #in ingresso ho (L, N, latent), lo converto in (L*N, latent)\n",
        "    L = z.shape[0]\n",
        "    N = z.shape[1]\n",
        "    z = z.view((L*N,z.shape[2]))\n",
        "    #se ho N z allora ho N log_det_J da memorizzare, uno per ogni z\n",
        "    log_det_J = z.new_zeros(z.shape[0])\n",
        "\n",
        "    output = z\n",
        "    #vado da p(x) a p0\n",
        "    for flow_i in range(self.number_of_flows):\n",
        "      output, s = self.coupling_layer(output, flow_i, forward=True)\n",
        "      output = self.permute(output)\n",
        "      log_det_J = log_det_J + s.sum(dim=1)\n",
        "\n",
        "    #adesso ho ottenuto che output=z0=f^-1(x) e ho la somma dei logaritmi dei determinanti\n",
        "    ln_p_z = self.p0.log_prob(output) - log_det_J\n",
        "\n",
        "    #ritorno nel formato previsto (L, N)\n",
        "    return ln_p_z.view((L,N))\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "\n",
        "    #campiono dalla prior\n",
        "    z0 = self.p0.sample()\n",
        "\n",
        "    z = z0.unsqueeze(0)\n",
        "\n",
        "    #procedo da p0 a p(x)\n",
        "    for flow_i in reversed(range(self.number_of_flows)):\n",
        "      z = self.permute(z)\n",
        "      z,_ = self.coupling_layer(z, flow_i, forward=False)\n",
        "\n",
        "    #ritorno un campione di p(x)\n",
        "    return z\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O_ZHlI9mVHIc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Householder flow"
      ],
      "metadata": {
        "id": "TPZZME0nZZmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HouseholderFlow(nn.Module):\n",
        "  def __init__(self, latent_space_dimension, number_of_flows):\n",
        "    super(HouseholderFlow,self).__init__()\n",
        "\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "    self.number_of_flows = number_of_flows\n",
        "\n",
        "    #creo number_of_flows dense layer, ciascuno elaborerà un suo Householder vector\n",
        "    self.linears = nn.ModuleList([nn.Linear(latent_space_dimension, latent_space_dimension) for i in range(number_of_flows)])\n",
        "\n",
        "\n",
        "    '''\n",
        "      Ricordo che dato un vi (Householder vector) la relativa matrice di Householder\n",
        "      Hi si trova come:\n",
        "                          H_i = I - 2* vi^T v / v v^T\n",
        "      Ne troveremo K che poi moltiplicheremo per trovare la matrice di trasformazione:\n",
        "                              U = H1*H2*...*HK\n",
        "      Dopodichè trasformeremo z cosi:\n",
        "                                  z' = U*z\n",
        "      Ricorda inoltre che ogni vettore di Householder ( a parte v0) viene trovato dando\n",
        "      a un lineare layer il vettore di Householder precedente in ingresso.\n",
        "\n",
        "      NB: quello sopra è teorico. Per praticità calcoleremo il flusso calcolando tutto a step,\n",
        "      ossia prima z1, poi z2, poi z3 e cosi via...\n",
        "    '''\n",
        "\n",
        "  #in ingresso prende gli z0 samples e il primo Householder vector v0\n",
        "  def forward(self, z, v):\n",
        "\n",
        "    #creo la matrice identità (una volta, tanto è la stessa per ogni flow)\n",
        "    I = torch.eye(self.latent_space_dimension).to(device)\n",
        "\n",
        "    for i in np.arange(self.number_of_flows):\n",
        "\n",
        "      #calcolo per ogni z la matrice di Householder Hi usando v_(i-1)\n",
        "      #per ogni householder vector vi calcolo calcolo ||vi||^2\n",
        "      norms = torch.norm(v, dim=-1, keepdim=True)\n",
        "      dot_product = torch.pow(norms,2)\n",
        "\n",
        "      #per ogni householder vector vi calcolo l'outer product con se stesso\n",
        "      outer_product = torch.matmul(v.unsqueeze(2), v.unsqueeze(1))\n",
        "\n",
        "      #adesso posso calcolare vi^T vi / ||vi||^2\n",
        "      normalized_outer_product = outer_product / dot_product[:,None]\n",
        "\n",
        "      #per ogni householder vector vi calcolo la relativa matrice di Householder Hi\n",
        "      H_is = I-2*normalized_outer_product\n",
        "\n",
        "      #calcolo trasformazione per il flusso corrente\n",
        "      z = torch.matmul(H_is.unsqueeze(0),torch.transpose(z.unsqueeze(2),2,3)).squeeze(-1)\n",
        "\n",
        "      #calcolo nuovo vettore di Householder\n",
        "      v = self.linears[i](v)\n",
        "\n",
        "    #ritorno gli z trasformati\n",
        "    return z\n",
        "\n"
      ],
      "metadata": {
        "id": "ez7kILXmZbaa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "hlA1ddleVKi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#--------------- Encoder\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_shape_image, latent_space_dimension, number_of_hidden_neurons, L, number_of_flows):\n",
        "    super(Encoder,self).__init__()\n",
        "\n",
        "    #numero di campioni per l'approssimazione Monte-Carlo dell'Expected Value\n",
        "    self.L = L\n",
        "\n",
        "    self.input_shape_image = input_shape_image\n",
        "\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "\n",
        "    out_channels = 14\n",
        "    kernel_size = 4\n",
        "\n",
        "    '''\n",
        "        NEW scompongo l'encoder in 3 parti cosi da poter utilizzare l'output di un layer\n",
        "        specifico senza fare girare due volte l'encoder\n",
        "    '''\n",
        "    self.encoder_0 = nn.Sequential(\n",
        "                   nn.Conv2d(1,out_channels,kernel_size, stride=2),\n",
        "                   nn.BatchNorm2d(out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "\n",
        "                   nn.Conv2d(out_channels,2*out_channels,kernel_size, stride=2),\n",
        "                   nn.BatchNorm2d(2*out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "\n",
        "                   nn.Conv2d(2*out_channels,2*out_channels,kernel_size,stride=2),\n",
        "                   nn.BatchNorm2d(2*out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "\n",
        "                   nn.Conv2d(2*out_channels,3*out_channels,kernel_size, stride=2),\n",
        "                   nn.BatchNorm2d(3*out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "\n",
        "                   nn.Flatten()\n",
        "                   )\n",
        "\n",
        "    #QUESTO è il nuovo layer che useremo per estrarre il primo Householder vector v cosi\n",
        "    #da renderlo in funzione dell'input x\n",
        "    self.encoder_1 = nn.LazyLinear(latent_space_dimension)\n",
        "\n",
        "    self.encoder_2 = nn.Linear(latent_space_dimension, 2*latent_space_dimension)\n",
        "\n",
        "    self.prior = None\n",
        "\n",
        "    #creo il modulo per effettuare l'Householder Flow\n",
        "    self.householderTransformation = HouseholderFlow(latent_space_dimension, number_of_flows)\n",
        "\n",
        "\n",
        "  def set_prior(self,prior):\n",
        "    #associo la prior scelta\n",
        "    self.prior = prior\n",
        "\n",
        "  def encode(self,x):\n",
        "    #trasformo il batch da (64, 28, 28) in (64,1,28,28)\n",
        "    x = x.unsqueeze(1)\n",
        "    #do alla rete x e prelevo vettore di media e std (diagonale)\n",
        "    output_0 = self.encoder_0(x.to(torch.float32))\n",
        "    output_1 = self.encoder_1(output_0)\n",
        "    output = self.encoder_2(output_1)\n",
        "\n",
        "    #divido il risultato in due parti: media e std (diagonale)(logaritmica)\n",
        "    mean_vector, log_std_vector = torch.chunk(output, 2, dim=1)\n",
        "\n",
        "    return mean_vector, log_std_vector\n",
        "\n",
        "\n",
        "  def KL_loss(self,log_std_vector,mean_vector,v0, batch_length):\n",
        "\n",
        "    L = self.L\n",
        "\n",
        "    #trasformo i logaritmi delle std in std\n",
        "    std_vector = torch.exp(log_std_vector)\n",
        "\n",
        "    #siccome devo avere una matrice positiva definita (cholesky decomposition) devo\n",
        "    #assicurarmi che i valori nelle diagonali non siano proprio zero\n",
        "    EPS = 1.e-5\n",
        "    std_vector = torch.clamp(std_vector, EPS,1. - EPS)\n",
        "\n",
        "    #trasformo le sequenze di varianze in matrici diagonali (covarianza)\n",
        "    covariance_matrixes = torch.diag_embed(std_vector)\n",
        "\n",
        "    #calcolo N distribuzioni  multivariate q(z|x) creata da ognuno degli N x\n",
        "    #QUESTA E' LA DISTRIBUZIONE q(z0|x) DI PARTENZA\n",
        "    q_z_x = MultivariateNormal(mean_vector, covariance_matrixes)\n",
        "\n",
        "\n",
        "    '''\n",
        "      per ciascuna distribuzione campiono L vettori z0\n",
        "      Nota però che anche se campiono L vettori da ciascuna, il risultato\n",
        "      conterrà i primi N vettori z0 campionati, poi i secondi N e cosi via fino\n",
        "      agli L-esimi. Per esempio i primi due z0_1 e z0_2 sono stati campionati da due\n",
        "      distribuzioni diverse! Quindi non ho blocchi da L vettori z0 appartenenti\n",
        "      alla stessa distribuzione!\n",
        "    '''\n",
        "    #dimensione (L, num_distribuzioni, dim_latente)\n",
        "    z_samples = q_z_x.rsample((L,)) #r sta per \"reparametrization trick\"\n",
        "\n",
        "\n",
        "    #Devo trasformare gli z0 campionati in zk tramite il flusso di Householder partendo da v0\n",
        "    #(L, num_distribuzioni, dim_latente)\n",
        "    zk_samples = self.householderTransformation(z_samples, v0)\n",
        "\n",
        "    '''\n",
        "      Per gli z0 (campionati dalla distribuzione di base) calcolo ln(q(z0|x))\n",
        "    '''\n",
        "    z_log_probs = q_z_x.log_prob(z_samples)\n",
        "\n",
        "    '''\n",
        "      mentre per gli zk calcolo ln(p(zk))\n",
        "    '''\n",
        "\n",
        "    ln_p_z = self.prior.log_prob(zk_samples)\n",
        "\n",
        "    '''\n",
        "      Ora per ogni immagine x io ho campionato L vettori z0, li ho trasformati in zk e per ciascuno ho\n",
        "      valutato sia ln(q(z0|x)) che ln(p(zk)). Per ogni immagine io volevo calcolare\n",
        "      l'expected value approssimandolo (Monte Carlo) come:\n",
        "\n",
        "                        KL = [Sum(ln(q(z0|x)))/L - Sum(ln(p(zk))/L)\n",
        "\n",
        "      Per ottenere la prima sommatoria, sommo le colonne di z_log_probs, mentre\n",
        "      per la seconda sommo le colonne della matrice ln_p_z. Dopodichè, ottenuti\n",
        "      due vettori, li divido per L e li sottraggo tra cosi da ottenere l'approssimazione\n",
        "      della KL per ogni immagine x in ingresso\n",
        "    '''\n",
        "\n",
        "    KL_per_image = z_log_probs.sum(0)/L - ln_p_z.sum(0)/L\n",
        "\n",
        "    #NB: adesso devo ritornare gli z_k in quanto il decoder calcolerò RE con gli zk\n",
        "    return KL_per_image, zk_samples\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "    z_sample = self.prior.sample()\n",
        "    return z_sample\n",
        "\n",
        "\n",
        "  #La rete ritorna il vettore di media, std (diagonale) e la z campionata\n",
        "  def forward(self, x):\n",
        "\n",
        "    #trasformo il batch da (64, 28, 28) in (64,1,28,28)\n",
        "    x = x.unsqueeze(1)\n",
        "\n",
        "    #do alla rete x e prelevo vettore di media e std (diagonale)\n",
        "    output_0 = self.encoder_0(x.to(torch.float32))\n",
        "    #v0 è il primo Householder vector (N, latent)\n",
        "    v0 = self.encoder_1(output_0)\n",
        "    output = self.encoder_2(v0)\n",
        "\n",
        "    #divido il risultato in tre parti: media e std (diagonale)(logaritmica)\n",
        "    mean_vector, log_std_vector = torch.chunk(output, 2, dim=1)\n",
        "\n",
        "    '''\n",
        "      Ottengo un KL_error (N,) contenente per ogni immagine il relativo KL_error,\n",
        "      e poi una matrice zk_samples (L, N, dim_latente) trasformati per Householder\n",
        "    '''\n",
        "    KL_per_image, zk_samples = self.KL_loss(log_std_vector,mean_vector,v0, x.shape[0])\n",
        "\n",
        "\n",
        "    return KL_per_image, zk_samples\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-------- Decoder\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_shape_image,latent_space_dimension, number_of_hidden_neurons, possible_pixel_values, L):\n",
        "    super(Decoder,self).__init__()\n",
        "\n",
        "    self.L = L\n",
        "\n",
        "    self.input_shape_image = input_shape_image\n",
        "\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "\n",
        "    self.possible_pixel_values = possible_pixel_values\n",
        "\n",
        "    kernel_size = 3\n",
        "    out_channels = 14\n",
        "\n",
        "    self.decoder = nn.Sequential(nn.Linear(latent_space_dimension,4096),\n",
        "                          nn.Unflatten(2, (int(math.sqrt(4096)),int(math.sqrt(4096)))),\n",
        "                          nn.Upsample(size=[8,8], mode='bilinear', align_corners=False),\n",
        "                          nn.Conv2d(in_channels=1, out_channels=3*out_channels, kernel_size=kernel_size),\n",
        "                          nn.BatchNorm2d(3*out_channels),\n",
        "                          nn.LeakyReLU(),\n",
        "\n",
        "                          nn.Upsample(size=[16,16], mode='bilinear', align_corners=False),\n",
        "                          nn.Conv2d(in_channels=3*out_channels, out_channels=2*out_channels, kernel_size=kernel_size),\n",
        "                          nn.BatchNorm2d(2*out_channels),\n",
        "                          nn.LeakyReLU(),\n",
        "\n",
        "                          nn.Upsample(size=[16,16], mode='bilinear', align_corners=False),\n",
        "                          nn.Conv2d(in_channels=2*out_channels, out_channels=out_channels, kernel_size=kernel_size),\n",
        "                          nn.BatchNorm2d(out_channels),\n",
        "                          nn.LeakyReLU(),\n",
        "\n",
        "                          nn.Flatten(),\n",
        "                          nn.LazyLinear(input_shape_image*possible_pixel_values),\n",
        "                          nn.Unflatten(1,(input_shape_image,possible_pixel_values))\n",
        "\n",
        "                          )\n",
        "\n",
        "  def decode_sample(self,z_sample):\n",
        "\n",
        "    #inietto nel decoder:\n",
        "    z_sample = z_sample.reshape(1,1,z_sample.shape[1])\n",
        "\n",
        "    logits = self.decoder(z_sample.to(torch.float32))\n",
        "\n",
        "    #(1,W*H,possible_pixel_values)\n",
        "    logits = logits.reshape(1, self.input_shape_image, self.possible_pixel_values )\n",
        "\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    #non applico la softmax per convertirli in probabilità perchè\n",
        "    probabilities = probabilities.view(-1, self.possible_pixel_values)\n",
        "\n",
        "    sample = torch.multinomial(probabilities, num_samples=1)\n",
        "\n",
        "    x = sample.view(self.input_shape_image)\n",
        "    return x\n",
        "\n",
        "\n",
        "  def forward(self, z, x):\n",
        "    #z è una matrice (L, N, dim_latente), la inietto nel decoder per ottenere le logits\n",
        "    z=z.reshape(self.L*z.shape[1], 1,z.shape[2])\n",
        "\n",
        "    logits = self.decoder(z.to(torch.float32))\n",
        "\n",
        "    logits = logits.reshape(self.L, int(logits.shape[0]//self.L), logits.shape[1]*logits.shape[2])\n",
        "\n",
        "    '''\n",
        "      Prima di convertire le logits in probabilità, ciascun vettore del tensore\n",
        "      contiene i logits di TUTTI i pixel [px1-v=v1,...,px1-v=vk, px2-v=1,....], quindi\n",
        "      devo prima fare un reshape del genere [[px1-v=v1,...,px1-v=vk], [...]] isolando\n",
        "      solo le probabilità di ogni pixel\n",
        "\n",
        "    '''\n",
        "    #(L, N, numero_pixel, possibili_valori)\n",
        "    logits = logits.reshape((logits.shape[0],logits.shape[1],self.input_shape_image,self.possible_pixel_values))\n",
        "    #applico la softmax per convertire le logits in probabilità\n",
        "    probabilities = torch.softmax(logits,3)\n",
        "\n",
        "    #correggo (per questioni di stabilità) le probabilità troppo basse\n",
        "    #Devono stare tra 0+EPS < p < 1-EPS\n",
        "    EPS = 1.e-5\n",
        "    probabilities = torch.clamp(probabilities, EPS,1. - EPS)\n",
        "\n",
        "    '''\n",
        "      Per ogni z iniettato ho ottenuto delle probabilità. Siccome voglio valutare\n",
        "      l'expected value seguente:\n",
        "                              E[ln(p(x|z))]\n",
        "      e sicome lo voglio approssimare con gli L ln(p(x|z)) ottenuti, ossia:\n",
        "                              E[ln(p(x|z))] = 1/L*Sum(ln(p(x|z)))\n",
        "      allora tutti i calcoli seguenti servono solo a poter ottenere per ciascuna\n",
        "      immagine x tutti i ln(p(x|z)), in particolare:\n",
        "      1) Per ogni z ho una matrice di dimensione(numero_pixel, probabilità_valori)\n",
        "         e quindi estraggo la probabilità che ha quella particolare componente xi\n",
        "         in ingresso.\n",
        "      2) Alla fine per ogni coppia x e z ho un vettore di probabilità per xi, quindi\n",
        "         quella di x è calcolabile come:\n",
        "                              p(x|z)=p(x1|z)*p(x2|z)*...*p(xk|z)\n",
        "         Se però calcolo il logaritmo, che è quello che voglio posso sommarli:\n",
        "                              ln(p(x|z))=ln(p(x1|z))+ln(p(x2|z))+...+ln(p(xk|z))\n",
        "      3) Avendone L li sommo e li divido per L\n",
        "\n",
        "    '''\n",
        "\n",
        "    #converto ogni pixel in un vettore one_hot\n",
        "    x_one_hot = F.one_hot(x.long(), num_classes = self.possible_pixel_values)\n",
        "    x_one_hot = x_one_hot.reshape(x_one_hot.shape[0],x_one_hot.shape[1]*x_one_hot.shape[2]*x_one_hot.shape[3])\n",
        "    probabilities = probabilities.reshape(probabilities.shape[0],probabilities.shape[1],probabilities.shape[2]*probabilities.shape[3])\n",
        "    #li converto in logaritmi\n",
        "    log_probabilities = torch.log(probabilities)\n",
        "\n",
        "    selected_log_probabilities = x_one_hot * log_probabilities\n",
        "    #adesso in un unico vettore ho tutti le ln(p(x_i|z)) per lo z.\n",
        "    #li sommo (L,N), ossia ogni vettore contiene gli ln(p(x|z)) per gli N x\n",
        "    ln_p_x_z = selected_log_probabilities.sum(2)\n",
        "\n",
        "\n",
        "    #ogni colonna contiene quindi gli ln(p(x|z)) per lo stesso x.\n",
        "    #li sommo e li divido per L ottenenedo il reconstruction error per ogni x\n",
        "    RE_per_image = ln_p_x_z.sum(0) / self.L\n",
        "\n",
        "    return RE_per_image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#------------ Variational AutoEncoder\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, possible_pixel_values, input_shape_image, latent_space_dimension, number_of_hidden_neurons,L,number_of_flows, type_of_prior=0, mog_components=1):\n",
        "    super(VAE, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(input_shape_image,latent_space_dimension,number_of_hidden_neurons,L,number_of_flows)\n",
        "    self.decoder = Decoder(input_shape_image,latent_space_dimension,number_of_hidden_neurons,possible_pixel_values,L)\n",
        "\n",
        "    prior = None\n",
        "    if type_of_prior == 1:\n",
        "      #creo una mixture of gaussian a 15 componenti come prior p(z)\n",
        "      prior = MoG(latent_space_dimension, mog_components)\n",
        "    elif type_of_prior == 2:\n",
        "      prior = VampPrior(input_shape_image, latent_space_dimension, possible_pixel_values, self.encoder.encode, num_components= mog_components )\n",
        "    elif type_of_prior == 3:\n",
        "      prior = GTM_VampPrior(input_shape_image, latent_space_dimension, possible_pixel_values, self.encoder.encode, num_components= mog_components )\n",
        "    elif type_of_prior == 4:\n",
        "      prior = Flow_Based_prior(latent_space_dimension)\n",
        "    else:\n",
        "      #p(z)=N(0,I)\n",
        "      prior = MultivariateNormal(torch.zeros(self.latent_space_dimension), torch.eye(self.latent_space_dimension))\n",
        "\n",
        "    self.prior = prior\n",
        "\n",
        "  def initialize(self):\n",
        "    #aggiorno il riferimento della prior per l'encoder\n",
        "    self.encoder.set_prior(self.prior)\n",
        "\n",
        "  def sample(self):\n",
        "    z_sample = self.encoder.sample()\n",
        "    return self.decoder.decode_sample(z_sample)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    #inietto x nell'encoder per ottenere la KL loss e i vettori z campionati (Monte-Carlo)\n",
        "    KL_loss_per_image, z_samples_per_image = self.encoder.forward(x)\n",
        "\n",
        "    #inietto nel decoder x per essere ricostruito attraverso gli stessi campioni z\n",
        "    #e per ottenere il reconstruction error\n",
        "    RE_loss_per_image = self.decoder.forward(z_samples_per_image,x)\n",
        "\n",
        "    #sommo per ottenere una approssimazione del ln(p(x)) per ogni immagine\n",
        "    ln_p = KL_loss_per_image - RE_loss_per_image\n",
        "\n",
        "    #calcolo la media del batch\n",
        "    ln_p_mean = ln_p.mean()\n",
        "\n",
        "    return ln_p_mean\n"
      ],
      "metadata": {
        "id": "1VgklM8sVJ7K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "VwoaF43RVQp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################### GPU + Path ##########################################\n",
        "\n",
        "# Controlla la disponibilità della GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Imposta il dispositivo sulla GPU\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Se la GPU non è disponibile, utilizza la CPU\n",
        "\n",
        "print(\"Device utilizzato:\", device)\n",
        "print(\"Numero di GPU disponibili:\", torch.cuda.device_count())\n",
        "\n",
        "\n",
        "#path dove salvare il modello migliore e i vari output di ogni epoca valida\n",
        "path_to_model = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/model/model_prior_mog_new_net1_HF.pth\"\n",
        "path_to_output = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/output/prior_mog_posterior_new_net_1_HF_\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################### Dataloader ##########################################\n",
        "\n",
        "#per motivi di efficienza, scegliere il rescaling e il massimo valore che ogni pixel può assumere\n",
        "resize_to = 64\n",
        "max_pixel_value = 20\n",
        "\n",
        "input_shape_image = resize_to*resize_to\n",
        "possible_pixel_values = max_pixel_value+1\n",
        "\n",
        "\n",
        "def load_data():\n",
        "\n",
        "\n",
        "    # Definisci le trasformazioni da applicare alle immagini durante il caricamento\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize( (resize_to, resize_to) ), #rescaling di ogni immagine\n",
        "        transforms.Grayscale(),  # Trasforma l'immagine in bianco e nero\n",
        "        transforms.ToTensor(),# Converte l'immagine in un tensore\n",
        "        transforms.Lambda(lambda x: torch.round(x*(max_pixel_value))), #normalizzo i valori dei pixel e li forzo ad essere interi\n",
        "        transforms.Lambda(lambda x: x.to(torch.float32))\n",
        "    ])\n",
        "\n",
        "    # Crea un oggetto ImageFolder per caricare le immagini dalla cartella specificata e applica le trasformazioni definite\n",
        "    dataset = datasets.ImageFolder('/content/dataset/', transform=transform)\n",
        "\n",
        "    # Calcola l'indice per dividere il dataset tra training set e validation set\n",
        "    split_ratio = 0.8  # Ratio di suddivisione (80% per il training set, 20% per il validation set)\n",
        "    dataset_size = len(dataset)\n",
        "    split_index = int(split_ratio * dataset_size)\n",
        "\n",
        "    # Crea due sottoinsiemi distinti per il training set e il validation set\n",
        "    train_dataset = Subset(dataset, range(0, split_index))\n",
        "    val_dataset = Subset(dataset, range(split_index, dataset_size))\n",
        "\n",
        "    # Crea i DataLoader per il training set e il validation set\n",
        "    batch_size = 32\n",
        "    training_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "    validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return training_loader, validation_loader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################### Training + validation #####################################\n",
        "\n",
        "def train_model_on_given_gpu():\n",
        "\n",
        "    #definisco la dimensione dello spazio latente\n",
        "    latent_space_dimension = 64 #deve essere pari se utilizzi il Flow-based\n",
        "    #nuumero di hidden neurons nell'encoder e decoder\n",
        "    number_of_hidden_neurons = 64 #la sua radice quadrata deve essere intera altrimenti ci sarà un errore\n",
        "    #numero componenti gaussiane per il MoG o VampPrior\n",
        "    mog_components = 20\n",
        "    #Monte-Carlo approximations\n",
        "    L = 2\n",
        "    #number of Householder flows\n",
        "    number_of_flows = 10\n",
        "\n",
        "    #---- creazione del modello\n",
        "    #decide il numero di campioni per l'approssimazione Monte-Carlo dell'expected value\n",
        "    print(\"Memoria GPU prima della creazione del modello:\", torch.cuda.memory_allocated())\n",
        "\n",
        "    model =  VAE( possible_pixel_values, input_shape_image, latent_space_dimension, number_of_hidden_neurons, L,number_of_flows,type_of_prior=1, mog_components=mog_components)\n",
        "    model.to(device)\n",
        "    model.initialize()\n",
        "    print(\"Memoria GPU dopo la creazione del modello:\", torch.cuda.memory_allocated())\n",
        "\n",
        "    # Esegui un passaggio di inoltro dummy per il LazyLinear\n",
        "    inputs = torch.round(torch.rand((5, resize_to, resize_to),dtype=torch.float32)*max_pixel_value).to(device)\n",
        "    dummy_output = model(inputs).item()\n",
        "\n",
        "    print(\"Numero parametri modello: \",sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    del inputs\n",
        "    del dummy_output\n",
        "    gc.collect()\n",
        "\n",
        "    model = torch.nn.parallel.DataParallel(model)\n",
        "\n",
        "    #parametri per il learning\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    parameters_to_optimize = [p for p in model.parameters() if p.requires_grad == True]\n",
        "\n",
        "    optimizer = torch.optim.Adamax(parameters_to_optimize, lr=learning_rate)\n",
        "\n",
        "\n",
        "    #------ Funzione per salvare una griglia di campioni decodificati dallo spazio latente ogni volta che la validation è migliore\n",
        "    def sample_and_save(model, name, input_shape):\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      #voglio campionare 16 immagini e le voglio in una griglia 4x4\n",
        "      n=4\n",
        "      number_of_grid_cells = n*n\n",
        "      #quindi dico al modello di campionarmi 16 immagini\n",
        "      xs = np.zeros((number_of_grid_cells,input_shape))\n",
        "      for i in np.arange(number_of_grid_cells):\n",
        "        generated_sample = model.module.sample().cpu() # il .module serve per andare oltre il wrapping di DataParallel\n",
        "        #lo stacco dal grafo di computazione\n",
        "        generated_sample = generated_sample.detach().numpy()\n",
        "        xs[i,:] = generated_sample\n",
        "\n",
        "\n",
        "      fig, ax = plt.subplots(n, n)\n",
        "      for i, ax in enumerate(ax.flatten()):\n",
        "          plottable_image = np.reshape(xs[i], (int(math.sqrt(input_shape)), int(math.sqrt(input_shape))))\n",
        "          ax.imshow(plottable_image, cmap='gray')\n",
        "          ax.axis('off')\n",
        "\n",
        "      plt.savefig(path_to_output+'epoca_' +str(name)+ '.pdf', bbox_inches='tight')\n",
        "      plt.close()\n",
        "\n",
        "\n",
        "\n",
        "    #---- Training e validation\n",
        "    number_of_epochs = 1000\n",
        "    #fisso il limite massimo di batch di training e validazione\n",
        "    max_batch_for_training = 800\n",
        "    max_batch_for_validation = 170\n",
        "\n",
        "\n",
        "    #qui salvo il migliore modello, ossia quello che ha la loss sulla validazione migliore\n",
        "    best_model = model\n",
        "    best_validation_loss = 1000000\n",
        "\n",
        "    patience = 0\n",
        "    max_patience = 30\n",
        "\n",
        "    training_loader, validation_loader = load_data()\n",
        "\n",
        "    grd_acc = 1 #significa che prima di backpropagare l'errore accumulerò il gradiente di batch_size*grd_acc (ees. 8*4=32 è come se processassi batch da 32)\n",
        "\n",
        "    for epoch in range(number_of_epochs):\n",
        "      model.train()\n",
        "      print(\"Epoca \"+str(epoch)+\" _____________________________________________________________________\")\n",
        "\n",
        "      num_batch = 1\n",
        "      for batch, _ in training_loader:\n",
        "\n",
        "        #reshaping di ogni batch da (N, 1, W, H) a (N, W, H)\n",
        "        batch = batch.squeeze(1)\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        #print(\"             Memoria GPU utilizzata prima loss per batch:\",num_batch,\"  -> \", round(torch.cuda.memory_allocated()*(1e-9),5),\" GB\")\n",
        "        #batch = batch.to(torch.float32)\n",
        "\n",
        "        loss = model.forward(batch)\n",
        "        #print(\"             Memoria GPU utilizzata dopo loss per batch:\",num_batch,\"  -> \", round(torch.cuda.memory_allocated()*(1e-9),5),\" GB\")\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        #calcolo le derivate parziali della loss rispetto ogni parametro NB: LA mean() E' PERCHE' UTILIZZO N GPU E CIASCUNA RITORNA LA SUA LOSS\n",
        "        (loss.mean()/grd_acc).backward(retain_graph=True)\n",
        "        torch.cuda.empty_cache()\n",
        "        #print(\"             Memoria GPU utilizzata dopo backward per batch:\",num_batch,\"  -> \", round(torch.cuda.memory_allocated()*(1e-9),5),\" GB\")\n",
        "        #se ho accumulato il gradiente di un numero sufficiente di batch, allora backpropago\n",
        "        if ( (num_batch % grd_acc) == 0):\n",
        "            #adesso ogni parametro ha in .grad il gradiente. Aggiorno il suo valore\n",
        "            optimizer.step()\n",
        "\n",
        "            #resetto il .grad di ogni parametro (altrimenti sommo quello attuale al successivo che calcoleremo nell'epoca dopo)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        print(\"   Loss batch: \",str(num_batch),\": \", loss, \"          Memoria GPU utilizzata  -> \", round(torch.cuda.memory_allocated()*(1e-9),4), \"GB\")\n",
        "\n",
        "            #se ho superato il numero massimo di batch per il training, esco\n",
        "        if num_batch >= max_batch_for_training:\n",
        "            break\n",
        "        else:\n",
        "            num_batch = num_batch + 1\n",
        "\n",
        "      #alla fine di ogni epoca, valuto come si comporta la loss col validation set\n",
        "      print(\"   ___________________________\")\n",
        "      model.eval()\n",
        "      validation_loss = 0\n",
        "      N = 0\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      num_batch = 1\n",
        "      for batch, _ in validation_loader:\n",
        "\n",
        "        batch = batch.squeeze(1)\n",
        "        batch = batch.to(device)\n",
        "        #batch = batch.to(torch.float32)\n",
        "        loss_i = model.forward(batch)\n",
        "        validation_loss = validation_loss + loss_i.mean().item()# NB: .mean() SOLO PERCH' UTILIZZO N GPU E QUINDI VOGLIO LA MEDIA DI OGNI LOSS RITORNATA DA OGNI GPU\n",
        "        N = N +  1\n",
        "\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(\"   Loss validation batch \",str(num_batch),\": \",loss_i)\n",
        "        #se ho superato il numero massimo di batch per il validation, esco\n",
        "        if num_batch >= max_batch_for_validation:\n",
        "            break\n",
        "        else:\n",
        "            num_batch = num_batch + 1\n",
        "\n",
        "        del loss_i\n",
        "\n",
        "      validation_loss = validation_loss/N\n",
        "      print(\"   Loss media validation: \",str(validation_loss))\n",
        "\n",
        "      #se tale modello ha una loss migliore di quella attualmente migliore..\n",
        "      if validation_loss < best_validation_loss:\n",
        "        patience = 0\n",
        "        best_validation_loss = validation_loss\n",
        "        print(\"   la loss risulta essere migliore\")\n",
        "        torch.save(model.state_dict(), path_to_model)\n",
        "        #campiono e salvo\n",
        "        sample_and_save(model, epoch, input_shape_image)\n",
        "      else:\n",
        "        print(\"   patience= \"+ str(patience+1))\n",
        "        patience = patience + 1\n",
        "\n",
        "      if patience > max_patience:\n",
        "        print(\"\")\n",
        "        print(\"Patience massimo superato. Fine del training\")\n",
        "        break\n",
        "\n",
        "      del validation_loss\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "\n",
        "    train_model_on_given_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBa71JKDVSPN",
        "outputId": "efe52bdc-98d2-4685-c860-44af82f256a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device utilizzato: cuda\n",
            "Numero di GPU disponibili: 1\n",
            "Memoria GPU prima della creazione del modello: 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memoria GPU dopo la creazione del modello: 1509376\n",
            "Numero parametri modello:  236496410\n",
            "Epoca 0 _____________________________________________________________________\n",
            "   Loss batch:  1 :  tensor(12859.8545, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9603 GB\n",
            "   Loss batch:  2 :  tensor(12774.9834, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9572 GB\n",
            "   Loss batch:  3 :  tensor(13021.9512, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9585 GB\n",
            "   Loss batch:  4 :  tensor(13120.5312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9575 GB\n",
            "   Loss batch:  5 :  tensor(12795.3604, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9583 GB\n",
            "   Loss batch:  6 :  tensor(12805.7354, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9576 GB\n",
            "   Loss batch:  7 :  tensor(12952.6719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9583 GB\n",
            "   Loss batch:  8 :  tensor(12866.8789, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9577 GB\n",
            "   Loss batch:  9 :  tensor(12108.0850, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9586 GB\n",
            "   Loss batch:  10 :  tensor(12795.4980, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9584 GB\n",
            "   Loss batch:  11 :  tensor(12564.0371, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  12 :  tensor(12612.7188, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  13 :  tensor(12420.7939, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  14 :  tensor(12510.8799, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  15 :  tensor(12425.5664, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  16 :  tensor(12414.8047, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  17 :  tensor(12504.4414, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  18 :  tensor(12188.6904, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  19 :  tensor(12422.9561, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  20 :  tensor(12226.8545, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  21 :  tensor(12291.8643, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  22 :  tensor(12361.5430, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  23 :  tensor(12220.8311, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  24 :  tensor(12065.4326, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  25 :  tensor(12131.4414, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  26 :  tensor(12177.8125, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  27 :  tensor(12124.6650, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  28 :  tensor(12027.0762, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  29 :  tensor(11990.1279, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  30 :  tensor(12269.7656, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  31 :  tensor(11999.6367, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  32 :  tensor(12092.4648, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  33 :  tensor(11892.0859, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  34 :  tensor(11741.3555, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  35 :  tensor(12030.1777, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  36 :  tensor(12043.0303, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  37 :  tensor(11825.3506, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  38 :  tensor(11801.0703, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  39 :  tensor(11784.8633, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  40 :  tensor(11988.0811, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  41 :  tensor(11734.0996, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  42 :  tensor(11897.4395, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  43 :  tensor(11665.4238, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  44 :  tensor(11775.3389, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  45 :  tensor(11843.4922, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  46 :  tensor(11703.1162, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  47 :  tensor(11876.9023, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  48 :  tensor(11614.6191, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  49 :  tensor(11697.1426, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  50 :  tensor(11737.8750, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  51 :  tensor(11636.2549, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  52 :  tensor(11806.6865, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  53 :  tensor(11773.1982, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  54 :  tensor(11672.2012, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  55 :  tensor(11495.2256, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  56 :  tensor(11751.1787, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  57 :  tensor(11696.7295, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  58 :  tensor(11407.0254, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  59 :  tensor(11564.2266, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  60 :  tensor(11885.8359, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  61 :  tensor(11497.2354, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  62 :  tensor(11636.9902, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  63 :  tensor(11354.5488, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  64 :  tensor(11597.1680, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  65 :  tensor(11476.2773, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  66 :  tensor(11678.6543, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  67 :  tensor(11280.0605, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  68 :  tensor(11732.7129, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  69 :  tensor(11519.4453, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  70 :  tensor(11471.0205, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  71 :  tensor(11620.4004, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  72 :  tensor(11573.3613, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  73 :  tensor(11318.1895, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  74 :  tensor(11247.8936, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  75 :  tensor(11462.2432, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  76 :  tensor(11142.0098, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  77 :  tensor(11569.3213, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  78 :  tensor(11684.3271, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  79 :  tensor(11225.5879, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  80 :  tensor(11312.7930, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  81 :  tensor(11579.6309, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  82 :  tensor(11266.6094, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  83 :  tensor(11444.1582, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  84 :  tensor(11194.4082, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  85 :  tensor(11614.0332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  86 :  tensor(11669.8770, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  87 :  tensor(11261.0723, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  88 :  tensor(11408.1016, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  89 :  tensor(11384.5859, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  90 :  tensor(11589.7900, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  91 :  tensor(11457.2363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  92 :  tensor(11318.3926, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  93 :  tensor(11439.8242, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  94 :  tensor(11239.3408, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  95 :  tensor(11392.2598, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  96 :  tensor(11211.7188, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  97 :  tensor(11372.8945, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  98 :  tensor(11191.0752, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  99 :  tensor(11459.1191, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  100 :  tensor(11552.6797, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  101 :  tensor(11632.1953, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  102 :  tensor(11637.9531, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  103 :  tensor(11250.5635, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  104 :  tensor(11259.9746, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  105 :  tensor(11389.3809, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  106 :  tensor(11485.5039, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  107 :  tensor(11351.7480, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  108 :  tensor(11254.0312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  109 :  tensor(11478.6035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  110 :  tensor(11169.4082, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  111 :  tensor(11047.7090, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  112 :  tensor(11227.2715, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  113 :  tensor(11675.0547, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  114 :  tensor(11380.1631, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  115 :  tensor(11183.2764, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  116 :  tensor(11013.9941, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  117 :  tensor(11119.7090, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  118 :  tensor(11080.1250, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  119 :  tensor(11136.9395, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  120 :  tensor(11012.9229, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  121 :  tensor(11214.0322, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  122 :  tensor(11179.4131, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  123 :  tensor(11305.3418, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  124 :  tensor(11249.6250, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  125 :  tensor(11301.3682, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  126 :  tensor(11295.4102, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  127 :  tensor(11097.7373, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  128 :  tensor(10979.2686, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  129 :  tensor(11014.1680, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  130 :  tensor(11247.8896, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  131 :  tensor(11191.6699, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  132 :  tensor(11039.0479, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  133 :  tensor(11322.1074, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  134 :  tensor(10987.6211, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  135 :  tensor(11220.2676, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  136 :  tensor(11215.3320, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  137 :  tensor(11043.7041, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  138 :  tensor(10950.8447, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  139 :  tensor(10908.5029, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  140 :  tensor(11253.4893, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  141 :  tensor(11004.9033, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  142 :  tensor(11278.0918, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  143 :  tensor(11225.4727, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  144 :  tensor(11260.9414, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  145 :  tensor(11463.5479, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  146 :  tensor(11096.5566, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  147 :  tensor(11188.3848, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  148 :  tensor(11449.7031, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  149 :  tensor(11223.6523, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  150 :  tensor(10863.0410, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  151 :  tensor(11102.6641, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  152 :  tensor(11378.0332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  153 :  tensor(11412.6777, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  154 :  tensor(11431.1670, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  155 :  tensor(10959.9492, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  156 :  tensor(11267.0625, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  157 :  tensor(11027.9033, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  158 :  tensor(11398.2324, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  159 :  tensor(11347.0088, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  160 :  tensor(10922.7471, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  161 :  tensor(11079.9336, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  162 :  tensor(11203.1016, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  163 :  tensor(11069.8613, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  164 :  tensor(11040.1797, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  165 :  tensor(11039.9883, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  166 :  tensor(11429.2363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  167 :  tensor(11201.3418, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  168 :  tensor(11119.2578, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  169 :  tensor(11321.1260, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  170 :  tensor(11150.7979, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  171 :  tensor(11058.3848, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  172 :  tensor(11021.2539, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  173 :  tensor(10773.8418, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  174 :  tensor(10887.0684, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  175 :  tensor(11180.1875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  176 :  tensor(10816.2930, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  177 :  tensor(11178.1953, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  178 :  tensor(11107.0342, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  179 :  tensor(11417.3477, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  180 :  tensor(10893.2617, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  181 :  tensor(10987.7480, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  182 :  tensor(11328.7871, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  183 :  tensor(10554.6172, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  184 :  tensor(11019.5566, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  185 :  tensor(11270.3730, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  186 :  tensor(11188.5771, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  187 :  tensor(11230.2051, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  188 :  tensor(11001.6084, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  189 :  tensor(10783.0732, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  190 :  tensor(10885.0205, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  191 :  tensor(10871.4570, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  192 :  tensor(10832.8379, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  193 :  tensor(10889.7803, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  194 :  tensor(10840.5166, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  195 :  tensor(11239.8223, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  196 :  tensor(11158.3379, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  197 :  tensor(10868.7881, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  198 :  tensor(11026.2148, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  199 :  tensor(11080.6152, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  200 :  tensor(11028.8955, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  201 :  tensor(10770.1934, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  202 :  tensor(11075.6289, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  203 :  tensor(10880.1602, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  204 :  tensor(10770.4170, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  205 :  tensor(11038.7783, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  206 :  tensor(10876.5625, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  207 :  tensor(10928.4922, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  208 :  tensor(11210.5703, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  209 :  tensor(11057.5703, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  210 :  tensor(10651.9209, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  211 :  tensor(10595.4609, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  212 :  tensor(11088.7402, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  213 :  tensor(10823.7061, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  214 :  tensor(10859.7861, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  215 :  tensor(10756.0078, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  216 :  tensor(11240.3545, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  217 :  tensor(10858.7930, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  218 :  tensor(10690.3096, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  219 :  tensor(10836.7100, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  220 :  tensor(10919.0117, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  221 :  tensor(11052.6113, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  222 :  tensor(10738.5391, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  223 :  tensor(10959.0791, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  224 :  tensor(10646.3691, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  225 :  tensor(10857.1797, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  226 :  tensor(10915.2275, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  227 :  tensor(10913.8750, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  228 :  tensor(10950.6504, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  229 :  tensor(10747.9062, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  230 :  tensor(10834.2158, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  231 :  tensor(11218.6553, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  232 :  tensor(10875.8418, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  233 :  tensor(10949.8965, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  234 :  tensor(10889.1445, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  235 :  tensor(10542.4014, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  236 :  tensor(10887.3369, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  237 :  tensor(10698.0996, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  238 :  tensor(10542.7842, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  239 :  tensor(10599.6035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  240 :  tensor(10654.1309, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  241 :  tensor(10715.3965, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  242 :  tensor(10667.6875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  243 :  tensor(10666.8496, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  244 :  tensor(10792.5000, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  245 :  tensor(10836.1660, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  246 :  tensor(10869.4238, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  247 :  tensor(11143.6484, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  248 :  tensor(11087.8984, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  249 :  tensor(10846.8799, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  250 :  tensor(10969.8496, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  251 :  tensor(10718.6152, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  252 :  tensor(11350.3428, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  253 :  tensor(10862.3184, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  254 :  tensor(10687.0059, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  255 :  tensor(10808.9326, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  256 :  tensor(11227.8682, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  257 :  tensor(10825.3965, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  258 :  tensor(10921.6123, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  259 :  tensor(10993.2598, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  260 :  tensor(10615.8525, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  261 :  tensor(10798.8184, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  262 :  tensor(10526.1738, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  263 :  tensor(10882.5674, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  264 :  tensor(11010.7861, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  265 :  tensor(10632.9980, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  266 :  tensor(11265.5039, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  267 :  tensor(10881.3828, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  268 :  tensor(10991.4199, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  269 :  tensor(10674.2988, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  270 :  tensor(10528.1562, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  271 :  tensor(10734.8887, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  272 :  tensor(10941.4326, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  273 :  tensor(10774.5195, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  274 :  tensor(10894.8301, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  275 :  tensor(10840.5117, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  276 :  tensor(10591.0723, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  277 :  tensor(10853.5596, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  278 :  tensor(10851.7197, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  279 :  tensor(10734.9766, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  280 :  tensor(10812.4473, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  281 :  tensor(10658.4902, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  282 :  tensor(10637.9609, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  283 :  tensor(10619.5635, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  284 :  tensor(10568.8242, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  285 :  tensor(10518.1885, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  286 :  tensor(10745.4609, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  287 :  tensor(10628.7666, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  288 :  tensor(10158.0977, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  289 :  tensor(10642.4629, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  290 :  tensor(10481.1113, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  291 :  tensor(10531.8848, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  292 :  tensor(10584.1660, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  293 :  tensor(10394.4033, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  294 :  tensor(10683.5898, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  295 :  tensor(10422.5234, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  296 :  tensor(10403.4004, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  297 :  tensor(10428.2822, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  298 :  tensor(10972.4102, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  299 :  tensor(11213.5967, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  300 :  tensor(10923.9824, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  301 :  tensor(10808.1953, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  302 :  tensor(10983.2285, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  303 :  tensor(10756.3828, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  304 :  tensor(10930.5732, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  305 :  tensor(10840.5547, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  306 :  tensor(10560.1035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  307 :  tensor(10842.6133, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  308 :  tensor(10762.1816, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  309 :  tensor(10903.2773, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  310 :  tensor(10499.6553, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  311 :  tensor(10790.4385, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  312 :  tensor(10796.5703, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  313 :  tensor(10670.7559, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  314 :  tensor(10542.4424, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  315 :  tensor(10552.7568, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  316 :  tensor(10423.3242, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  317 :  tensor(10762.6953, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  318 :  tensor(10429.6445, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  319 :  tensor(10708.9961, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  320 :  tensor(10487.5068, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  321 :  tensor(10345.2744, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  322 :  tensor(10688.7314, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  323 :  tensor(11087.9326, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  324 :  tensor(10549.0996, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  325 :  tensor(10610.6963, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  326 :  tensor(11075.5059, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  327 :  tensor(10575.0830, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  328 :  tensor(10617.9043, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  329 :  tensor(10661.9561, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  330 :  tensor(10534.8984, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  331 :  tensor(10557.6885, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  332 :  tensor(10321.3389, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  333 :  tensor(10497.3848, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  334 :  tensor(10261.9922, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  335 :  tensor(11075.6279, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  336 :  tensor(10610.6621, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  337 :  tensor(10325.6885, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  338 :  tensor(10501.1514, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  339 :  tensor(10735.5078, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  340 :  tensor(10693.4189, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  341 :  tensor(11051.2979, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  342 :  tensor(10749.5312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  343 :  tensor(10710.6953, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  344 :  tensor(10221.1738, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  345 :  tensor(10437.6035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  346 :  tensor(10621.3291, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  347 :  tensor(10712.4180, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  348 :  tensor(10574.8740, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  349 :  tensor(10247.2383, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  350 :  tensor(10469.5059, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  351 :  tensor(10480.6133, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  352 :  tensor(10603.5020, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  353 :  tensor(10439.7783, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  354 :  tensor(10730.6191, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  355 :  tensor(10559.8760, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  356 :  tensor(10784.3008, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  357 :  tensor(10448.7354, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  358 :  tensor(10337.3457, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  359 :  tensor(10501.8643, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  360 :  tensor(10353.0166, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  361 :  tensor(10435.4678, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  362 :  tensor(10405.7100, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  363 :  tensor(10731.0898, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  364 :  tensor(10837.5117, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  365 :  tensor(10429.3105, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  366 :  tensor(10433.6484, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  367 :  tensor(10185.2539, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  368 :  tensor(10349.4873, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  369 :  tensor(10428.0605, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  370 :  tensor(10566.7490, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  371 :  tensor(10602.5488, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  372 :  tensor(10368.4277, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  373 :  tensor(10419.9062, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  374 :  tensor(10258.6992, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  375 :  tensor(10551.9434, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  376 :  tensor(10719.8242, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  377 :  tensor(10487.6963, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  378 :  tensor(10213.7910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  379 :  tensor(10574.7305, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  380 :  tensor(10291.0156, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  381 :  tensor(10563.1895, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  382 :  tensor(10563.6436, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  383 :  tensor(10392.1523, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  384 :  tensor(10617.0820, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  385 :  tensor(10806.1250, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  386 :  tensor(10411.4277, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  387 :  tensor(10727.7783, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  388 :  tensor(10768.1211, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  389 :  tensor(10382.3164, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  390 :  tensor(10999.0312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  391 :  tensor(10625.4854, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  392 :  tensor(10469.9414, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  393 :  tensor(10352.7930, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  394 :  tensor(10659.7285, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  395 :  tensor(10619.2490, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  396 :  tensor(10432.9727, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  397 :  tensor(10430.1406, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  398 :  tensor(10573.8965, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  399 :  tensor(10243.7930, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  400 :  tensor(10362.4883, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  401 :  tensor(10451.8789, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  402 :  tensor(10460.1660, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  403 :  tensor(10659.7764, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  404 :  tensor(10238.0957, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  405 :  tensor(10529.0371, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  406 :  tensor(10443.6719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  407 :  tensor(10448.3242, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  408 :  tensor(9981.8320, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  409 :  tensor(10474.4316, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  410 :  tensor(10396.2617, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  411 :  tensor(10548.9746, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  412 :  tensor(10514.1465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  413 :  tensor(10456.8867, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  414 :  tensor(10455.7754, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  415 :  tensor(10043.1094, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  416 :  tensor(10299.2793, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  417 :  tensor(10193.7764, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  418 :  tensor(10822.0713, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  419 :  tensor(10397.1211, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  420 :  tensor(10281.0225, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  421 :  tensor(10627.1074, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  422 :  tensor(10575.7930, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  423 :  tensor(10534.7783, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  424 :  tensor(10720.2246, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  425 :  tensor(10553.3320, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  426 :  tensor(10072.9453, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  427 :  tensor(10604.0469, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  428 :  tensor(10332.8320, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  429 :  tensor(10425.8975, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  430 :  tensor(10406.9219, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  431 :  tensor(10304.3301, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  432 :  tensor(10105.8047, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  433 :  tensor(10535.2773, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  434 :  tensor(10172.8984, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  435 :  tensor(9854.7637, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  436 :  tensor(10550.6611, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  437 :  tensor(10450.1875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  438 :  tensor(10832.3799, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  439 :  tensor(10526.5098, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  440 :  tensor(10082.1895, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  441 :  tensor(10409.1914, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  442 :  tensor(10376.1670, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  443 :  tensor(10377.5020, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  444 :  tensor(10504.4189, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  445 :  tensor(10456.6855, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  446 :  tensor(10320.0020, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  447 :  tensor(10335.4824, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  448 :  tensor(10492.9297, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  449 :  tensor(10373.6152, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  450 :  tensor(9986.9590, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  451 :  tensor(10238.8926, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  452 :  tensor(10075.5195, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  453 :  tensor(10507.9697, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  454 :  tensor(10397.4570, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  455 :  tensor(10751.4512, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  456 :  tensor(10006.3682, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  457 :  tensor(10381.7451, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  458 :  tensor(10507.8438, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  459 :  tensor(10859.6494, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  460 :  tensor(10308.0303, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  461 :  tensor(9985.7676, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  462 :  tensor(10043.2402, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  463 :  tensor(10200.3848, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  464 :  tensor(10236.0566, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  465 :  tensor(10447.9141, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  466 :  tensor(10364.9395, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  467 :  tensor(10017.2617, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  468 :  tensor(9978.7227, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  469 :  tensor(10381.0967, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  470 :  tensor(10351.3193, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  471 :  tensor(10583.6660, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  472 :  tensor(10410.9111, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  473 :  tensor(10238.7373, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  474 :  tensor(10258.5391, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  475 :  tensor(10548.4668, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  476 :  tensor(10173.6719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  477 :  tensor(10231.0420, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  478 :  tensor(10097.2676, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  479 :  tensor(10065.4590, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  480 :  tensor(10426.1699, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  481 :  tensor(10488.1055, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  482 :  tensor(10485.2266, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  483 :  tensor(10299.4258, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  484 :  tensor(10428.1426, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  485 :  tensor(10279.5986, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  486 :  tensor(10364.9775, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  487 :  tensor(9931.3389, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  488 :  tensor(10267.7148, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  489 :  tensor(10334.9268, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  490 :  tensor(10552.0020, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  491 :  tensor(10539.9941, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  492 :  tensor(10534.5039, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  493 :  tensor(10105.2559, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  494 :  tensor(10445.7119, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  495 :  tensor(10480.6211, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  496 :  tensor(10236.4043, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  497 :  tensor(10230.5752, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  498 :  tensor(9984.7607, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  499 :  tensor(10274.8057, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  500 :  tensor(10071.4229, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  501 :  tensor(10681.0723, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  502 :  tensor(10188.2656, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  503 :  tensor(10132.9971, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  504 :  tensor(10150.4121, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  505 :  tensor(10075.0508, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  506 :  tensor(9995.2461, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  507 :  tensor(10094.2520, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  508 :  tensor(10479.0430, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  509 :  tensor(10055.6230, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  510 :  tensor(10154.3291, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  511 :  tensor(10454.8164, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  512 :  tensor(10388.6553, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  513 :  tensor(10450.0752, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  514 :  tensor(10351.1895, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  515 :  tensor(10193.3379, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  516 :  tensor(10448.1758, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  517 :  tensor(10195.2383, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  518 :  tensor(10151.4434, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  519 :  tensor(10386.1758, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  520 :  tensor(10066.1055, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  521 :  tensor(10337.5732, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  522 :  tensor(10405.4805, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  523 :  tensor(10140.7266, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  524 :  tensor(10237.1523, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  525 :  tensor(10036.6602, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  526 :  tensor(10477.5586, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  527 :  tensor(10459.9473, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  528 :  tensor(10144.0625, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  529 :  tensor(10721.4541, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  530 :  tensor(10284.6816, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  531 :  tensor(10115.6055, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  532 :  tensor(10082.3496, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  533 :  tensor(9923.2734, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  534 :  tensor(10474.4121, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  535 :  tensor(10593.6875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  536 :  tensor(10514.1152, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  537 :  tensor(10222.2920, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  538 :  tensor(10486.9668, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  539 :  tensor(10022.1406, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  540 :  tensor(10295.2012, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  541 :  tensor(10089.5127, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  542 :  tensor(10408.2520, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  543 :  tensor(10077.7324, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  544 :  tensor(10219.4531, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  545 :  tensor(10260.3037, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  546 :  tensor(10212.8691, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  547 :  tensor(10349.0273, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  548 :  tensor(10335.5996, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  549 :  tensor(10115.6846, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  550 :  tensor(10375.3184, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  551 :  tensor(10320.6934, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  552 :  tensor(10166.2031, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  553 :  tensor(10343.4209, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  554 :  tensor(10297.0010, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  555 :  tensor(10010.4023, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  556 :  tensor(10286.6602, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  557 :  tensor(10128.8594, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  558 :  tensor(9868.5400, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  559 :  tensor(10152.0762, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  560 :  tensor(10326.3418, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  561 :  tensor(10211.9697, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  562 :  tensor(10044.2949, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  563 :  tensor(10464.1309, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  564 :  tensor(10226.7715, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  565 :  tensor(9927.4736, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  566 :  tensor(10046.6328, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  567 :  tensor(10133.2793, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  568 :  tensor(10091.3242, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  569 :  tensor(9860.1387, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  570 :  tensor(10344.8672, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  571 :  tensor(9728.2832, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  572 :  tensor(10093.3799, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  573 :  tensor(10014.7012, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  574 :  tensor(10203.8848, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  575 :  tensor(9885.3496, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  576 :  tensor(10302.5098, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  577 :  tensor(10627.3965, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  578 :  tensor(9995.5234, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  579 :  tensor(10237.7910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  580 :  tensor(10193.9844, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  581 :  tensor(10203.1406, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  582 :  tensor(9823.9824, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  583 :  tensor(10355.9727, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  584 :  tensor(10423.5137, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  585 :  tensor(10116.1953, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  586 :  tensor(10158.6348, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  587 :  tensor(10164.2988, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  588 :  tensor(10496.2656, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  589 :  tensor(10174.0215, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  590 :  tensor(10293.7773, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  591 :  tensor(10088.7910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  592 :  tensor(9775.6162, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  593 :  tensor(10412.3369, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  594 :  tensor(10145.4111, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  595 :  tensor(10156.9316, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  596 :  tensor(9722.5234, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  597 :  tensor(9819.8516, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  598 :  tensor(10143.3633, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  599 :  tensor(10164.1406, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  600 :  tensor(10233.8438, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  601 :  tensor(10145.8809, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  602 :  tensor(9871.7012, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  603 :  tensor(9935.0566, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  604 :  tensor(9886.1836, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  605 :  tensor(9894.2451, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  606 :  tensor(9899.3438, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  607 :  tensor(10131.7314, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  608 :  tensor(10149.7910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  609 :  tensor(9915.8271, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  610 :  tensor(9893.1465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  611 :  tensor(9835.6172, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  612 :  tensor(9741.6973, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  613 :  tensor(10312.6846, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  614 :  tensor(9902.1797, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  615 :  tensor(10353.2539, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  616 :  tensor(10064.7520, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  617 :  tensor(9943.4258, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  618 :  tensor(10028.3770, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  619 :  tensor(10041.7617, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  620 :  tensor(10437.2109, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  621 :  tensor(10249.3867, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  622 :  tensor(9962.9180, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  623 :  tensor(9992.4258, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  624 :  tensor(9882.8037, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  625 :  tensor(9816.0195, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  626 :  tensor(10040.8203, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  627 :  tensor(9800.8037, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  628 :  tensor(9976.9502, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  629 :  tensor(9998.4941, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  630 :  tensor(9882.7031, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  631 :  tensor(9971.3643, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  632 :  tensor(10206.5850, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  633 :  tensor(9946.1953, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  634 :  tensor(10328.2041, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  635 :  tensor(10038.4365, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  636 :  tensor(10137.7598, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  637 :  tensor(10066.8184, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  638 :  tensor(9796.7715, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  639 :  tensor(9661.0078, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  640 :  tensor(10405.1641, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  641 :  tensor(9860.1875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  642 :  tensor(9974.7344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  643 :  tensor(9413.7012, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  644 :  tensor(10084.2080, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  645 :  tensor(9840.3789, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  646 :  tensor(9949.0439, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  647 :  tensor(10136.0312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  648 :  tensor(9982.9658, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  649 :  tensor(9928.6875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  650 :  tensor(10031.2617, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  651 :  tensor(10278.8145, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  652 :  tensor(9779.4775, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  653 :  tensor(9792.3672, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  654 :  tensor(10065.9961, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  655 :  tensor(9975.2402, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  656 :  tensor(9788.4160, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  657 :  tensor(10204.7793, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  658 :  tensor(10022.6230, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  659 :  tensor(10168.1562, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  660 :  tensor(9813.8350, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  661 :  tensor(9787.4443, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  662 :  tensor(9588.1572, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  663 :  tensor(10384.3447, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  664 :  tensor(9929.5977, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  665 :  tensor(9871.2510, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  666 :  tensor(9988.5352, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  667 :  tensor(9949.7832, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  668 :  tensor(9801.8135, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  669 :  tensor(9868.2344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  670 :  tensor(9635.2930, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  671 :  tensor(9962.7500, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  672 :  tensor(9890.1074, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  673 :  tensor(9876.1572, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  674 :  tensor(10098.1670, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  675 :  tensor(9783.4082, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  676 :  tensor(9814.2568, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  677 :  tensor(9791.9443, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  678 :  tensor(9965.8457, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  679 :  tensor(9590.0332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  680 :  tensor(9995.6953, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  681 :  tensor(9936.9766, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  682 :  tensor(10271.9209, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  683 :  tensor(9804.9062, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  684 :  tensor(9948.5156, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  685 :  tensor(9708.9814, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  686 :  tensor(9899.2715, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  687 :  tensor(9733.5469, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  688 :  tensor(9577.1348, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  689 :  tensor(9992.0830, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  690 :  tensor(9911.5938, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  691 :  tensor(9825.2188, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  692 :  tensor(9805.7227, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  693 :  tensor(10230.2480, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  694 :  tensor(9982.2051, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  695 :  tensor(9598.2559, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  696 :  tensor(10034.9707, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  697 :  tensor(9928.4922, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  698 :  tensor(10331.3271, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  699 :  tensor(10253.4209, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  700 :  tensor(9636.1846, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  701 :  tensor(9781.1865, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  702 :  tensor(9812.7441, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  703 :  tensor(9739.7832, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  704 :  tensor(10020.7773, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  705 :  tensor(9623.7363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  706 :  tensor(9895.8467, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  707 :  tensor(10017.3506, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  708 :  tensor(10142.3682, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  709 :  tensor(9949.9531, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  710 :  tensor(9767.3984, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  711 :  tensor(9997.7344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  712 :  tensor(9694.7500, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  713 :  tensor(9903.9746, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  714 :  tensor(10065.7686, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  715 :  tensor(9881.9160, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  716 :  tensor(9707.3545, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  717 :  tensor(9923.1650, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  718 :  tensor(9994.1836, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  719 :  tensor(10055.0518, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  720 :  tensor(9772.9570, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  721 :  tensor(10256.0332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  722 :  tensor(9952.1514, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  723 :  tensor(9565.2637, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  724 :  tensor(10349.7148, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  725 :  tensor(9827.7910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  726 :  tensor(10038.1426, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  727 :  tensor(9635.0195, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  728 :  tensor(10119.8525, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  729 :  tensor(10280.2227, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  730 :  tensor(9982.1006, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  731 :  tensor(10055.7363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  732 :  tensor(10062.1484, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  733 :  tensor(10095.9590, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  734 :  tensor(10124.1846, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  735 :  tensor(10044.8828, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  736 :  tensor(10026.0195, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  737 :  tensor(9935.0293, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  738 :  tensor(9862.8965, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  739 :  tensor(9753.7559, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  740 :  tensor(10091.7070, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  741 :  tensor(9865.3525, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  742 :  tensor(9992.0996, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  743 :  tensor(9977.0156, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  744 :  tensor(9533.0449, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  745 :  tensor(9956.7246, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  746 :  tensor(9397.1035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  747 :  tensor(10191.2002, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  748 :  tensor(10032.0527, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  749 :  tensor(10196.7832, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  750 :  tensor(9816.6250, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  751 :  tensor(9993.0176, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  752 :  tensor(9785.3096, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  753 :  tensor(9732.9951, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  754 :  tensor(9839.6387, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  755 :  tensor(9841.0107, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  756 :  tensor(9785.1934, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  757 :  tensor(9656.0449, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  758 :  tensor(10011.8633, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  759 :  tensor(9693.5645, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  760 :  tensor(9871.8848, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  761 :  tensor(9837.5938, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  762 :  tensor(10074.5000, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  763 :  tensor(9953.8662, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  764 :  tensor(9788.2949, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  765 :  tensor(9743.1475, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  766 :  tensor(9801.2520, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  767 :  tensor(10095.6445, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  768 :  tensor(9986.2656, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  769 :  tensor(9573.3887, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  770 :  tensor(10115.6006, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  771 :  tensor(10058.7910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  772 :  tensor(9841.1172, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  773 :  tensor(9854.6680, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  774 :  tensor(9829.2988, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  775 :  tensor(9733.9766, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  776 :  tensor(9848.1406, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  777 :  tensor(9528.6016, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  778 :  tensor(9602.1777, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  779 :  tensor(10170.6914, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  780 :  tensor(9957.8691, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  781 :  tensor(9991.7529, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  782 :  tensor(9759.2559, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  783 :  tensor(9565.1504, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  784 :  tensor(10079.5742, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  785 :  tensor(9889.8555, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  786 :  tensor(9953.8652, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  787 :  tensor(9771.0068, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  788 :  tensor(9911.6836, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  789 :  tensor(10056.2539, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  790 :  tensor(10274.6367, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  791 :  tensor(9967.9131, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  792 :  tensor(10196.1104, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  793 :  tensor(10032.0420, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  794 :  tensor(9930.1523, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  795 :  tensor(10144.2852, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  796 :  tensor(10296.6270, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  797 :  tensor(9882.0361, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  798 :  tensor(9888.7480, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   Loss batch:  799 :  tensor(9958.7188, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9578 GB\n",
            "   Loss batch:  800 :  tensor(9814.8467, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  2.9581 GB\n",
            "   ___________________________\n",
            "   Loss validation batch  1 :  tensor(9858.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  2 :  tensor(9955.1455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  3 :  tensor(9912.8691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  4 :  tensor(10081.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  5 :  tensor(10098.2520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  6 :  tensor(9925.5811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  7 :  tensor(9809.7656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  8 :  tensor(9943.2109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  9 :  tensor(9947.0352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  10 :  tensor(9954.5684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  11 :  tensor(9820.6084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  12 :  tensor(9686.5391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  13 :  tensor(9716.2676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  14 :  tensor(9920.4707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  15 :  tensor(9650.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  16 :  tensor(9504.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  17 :  tensor(10086.8320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  18 :  tensor(9718.6279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  19 :  tensor(9877.8740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  20 :  tensor(9785.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  21 :  tensor(9547.3672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  22 :  tensor(9905.5664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  23 :  tensor(9691.2012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  24 :  tensor(10099.6768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  25 :  tensor(9728.6562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  26 :  tensor(10040.6895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  27 :  tensor(9712.9746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  28 :  tensor(10124.5225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  29 :  tensor(9965.6943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  30 :  tensor(10002.0508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  31 :  tensor(9980.9707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  32 :  tensor(9918.5918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  33 :  tensor(9650.9121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  34 :  tensor(9667.4609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  35 :  tensor(9982.7793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  36 :  tensor(9872.7275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  37 :  tensor(10181.0137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  38 :  tensor(9892.2744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  39 :  tensor(9657.4932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  40 :  tensor(10046.2529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  41 :  tensor(9643.1270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  42 :  tensor(10031.4492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  43 :  tensor(10067.2520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  44 :  tensor(9737.9023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  45 :  tensor(10019.5518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  46 :  tensor(9905.7988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  47 :  tensor(9976.7832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  48 :  tensor(9675.7734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  49 :  tensor(9992.3320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  50 :  tensor(10129.6982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  51 :  tensor(10080.6221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  52 :  tensor(10152.4219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  53 :  tensor(9802.7910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  54 :  tensor(10101.4414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  55 :  tensor(10022.9434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  56 :  tensor(9934.9121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  57 :  tensor(10138.0791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  58 :  tensor(9376.3574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  59 :  tensor(9963.1777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  60 :  tensor(10022.3984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  61 :  tensor(10060.9316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  62 :  tensor(9881.7910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  63 :  tensor(9904.8750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  64 :  tensor(9833.4609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  65 :  tensor(10240.9492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  66 :  tensor(9625.0527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  67 :  tensor(9685.9023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  68 :  tensor(9806.6182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  69 :  tensor(9960.7744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  70 :  tensor(9911.3799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  71 :  tensor(9873.2354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  72 :  tensor(9828.7383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  73 :  tensor(9831.7305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  74 :  tensor(9650.4619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  75 :  tensor(10016.2285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  76 :  tensor(9966.5703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  77 :  tensor(9924.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  78 :  tensor(10064.5840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  79 :  tensor(9504.9453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  80 :  tensor(10094.3262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  81 :  tensor(9914.7598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  82 :  tensor(10155.2070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  83 :  tensor(9871.5400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  84 :  tensor(9763.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  85 :  tensor(9735.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  86 :  tensor(10096.6602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  87 :  tensor(9806.7939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  88 :  tensor(9869.7383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  89 :  tensor(9983.5488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  90 :  tensor(9839.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  91 :  tensor(9805.8613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  92 :  tensor(9997.1709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  93 :  tensor(9973.8271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  94 :  tensor(9929.3945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  95 :  tensor(9967.4199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  96 :  tensor(9919.6221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  97 :  tensor(9927.2490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  98 :  tensor(10279.6123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  99 :  tensor(9597.0508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  100 :  tensor(9748.9951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  101 :  tensor(10014.1963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  102 :  tensor(10125.7969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  103 :  tensor(9785.8076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  104 :  tensor(9911.6504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  105 :  tensor(9933.6777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  106 :  tensor(9786.4863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  107 :  tensor(9792.9902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  108 :  tensor(9815.3652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  109 :  tensor(10039.4453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  110 :  tensor(9646.7705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  111 :  tensor(9756.2266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  112 :  tensor(9691.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  113 :  tensor(9737.2480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  114 :  tensor(9772.7012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  115 :  tensor(9884.2324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  116 :  tensor(9920.8164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  117 :  tensor(10049.2871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  118 :  tensor(9742.3574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  119 :  tensor(10030.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  120 :  tensor(9820.3115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  121 :  tensor(10330.4629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  122 :  tensor(9688.9883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  123 :  tensor(9927.3633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  124 :  tensor(9838.9189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  125 :  tensor(9695.7461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  126 :  tensor(9987.5176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  127 :  tensor(10060.2109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  128 :  tensor(10053.7031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  129 :  tensor(10031.2881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  130 :  tensor(9834.1113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  131 :  tensor(10005.8008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  132 :  tensor(9773.6055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  133 :  tensor(9861.5664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  134 :  tensor(9613.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  135 :  tensor(9967.9785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  136 :  tensor(10091.0957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  137 :  tensor(9880.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  138 :  tensor(10151.2051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  139 :  tensor(9919.7617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  140 :  tensor(10033.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  141 :  tensor(9841.0420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  142 :  tensor(10100.6221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  143 :  tensor(10170.1699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  144 :  tensor(9813.7383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  145 :  tensor(9855.3799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  146 :  tensor(9668.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  147 :  tensor(9884.5801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  148 :  tensor(9856.7051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  149 :  tensor(9987.8623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  150 :  tensor(9897.0098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  151 :  tensor(9941.9434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  152 :  tensor(10155.7324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  153 :  tensor(9869.6084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  154 :  tensor(9739.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  155 :  tensor(10000.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  156 :  tensor(10072.7686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  157 :  tensor(10278.4551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  158 :  tensor(10214.8262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  159 :  tensor(9681.9531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  160 :  tensor(9802.0332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  161 :  tensor(9920.4199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  162 :  tensor(9683.6328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  163 :  tensor(9695.6152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  164 :  tensor(10007.4551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  165 :  tensor(9784.9160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  166 :  tensor(10041.3545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  167 :  tensor(10005.0381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  168 :  tensor(9810.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  169 :  tensor(9913.0264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  170 :  tensor(9996.4219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss media validation:  9901.417365579044\n",
            "   la loss risulta essere migliore\n",
            "Epoca 1 _____________________________________________________________________\n",
            "   Loss batch:  1 :  tensor(10164.0195, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.06 GB\n",
            "   Loss batch:  2 :  tensor(9640.4346, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0608 GB\n",
            "   Loss batch:  3 :  tensor(10096.3330, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0601 GB\n",
            "   Loss batch:  4 :  tensor(10077.1680, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  5 :  tensor(9921.8115, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0598 GB\n",
            "   Loss batch:  6 :  tensor(10327.9893, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0616 GB\n",
            "   Loss batch:  7 :  tensor(10083.2949, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  8 :  tensor(9895.1221, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  9 :  tensor(10121.0312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  10 :  tensor(10068.9512, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  11 :  tensor(9789.7734, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  12 :  tensor(9740.6572, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  13 :  tensor(9662.8701, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  14 :  tensor(9660.4736, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  15 :  tensor(10164.3828, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  16 :  tensor(9749.4053, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  17 :  tensor(9963.5332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  18 :  tensor(9706.8867, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  19 :  tensor(10064.2764, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  20 :  tensor(9764.1748, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  21 :  tensor(9881.9893, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  22 :  tensor(9956.2852, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  23 :  tensor(9582.6055, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  24 :  tensor(9663.5859, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  25 :  tensor(9940.7441, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  26 :  tensor(9548.3232, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  27 :  tensor(9628.9668, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  28 :  tensor(9463.3389, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  29 :  tensor(9665.8008, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  30 :  tensor(10057.4336, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  31 :  tensor(9598.9277, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  32 :  tensor(10001.6660, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  33 :  tensor(9827.6709, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  34 :  tensor(9711.2441, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  35 :  tensor(9946.0986, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  36 :  tensor(10071.3867, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  37 :  tensor(9940.6904, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  38 :  tensor(9705.4961, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  39 :  tensor(9776.1719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  40 :  tensor(10066.1699, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  41 :  tensor(9734.2900, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  42 :  tensor(9876.5020, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  43 :  tensor(9517.2490, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  44 :  tensor(9743.5957, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  45 :  tensor(9828.2402, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  46 :  tensor(10004.3115, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  47 :  tensor(10189.3350, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  48 :  tensor(9659.3174, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  49 :  tensor(9814.4414, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  50 :  tensor(9851.3359, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  51 :  tensor(10227.7324, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  52 :  tensor(10062.9893, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  53 :  tensor(9951.1484, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  54 :  tensor(9735.7920, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  55 :  tensor(9638.6475, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  56 :  tensor(10065.4023, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  57 :  tensor(9824.4473, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  58 :  tensor(9781.0117, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  59 :  tensor(9707.8516, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  60 :  tensor(9942.6143, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  61 :  tensor(9821.5586, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  62 :  tensor(9942.8867, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  63 :  tensor(9750.5850, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  64 :  tensor(9802.4941, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  65 :  tensor(9699.0908, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  66 :  tensor(10060.0254, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  67 :  tensor(9404.8516, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  68 :  tensor(9996.9297, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  69 :  tensor(9683.6396, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  70 :  tensor(9723.4902, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  71 :  tensor(9733.4922, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  72 :  tensor(9718.0771, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  73 :  tensor(9699.5049, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  74 :  tensor(9435.6211, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  75 :  tensor(9616.8926, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  76 :  tensor(9395.7344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  77 :  tensor(9787.7891, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  78 :  tensor(9822.9150, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  79 :  tensor(9492.7461, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  80 :  tensor(9929.2773, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  81 :  tensor(9870.9912, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  82 :  tensor(9813.0576, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  83 :  tensor(9816.5332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  84 :  tensor(9704.6826, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  85 :  tensor(10141.2979, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  86 :  tensor(10287.4297, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  87 :  tensor(9676.1523, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  88 :  tensor(9732.4482, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  89 :  tensor(9780.3828, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  90 :  tensor(9666.5361, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  91 :  tensor(10004.6875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  92 :  tensor(10035.5176, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  93 :  tensor(9813.6719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  94 :  tensor(9818.8086, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  95 :  tensor(9886.9043, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  96 :  tensor(9946.8740, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  97 :  tensor(9670.0771, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  98 :  tensor(9461.0273, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  99 :  tensor(10082.8135, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  100 :  tensor(10001.6240, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  101 :  tensor(10296.4834, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  102 :  tensor(10463.6348, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  103 :  tensor(9463.1436, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  104 :  tensor(9586.8955, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  105 :  tensor(9659.0820, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  106 :  tensor(9709.8506, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  107 :  tensor(10008.1572, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  108 :  tensor(9602.4141, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  109 :  tensor(10031.0039, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  110 :  tensor(9517.3203, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  111 :  tensor(9412.9062, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  112 :  tensor(10000.9746, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  113 :  tensor(10434.5000, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  114 :  tensor(10106.5820, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  115 :  tensor(9869.3262, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  116 :  tensor(9392.2021, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  117 :  tensor(9743.6396, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  118 :  tensor(9637.5078, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  119 :  tensor(9657.1680, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  120 :  tensor(9564.2461, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  121 :  tensor(9746.6016, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  122 :  tensor(9775.0391, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  123 :  tensor(9913.3457, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  124 :  tensor(9761.9092, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  125 :  tensor(9910.1416, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  126 :  tensor(9857.2910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  127 :  tensor(9584.8809, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  128 :  tensor(9508.5059, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  129 :  tensor(9542.7246, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  130 :  tensor(9751.0098, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  131 :  tensor(9882.1660, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  132 :  tensor(9641.7490, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  133 :  tensor(9712.4785, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  134 :  tensor(9506.1016, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  135 :  tensor(9654.6387, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  136 :  tensor(9698.6562, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  137 :  tensor(9535.6104, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  138 :  tensor(9522.2969, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  139 :  tensor(9558.2949, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  140 :  tensor(9605.3760, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  141 :  tensor(9441.2910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  142 :  tensor(9805.3496, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  143 :  tensor(9438.0146, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  144 :  tensor(9889.1289, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  145 :  tensor(9924.8691, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  146 :  tensor(10032.1562, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  147 :  tensor(9711.3428, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  148 :  tensor(9947.5918, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  149 :  tensor(9818.2715, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  150 :  tensor(9382.1895, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  151 :  tensor(9518.1914, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  152 :  tensor(9926.9346, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  153 :  tensor(9816.2354, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  154 :  tensor(9715.8887, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  155 :  tensor(9653.3320, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  156 :  tensor(10007.2949, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  157 :  tensor(9568.4883, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  158 :  tensor(9752.7139, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  159 :  tensor(10103.1328, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  160 :  tensor(9562.3564, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  161 :  tensor(9632.3477, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  162 :  tensor(9723.0703, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  163 :  tensor(9600.4932, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  164 :  tensor(9557.2148, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  165 :  tensor(9745.4326, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  166 :  tensor(10035.0244, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  167 :  tensor(9730.0449, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  168 :  tensor(9749.1426, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  169 :  tensor(9780.4609, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  170 :  tensor(9926.3330, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  171 :  tensor(9714.6943, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  172 :  tensor(9716.7393, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  173 :  tensor(9530.2793, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  174 :  tensor(9375.6523, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  175 :  tensor(9819.2168, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  176 :  tensor(9340.0957, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  177 :  tensor(9652.0195, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  178 :  tensor(9637.5254, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  179 :  tensor(9909.4561, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  180 :  tensor(9527.5518, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  181 :  tensor(9651.2451, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  182 :  tensor(10031.3291, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  183 :  tensor(8932.9268, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  184 :  tensor(9383.6270, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  185 :  tensor(9889.1924, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  186 :  tensor(9627.5293, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  187 :  tensor(9864.8018, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  188 :  tensor(9711.7119, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  189 :  tensor(9528.0605, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  190 :  tensor(9694.1191, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  191 :  tensor(9503.1143, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  192 :  tensor(9639.0254, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  193 :  tensor(9463.9307, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  194 :  tensor(9594.4521, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  195 :  tensor(10089.1748, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  196 :  tensor(9941.7354, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  197 :  tensor(9603.1641, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  198 :  tensor(9550.6846, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  199 :  tensor(9850.1611, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  200 :  tensor(9585.7432, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  201 :  tensor(9392.9238, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  202 :  tensor(9863.7539, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  203 :  tensor(9672.4707, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  204 :  tensor(9452.8779, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  205 :  tensor(9784.2988, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  206 :  tensor(9748.8145, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  207 :  tensor(9669.7637, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  208 :  tensor(10220.3711, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  209 :  tensor(9844.8779, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  210 :  tensor(9264.8838, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  211 :  tensor(9356.2637, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  212 :  tensor(10039.1387, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  213 :  tensor(9620.5176, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  214 :  tensor(9482.0381, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  215 :  tensor(9377.0898, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  216 :  tensor(10136.5078, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  217 :  tensor(9663.7588, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  218 :  tensor(9499.4502, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  219 :  tensor(9664.1504, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  220 :  tensor(9768.5020, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  221 :  tensor(9729.0801, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  222 :  tensor(9465.5674, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  223 :  tensor(9682.6943, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  224 :  tensor(9473.3809, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  225 :  tensor(9907.0840, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  226 :  tensor(9765.4805, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  227 :  tensor(9557.1035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  228 :  tensor(9866.8428, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  229 :  tensor(9489.3008, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  230 :  tensor(9657.6885, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  231 :  tensor(9804.7197, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  232 :  tensor(9566.3984, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  233 :  tensor(9887.4980, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  234 :  tensor(9732.0898, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  235 :  tensor(9263.5527, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  236 :  tensor(9587.2529, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  237 :  tensor(9379.1807, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  238 :  tensor(9525.1475, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  239 :  tensor(9487.2227, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  240 :  tensor(9465.5498, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  241 :  tensor(9628.0137, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  242 :  tensor(9552.2207, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  243 :  tensor(9420.9121, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  244 :  tensor(9643.2412, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  245 :  tensor(9537.6621, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  246 :  tensor(9726.0918, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  247 :  tensor(9842.4453, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  248 :  tensor(9926.9912, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  249 :  tensor(9598.2939, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  250 :  tensor(9463.6006, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  251 :  tensor(9751.0742, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  252 :  tensor(10362.1416, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  253 :  tensor(9755.6211, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  254 :  tensor(9599.3135, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  255 :  tensor(9711.1543, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  256 :  tensor(10016.5625, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  257 :  tensor(9802.3730, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  258 :  tensor(9673.1719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  259 :  tensor(9768.5664, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  260 :  tensor(9377.2559, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  261 :  tensor(9764.8164, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  262 :  tensor(9437.5684, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  263 :  tensor(9750.2549, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  264 :  tensor(9913.9512, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  265 :  tensor(9588.2002, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  266 :  tensor(10037.8203, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  267 :  tensor(9828.9824, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  268 :  tensor(9840.7324, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  269 :  tensor(9788.1465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  270 :  tensor(9579.3867, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  271 :  tensor(9551.5283, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  272 :  tensor(9870.5586, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  273 :  tensor(9549.6787, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  274 :  tensor(9789.7148, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  275 :  tensor(9729.8662, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  276 :  tensor(9678.4277, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  277 :  tensor(10029.0283, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  278 :  tensor(9766.4980, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  279 :  tensor(9654.1943, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  280 :  tensor(9758.0137, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  281 :  tensor(9602.3232, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  282 :  tensor(9617.2422, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  283 :  tensor(9554.7881, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  284 :  tensor(9526.2676, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  285 :  tensor(9515.5801, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  286 :  tensor(9681.1846, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  287 :  tensor(9489.4492, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  288 :  tensor(9062.8311, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  289 :  tensor(9597.0166, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  290 :  tensor(9331.0488, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  291 :  tensor(9392.3867, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  292 :  tensor(9554.8652, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  293 :  tensor(9609.9727, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  294 :  tensor(9621.7305, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  295 :  tensor(9553.6816, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  296 :  tensor(9266.2383, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  297 :  tensor(9460.7578, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  298 :  tensor(9942.0332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  299 :  tensor(9955.1299, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  300 :  tensor(9851.8096, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  301 :  tensor(9885.5000, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  302 :  tensor(9943.2119, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  303 :  tensor(9870.1973, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  304 :  tensor(9924.9766, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  305 :  tensor(9870.0859, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  306 :  tensor(9522.7363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  307 :  tensor(9931.8301, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  308 :  tensor(9745.3301, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  309 :  tensor(9770.0469, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  310 :  tensor(9481.1592, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  311 :  tensor(9689.7090, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  312 :  tensor(9772.0918, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  313 :  tensor(9571.4043, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  314 :  tensor(9512.6787, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  315 :  tensor(9606.4922, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  316 :  tensor(9264.9434, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  317 :  tensor(9605.9414, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  318 :  tensor(9323.6543, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  319 :  tensor(9715.1582, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  320 :  tensor(9579.5391, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  321 :  tensor(9494.1562, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  322 :  tensor(9554.8447, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  323 :  tensor(10104.1719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  324 :  tensor(9541.1182, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  325 :  tensor(9460.2852, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  326 :  tensor(10087.3369, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  327 :  tensor(9481.5215, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  328 :  tensor(9699.0986, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  329 :  tensor(9669.7021, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  330 :  tensor(9620.2109, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  331 :  tensor(9481.7217, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  332 :  tensor(9199.1357, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  333 :  tensor(9550.5742, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  334 :  tensor(9326.1758, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  335 :  tensor(10030.5645, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  336 :  tensor(9753.0488, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  337 :  tensor(9479.9102, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  338 :  tensor(9506.6289, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  339 :  tensor(9746.2246, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  340 :  tensor(9678.9775, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  341 :  tensor(9852.9180, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  342 :  tensor(9996.2090, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  343 :  tensor(9650.3213, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  344 :  tensor(9302.4326, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  345 :  tensor(9530.8574, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  346 :  tensor(9528.0215, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  347 :  tensor(9782.6582, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  348 :  tensor(9689.4668, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  349 :  tensor(9243.1660, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  350 :  tensor(9565.8867, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  351 :  tensor(9445.5195, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  352 :  tensor(9751.6387, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  353 :  tensor(9470.4531, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  354 :  tensor(9746.0117, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  355 :  tensor(9719.1719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  356 :  tensor(9740.0469, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  357 :  tensor(9521.3516, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  358 :  tensor(9376.8047, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  359 :  tensor(9498.9443, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  360 :  tensor(9551.6357, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  361 :  tensor(9590.2676, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  362 :  tensor(9468.4043, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  363 :  tensor(9770.4883, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  364 :  tensor(9938.8691, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  365 :  tensor(9535.8066, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  366 :  tensor(9440.8076, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  367 :  tensor(9242.0898, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  368 :  tensor(9548.1133, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  369 :  tensor(9640.4482, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  370 :  tensor(9731.2559, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  371 :  tensor(9797.9551, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  372 :  tensor(9400.2148, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  373 :  tensor(9549.8418, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  374 :  tensor(9383.6660, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  375 :  tensor(9849.3516, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  376 :  tensor(9772.1797, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  377 :  tensor(9606.3281, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  378 :  tensor(9330.4805, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  379 :  tensor(9600.4023, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  380 :  tensor(9375.9482, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  381 :  tensor(9625.9688, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  382 :  tensor(9820.1523, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  383 :  tensor(9338.2549, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  384 :  tensor(9694.1787, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  385 :  tensor(9869.4062, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  386 :  tensor(9361.1367, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  387 :  tensor(9829.4463, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  388 :  tensor(9855.7627, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  389 :  tensor(9296.0234, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  390 :  tensor(10186.2109, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  391 :  tensor(9885.8486, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  392 :  tensor(9523.4141, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  393 :  tensor(9460.0039, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  394 :  tensor(9957.2207, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  395 :  tensor(9656.3584, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  396 :  tensor(9649.9434, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  397 :  tensor(9495.4746, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  398 :  tensor(9798.2734, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  399 :  tensor(9459.2129, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  400 :  tensor(9492.8271, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  401 :  tensor(9665.8613, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  402 :  tensor(9408.2363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  403 :  tensor(9817.2363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  404 :  tensor(9437.3535, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  405 :  tensor(9616.1230, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  406 :  tensor(9431.2246, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  407 :  tensor(9671.4863, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  408 :  tensor(9036.3252, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  409 :  tensor(9736.6982, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  410 :  tensor(9608.9512, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  411 :  tensor(9866.1836, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  412 :  tensor(9677.7441, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  413 :  tensor(9638.8613, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  414 :  tensor(9794.8223, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  415 :  tensor(9324.2539, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  416 :  tensor(9414.5703, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  417 :  tensor(9336.6006, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  418 :  tensor(9919.9590, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  419 :  tensor(9555.0977, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  420 :  tensor(9473.9287, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  421 :  tensor(9888.2070, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  422 :  tensor(9752.3125, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  423 :  tensor(9671.3809, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  424 :  tensor(9776.8105, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  425 :  tensor(9692.2373, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  426 :  tensor(9212.1094, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  427 :  tensor(9807.7500, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  428 :  tensor(9537.7812, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  429 :  tensor(9474.6367, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  430 :  tensor(9594.7959, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  431 :  tensor(9397.3398, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  432 :  tensor(9294.6309, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  433 :  tensor(9796.3506, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  434 :  tensor(9440.8535, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  435 :  tensor(9110.9971, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  436 :  tensor(9734.7344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  437 :  tensor(9796.9531, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  438 :  tensor(9992.3438, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  439 :  tensor(9588.6807, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  440 :  tensor(9250.1406, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  441 :  tensor(9760.3193, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  442 :  tensor(9479.4258, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  443 :  tensor(9650.1465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  444 :  tensor(9818.7881, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  445 :  tensor(9683.6914, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  446 :  tensor(9549.9062, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  447 :  tensor(9528.9463, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  448 :  tensor(9646.4277, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  449 :  tensor(9541.5654, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  450 :  tensor(9256.2852, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  451 :  tensor(9514.2598, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  452 :  tensor(9468.6533, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  453 :  tensor(9697.2021, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  454 :  tensor(9636.3008, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  455 :  tensor(9845.9863, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  456 :  tensor(9246.3711, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  457 :  tensor(9540.8779, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  458 :  tensor(9864.9238, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  459 :  tensor(10076.3379, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  460 :  tensor(9560.4834, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  461 :  tensor(9194.2314, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  462 :  tensor(9233.0146, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  463 :  tensor(9417.8574, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  464 :  tensor(9455.0615, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  465 :  tensor(9599.8535, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  466 :  tensor(9613.7832, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  467 :  tensor(9279.6074, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  468 :  tensor(9167.4307, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  469 :  tensor(9527.4414, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  470 :  tensor(9629.2812, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  471 :  tensor(9859.0547, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  472 :  tensor(9548.0273, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  473 :  tensor(9564.4805, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  474 :  tensor(9590.1699, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  475 :  tensor(9946.8809, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  476 :  tensor(9571.7197, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  477 :  tensor(9567.9346, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  478 :  tensor(9255.4395, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  479 :  tensor(9348.6348, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  480 :  tensor(9736.2773, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  481 :  tensor(9681.1045, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  482 :  tensor(9735.4248, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  483 :  tensor(9546.9023, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  484 :  tensor(9745.7822, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  485 :  tensor(9730.7207, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  486 :  tensor(9575.0508, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  487 :  tensor(9318.3262, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  488 :  tensor(9665.0547, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  489 :  tensor(9575.0957, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  490 :  tensor(9796.0479, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  491 :  tensor(9787.6943, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  492 :  tensor(9646.1494, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  493 :  tensor(9320.2666, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  494 :  tensor(9746.4629, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  495 :  tensor(9806.9863, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  496 :  tensor(9394.1006, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  497 :  tensor(9471.6152, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  498 :  tensor(9349.1465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  499 :  tensor(9611.4297, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  500 :  tensor(9401.9834, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  501 :  tensor(9818.5332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  502 :  tensor(9421.6396, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  503 :  tensor(9435.1377, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  504 :  tensor(9494.7295, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  505 :  tensor(9433.1611, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  506 :  tensor(9358.0928, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  507 :  tensor(9441.1357, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  508 :  tensor(9705.8945, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  509 :  tensor(9218.6797, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  510 :  tensor(9420.3535, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  511 :  tensor(9649.3779, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  512 :  tensor(9622.2490, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  513 :  tensor(9740.1865, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  514 :  tensor(9584.6523, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  515 :  tensor(9490.8701, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  516 :  tensor(9632.9287, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  517 :  tensor(9531.3916, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  518 :  tensor(9398.2412, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  519 :  tensor(9638.4902, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  520 :  tensor(9403.6533, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  521 :  tensor(9615.8555, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  522 :  tensor(9678.3965, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  523 :  tensor(9486.8555, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  524 :  tensor(9603.9082, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  525 :  tensor(9424.2939, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  526 :  tensor(9920.3711, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  527 :  tensor(9751.6299, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  528 :  tensor(9522.6963, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  529 :  tensor(10208.9590, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  530 :  tensor(9583.8164, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  531 :  tensor(9441.5898, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  532 :  tensor(9404.4453, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  533 :  tensor(9217.1758, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  534 :  tensor(9686.4922, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  535 :  tensor(10154.0762, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  536 :  tensor(9773.4746, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  537 :  tensor(9488.2314, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  538 :  tensor(9798.4824, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  539 :  tensor(9294.3281, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  540 :  tensor(9655.6621, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  541 :  tensor(9435.4238, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  542 :  tensor(9815.2871, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  543 :  tensor(9499.7871, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  544 :  tensor(9667.2480, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  545 :  tensor(9576.1387, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  546 :  tensor(9604.5625, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  547 :  tensor(9656.3389, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  548 :  tensor(9571.3281, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  549 :  tensor(9359.3779, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  550 :  tensor(9590.7031, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  551 :  tensor(9733.7803, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  552 :  tensor(9386.4023, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  553 :  tensor(9663.7539, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  554 :  tensor(9727.5234, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  555 :  tensor(9408.5234, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  556 :  tensor(9681.8789, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  557 :  tensor(9414.9629, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  558 :  tensor(9224.5889, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  559 :  tensor(9515.3613, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  560 :  tensor(9609.5947, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  561 :  tensor(9636.8945, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  562 :  tensor(9422.7314, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  563 :  tensor(9798.6240, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  564 :  tensor(9496.3418, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  565 :  tensor(9322.7773, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  566 :  tensor(9428.0566, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  567 :  tensor(9424.3848, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  568 :  tensor(9312.6309, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  569 :  tensor(9108.0938, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  570 :  tensor(9720.8574, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  571 :  tensor(9095.7168, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  572 :  tensor(9379.8555, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  573 :  tensor(9486.8662, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  574 :  tensor(9471.6914, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  575 :  tensor(9273.2285, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  576 :  tensor(9657.9053, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  577 :  tensor(9949.4248, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  578 :  tensor(9373.3008, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  579 :  tensor(9525.3252, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  580 :  tensor(9526.6797, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  581 :  tensor(9564.1846, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  582 :  tensor(9205.5742, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  583 :  tensor(9699.5605, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  584 :  tensor(9695.6309, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  585 :  tensor(9535.9912, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  586 :  tensor(9600.5430, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  587 :  tensor(9468.4355, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  588 :  tensor(9913.5859, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  589 :  tensor(9666.5127, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  590 :  tensor(9632.6777, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  591 :  tensor(9468.2383, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  592 :  tensor(9215.3721, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  593 :  tensor(9823.7168, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  594 :  tensor(9648.4219, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  595 :  tensor(9443.2832, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  596 :  tensor(9278.8916, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  597 :  tensor(9274.4434, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  598 :  tensor(9595.5732, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  599 :  tensor(9580.4043, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  600 :  tensor(9567.7822, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  601 :  tensor(9526.3604, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  602 :  tensor(9285.5752, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  603 :  tensor(9283.9199, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  604 :  tensor(9081.8711, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  605 :  tensor(9301.1475, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  606 :  tensor(9389.6465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  607 :  tensor(9546.0332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  608 :  tensor(9561.7949, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  609 :  tensor(9276.5439, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  610 :  tensor(9218.3789, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  611 :  tensor(9266.8516, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  612 :  tensor(9139.6260, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  613 :  tensor(9743.7129, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  614 :  tensor(9311.4121, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  615 :  tensor(9666.6562, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  616 :  tensor(9459.4336, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  617 :  tensor(9225.0859, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  618 :  tensor(9375.4795, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  619 :  tensor(9426.8945, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  620 :  tensor(9860.1006, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  621 :  tensor(9656.6289, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  622 :  tensor(9382.9473, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  623 :  tensor(9434.1855, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  624 :  tensor(9381.7510, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  625 :  tensor(9296.1602, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  626 :  tensor(9476.5410, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  627 :  tensor(9170.8730, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  628 :  tensor(9444.4238, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  629 :  tensor(9501.5566, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  630 :  tensor(9271.4414, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  631 :  tensor(9365.1836, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  632 :  tensor(9574.2568, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  633 :  tensor(9385.1582, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  634 :  tensor(9686.5762, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  635 :  tensor(9561.3184, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  636 :  tensor(9627.7422, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  637 :  tensor(9449.3965, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  638 :  tensor(9239.6113, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  639 :  tensor(9085.6543, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  640 :  tensor(9710.4375, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  641 :  tensor(9333.6562, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  642 :  tensor(9405.2051, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  643 :  tensor(8891.6465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  644 :  tensor(9356.2344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  645 :  tensor(9227.8555, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  646 :  tensor(9436.0127, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  647 :  tensor(9584.6152, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  648 :  tensor(9450.3008, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  649 :  tensor(9322.8223, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  650 :  tensor(9429.4590, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  651 :  tensor(9723.8262, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  652 :  tensor(9187.2051, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  653 :  tensor(9163.8975, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  654 :  tensor(9433.4199, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  655 :  tensor(9351.5693, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  656 :  tensor(9149.4375, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  657 :  tensor(9710.8242, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  658 :  tensor(9606.6230, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  659 :  tensor(9507.8359, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  660 :  tensor(9216.5898, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  661 :  tensor(9185.1123, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  662 :  tensor(8972.8467, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  663 :  tensor(9898.6738, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  664 :  tensor(9441.1787, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  665 :  tensor(9297.6387, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  666 :  tensor(9474.5645, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  667 :  tensor(9447.2949, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  668 :  tensor(9213.7783, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  669 :  tensor(9306.2393, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  670 :  tensor(8987.3164, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  671 :  tensor(9451.4209, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  672 :  tensor(9375.4141, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  673 :  tensor(9297.1260, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  674 :  tensor(9513.0322, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  675 :  tensor(9185.5586, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  676 :  tensor(9248.2852, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  677 :  tensor(9202.6621, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  678 :  tensor(9402.4199, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  679 :  tensor(9078.8789, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  680 :  tensor(9526.4922, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  681 :  tensor(9432.1689, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  682 :  tensor(9856.1504, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  683 :  tensor(9271.0850, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  684 :  tensor(9274.3008, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  685 :  tensor(9227.5713, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  686 :  tensor(9270.6406, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  687 :  tensor(9238.0908, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  688 :  tensor(9180.6328, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  689 :  tensor(9405.9219, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  690 :  tensor(9328.2520, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  691 :  tensor(9151.2549, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  692 :  tensor(9250.3311, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  693 :  tensor(9802.6426, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  694 :  tensor(9537.5000, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  695 :  tensor(9044.7539, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  696 :  tensor(9565.9629, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  697 :  tensor(9337.7012, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  698 :  tensor(9620.5303, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  699 :  tensor(9651.3027, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  700 :  tensor(9144.9980, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  701 :  tensor(9290.3604, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  702 :  tensor(9339.8662, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  703 :  tensor(9226.7285, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  704 :  tensor(9520.0977, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  705 :  tensor(9107.8320, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  706 :  tensor(9461.5850, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  707 :  tensor(9610.0674, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  708 :  tensor(9644.5059, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  709 :  tensor(9478.4336, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  710 :  tensor(9415.1279, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  711 :  tensor(9454.6035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  712 :  tensor(9182.6572, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  713 :  tensor(9396.3994, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  714 :  tensor(9561.6035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  715 :  tensor(9465.7676, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  716 :  tensor(9175.6875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  717 :  tensor(9342.2930, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  718 :  tensor(9418.0488, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  719 :  tensor(9509.1641, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  720 :  tensor(9235.8184, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  721 :  tensor(9870.4473, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  722 :  tensor(9463.1445, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  723 :  tensor(9028.9160, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  724 :  tensor(9888.4023, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  725 :  tensor(9251.2793, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  726 :  tensor(9526.1152, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  727 :  tensor(9161.8086, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  728 :  tensor(9662.8770, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  729 :  tensor(9676.7207, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  730 :  tensor(9572.9902, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  731 :  tensor(9700.0547, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  732 :  tensor(9582.6543, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  733 :  tensor(9611.0332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  734 :  tensor(9603.7891, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  735 :  tensor(9635.7988, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  736 :  tensor(9536.3262, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  737 :  tensor(9412.4443, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  738 :  tensor(9270.2363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  739 :  tensor(9335.6602, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  740 :  tensor(9648.8184, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  741 :  tensor(9412.9717, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  742 :  tensor(9359.2705, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  743 :  tensor(9558.7295, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  744 :  tensor(8965.5664, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  745 :  tensor(9463.7637, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  746 :  tensor(8929.6182, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  747 :  tensor(9582.6768, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  748 :  tensor(9627.2207, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  749 :  tensor(9619.9551, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  750 :  tensor(9231.4131, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  751 :  tensor(9419.7041, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  752 :  tensor(9310.5723, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  753 :  tensor(9201.1777, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  754 :  tensor(9346.5605, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  755 :  tensor(9400.3535, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  756 :  tensor(9292.8027, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  757 :  tensor(9173.9922, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  758 :  tensor(9715.7363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  759 :  tensor(9236.9160, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  760 :  tensor(9381.4082, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  761 :  tensor(9480.4209, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  762 :  tensor(9590.4434, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  763 :  tensor(9536.7451, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  764 :  tensor(9178.5957, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  765 :  tensor(9270.5801, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  766 :  tensor(9334.2578, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  767 :  tensor(9655.5371, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  768 :  tensor(9573.6582, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  769 :  tensor(9201.0215, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  770 :  tensor(9798.6465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  771 :  tensor(9581.1367, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  772 :  tensor(9412.0664, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  773 :  tensor(9391.5371, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  774 :  tensor(9291.3750, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  775 :  tensor(9260.0293, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  776 :  tensor(9437.1045, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  777 :  tensor(9116.7344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  778 :  tensor(9128.8496, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  779 :  tensor(9715.9795, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  780 :  tensor(9524.3613, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  781 :  tensor(9381.4629, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  782 :  tensor(9284.3711, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  783 :  tensor(9070.9688, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  784 :  tensor(9586.1279, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  785 :  tensor(9455.7422, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  786 :  tensor(9390.3750, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  787 :  tensor(9347.0361, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  788 :  tensor(9454.5312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  789 :  tensor(9693.6104, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  790 :  tensor(9747.1484, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  791 :  tensor(9521.3662, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  792 :  tensor(9784.5312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  793 :  tensor(9593.5029, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  794 :  tensor(9539.8408, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  795 :  tensor(9717.8047, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  796 :  tensor(9652.7480, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  797 :  tensor(9500.3311, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  798 :  tensor(9465.9258, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   Loss batch:  799 :  tensor(9587.1104, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0597 GB\n",
            "   Loss batch:  800 :  tensor(9260.2930, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0615 GB\n",
            "   ___________________________\n",
            "   Loss validation batch  1 :  tensor(9455.5566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  2 :  tensor(9491.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  3 :  tensor(9523.8633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  4 :  tensor(9710.0078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  5 :  tensor(9713.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  6 :  tensor(9575.3848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  7 :  tensor(9344.4785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  8 :  tensor(9552.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  9 :  tensor(9494.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  10 :  tensor(9592.5586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  11 :  tensor(9450.6172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  12 :  tensor(9317.3555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  13 :  tensor(9296.0137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  14 :  tensor(9474.8750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  15 :  tensor(9128.2441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  16 :  tensor(9128.8359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  17 :  tensor(9709.3398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  18 :  tensor(9368.2695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  19 :  tensor(9388.6191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  20 :  tensor(9421.0605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  21 :  tensor(9102.4395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  22 :  tensor(9446.2793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  23 :  tensor(9296.3389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  24 :  tensor(9739.3506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  25 :  tensor(9354.4395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  26 :  tensor(9600.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  27 :  tensor(9252.4531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  28 :  tensor(9699.4736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  29 :  tensor(9528.4600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  30 :  tensor(9572.0957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  31 :  tensor(9576.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  32 :  tensor(9518.9238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  33 :  tensor(9247.9062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  34 :  tensor(9248.1309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  35 :  tensor(9681.3828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  36 :  tensor(9480.1592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  37 :  tensor(9721.8447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  38 :  tensor(9490.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  39 :  tensor(9206.9141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  40 :  tensor(9642.6963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  41 :  tensor(9287.8125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  42 :  tensor(9621.7910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  43 :  tensor(9668.7969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  44 :  tensor(9309.2324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  45 :  tensor(9625.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  46 :  tensor(9511.9863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  47 :  tensor(9495.3047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  48 :  tensor(9337.3691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  49 :  tensor(9709.6338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  50 :  tensor(9710.3066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  51 :  tensor(9644.4707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  52 :  tensor(9730.8076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  53 :  tensor(9376.4307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  54 :  tensor(9682.7041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  55 :  tensor(9632.8311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  56 :  tensor(9556.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  57 :  tensor(9701.4980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  58 :  tensor(9008.5742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  59 :  tensor(9468.1211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  60 :  tensor(9655.6836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  61 :  tensor(9666.9951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  62 :  tensor(9468.9482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  63 :  tensor(9464.1396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  64 :  tensor(9537.1221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  65 :  tensor(9829.9629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  66 :  tensor(9227.6934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  67 :  tensor(9295.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  68 :  tensor(9424.8105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  69 :  tensor(9517.3418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  70 :  tensor(9537.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  71 :  tensor(9415.6221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  72 :  tensor(9387.0322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  73 :  tensor(9456.8369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  74 :  tensor(9218.1777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  75 :  tensor(9668.8115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  76 :  tensor(9564.0420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  77 :  tensor(9446.8223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  78 :  tensor(9699.9160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  79 :  tensor(9067.3984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  80 :  tensor(9618.6973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  81 :  tensor(9509.1787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  82 :  tensor(9777.5820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  83 :  tensor(9498.6094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  84 :  tensor(9267.8828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  85 :  tensor(9419.4619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  86 :  tensor(9768.7090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  87 :  tensor(9343.7227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  88 :  tensor(9429.4043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  89 :  tensor(9591.8223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  90 :  tensor(9403.8145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  91 :  tensor(9386.0811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  92 :  tensor(9510.4404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  93 :  tensor(9552.6328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  94 :  tensor(9514.6426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  95 :  tensor(9520.3047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  96 :  tensor(9464.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  97 :  tensor(9562.7207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  98 :  tensor(9851.8242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  99 :  tensor(9182.6270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  100 :  tensor(9303.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  101 :  tensor(9495.8262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  102 :  tensor(9683.1641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  103 :  tensor(9422.8789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  104 :  tensor(9514.9854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  105 :  tensor(9557.9482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  106 :  tensor(9288.1914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  107 :  tensor(9418.9160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  108 :  tensor(9355.3145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  109 :  tensor(9518.6611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  110 :  tensor(9269.4121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  111 :  tensor(9341.7656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  112 :  tensor(9334.4551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  113 :  tensor(9275.5547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  114 :  tensor(9361.4434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  115 :  tensor(9392.0420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  116 :  tensor(9525.8086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  117 :  tensor(9595.6328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  118 :  tensor(9379.7598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  119 :  tensor(9614.1279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  120 :  tensor(9348.4238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  121 :  tensor(9924.9844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  122 :  tensor(9269.6367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  123 :  tensor(9603.5625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  124 :  tensor(9367.9453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  125 :  tensor(9204.9707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  126 :  tensor(9581.9180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  127 :  tensor(9558.3691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  128 :  tensor(9642.8135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  129 :  tensor(9546.0391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  130 :  tensor(9487.6172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  131 :  tensor(9569.7617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  132 :  tensor(9386.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  133 :  tensor(9437.5488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  134 :  tensor(9238.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  135 :  tensor(9534.1494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  136 :  tensor(9649.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  137 :  tensor(9394.8467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  138 :  tensor(9722.6934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  139 :  tensor(9406.8779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  140 :  tensor(9605.4268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  141 :  tensor(9360.8867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  142 :  tensor(9714.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  143 :  tensor(9793.1914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  144 :  tensor(9468.1289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  145 :  tensor(9459.3682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  146 :  tensor(9271.6055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  147 :  tensor(9534.2812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  148 :  tensor(9375.6465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  149 :  tensor(9642.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  150 :  tensor(9558.1074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  151 :  tensor(9475.0078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  152 :  tensor(9774.7773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  153 :  tensor(9417.2891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  154 :  tensor(9244.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  155 :  tensor(9586.0078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  156 :  tensor(9672.9082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  157 :  tensor(9848.2197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  158 :  tensor(9867.8047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  159 :  tensor(9305.9805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  160 :  tensor(9358.5312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  161 :  tensor(9474.3652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  162 :  tensor(9296.8223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  163 :  tensor(9308.8047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  164 :  tensor(9571.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  165 :  tensor(9378.6074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  166 :  tensor(9622.7197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  167 :  tensor(9543.2383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  168 :  tensor(9334.9785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  169 :  tensor(9477.3545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss validation batch  170 :  tensor(9575.7949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "   Loss media validation:  9486.988729319854\n",
            "   la loss risulta essere migliore\n",
            "Epoca 2 _____________________________________________________________________\n",
            "   Loss batch:  1 :  tensor(9688.3164, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0606 GB\n",
            "   Loss batch:  2 :  tensor(9086.6650, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0628 GB\n",
            "   Loss batch:  3 :  tensor(9719.8994, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0607 GB\n",
            "   Loss batch:  4 :  tensor(9617.7363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  5 :  tensor(9533.9277, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  6 :  tensor(9854.1416, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  7 :  tensor(9634.9668, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  8 :  tensor(9466.8301, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  9 :  tensor(9601.0430, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  10 :  tensor(9554.6230, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  11 :  tensor(9484.9199, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  12 :  tensor(9265.9141, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  13 :  tensor(9212.3330, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  14 :  tensor(9212.4043, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  15 :  tensor(9670.7480, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  16 :  tensor(9293.9941, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  17 :  tensor(9519.7793, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  18 :  tensor(9343.0762, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  19 :  tensor(9610.4160, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  20 :  tensor(9248.7598, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  21 :  tensor(9485.3086, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  22 :  tensor(9491.4746, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  23 :  tensor(9122.7539, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  24 :  tensor(9190.8096, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  25 :  tensor(9440.4941, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  26 :  tensor(9069.9785, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  27 :  tensor(9186.5664, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  28 :  tensor(8895.3037, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  29 :  tensor(9287.3750, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  30 :  tensor(9587.9688, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  31 :  tensor(9246.7529, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  32 :  tensor(9657.2383, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  33 :  tensor(9500.4424, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  34 :  tensor(9273.3398, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  35 :  tensor(9551.0439, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  36 :  tensor(9626.8965, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  37 :  tensor(9583.3418, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  38 :  tensor(9337.0430, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  39 :  tensor(9380.1816, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  40 :  tensor(9652.9727, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  41 :  tensor(9381.7373, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  42 :  tensor(9469.7471, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  43 :  tensor(9141.3672, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  44 :  tensor(9386.2588, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  45 :  tensor(9346.8770, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  46 :  tensor(9588.1826, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  47 :  tensor(9771.4707, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  48 :  tensor(9280.6523, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  49 :  tensor(9503.7871, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  50 :  tensor(9493.2412, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  51 :  tensor(9772.4922, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  52 :  tensor(9596.3281, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  53 :  tensor(9422.1484, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  54 :  tensor(9251.7471, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  55 :  tensor(9182.0859, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  56 :  tensor(9536.8047, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  57 :  tensor(9392.0215, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  58 :  tensor(9377.7393, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  59 :  tensor(9261.2471, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  60 :  tensor(9624.8438, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  61 :  tensor(9406.6914, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  62 :  tensor(9522.6758, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  63 :  tensor(9374.6406, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  64 :  tensor(9439.5479, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  65 :  tensor(9302.8691, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  66 :  tensor(9560.3320, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  67 :  tensor(9019.1240, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  68 :  tensor(9534.1338, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  69 :  tensor(9309.6250, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  70 :  tensor(9355.3252, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  71 :  tensor(9292.6123, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  72 :  tensor(9302.8594, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  73 :  tensor(9303.2246, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  74 :  tensor(9094.3555, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  75 :  tensor(9202.7266, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  76 :  tensor(8977.1650, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  77 :  tensor(9292.3213, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  78 :  tensor(9384.2910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  79 :  tensor(9090.9404, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  80 :  tensor(9560.5391, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  81 :  tensor(9395.0898, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  82 :  tensor(9470.3301, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  83 :  tensor(9441.6816, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  84 :  tensor(9210.7715, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  85 :  tensor(9657.8906, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  86 :  tensor(9847.7178, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  87 :  tensor(9291.9873, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  88 :  tensor(9279.8428, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  89 :  tensor(9372.6943, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  90 :  tensor(9278.3740, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  91 :  tensor(9672.9297, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  92 :  tensor(9489.3682, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  93 :  tensor(9274.9229, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  94 :  tensor(9486.5303, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  95 :  tensor(9383.9990, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  96 :  tensor(9508.5020, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  97 :  tensor(9236.1826, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  98 :  tensor(9091.6602, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  99 :  tensor(9601.0586, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  100 :  tensor(9537.6719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  101 :  tensor(9914.9629, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  102 :  tensor(9895.1621, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  103 :  tensor(9016.0225, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  104 :  tensor(9203.2109, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  105 :  tensor(9319.4883, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  106 :  tensor(9355.5918, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  107 :  tensor(9558.3730, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  108 :  tensor(9171.9287, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  109 :  tensor(9663.7246, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  110 :  tensor(9100.6787, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  111 :  tensor(8947.3652, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  112 :  tensor(9567.5459, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  113 :  tensor(10135.7520, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  114 :  tensor(9800.0039, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  115 :  tensor(9493.2041, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  116 :  tensor(9024.8887, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  117 :  tensor(9365.2793, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  118 :  tensor(9260.9570, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  119 :  tensor(9399.2676, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  120 :  tensor(9228.7373, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  121 :  tensor(9430.2070, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  122 :  tensor(9418.5449, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  123 :  tensor(9526.2432, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  124 :  tensor(9340.1689, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  125 :  tensor(9493.7881, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  126 :  tensor(9599.4062, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  127 :  tensor(9183.1035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  128 :  tensor(9179.9170, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  129 :  tensor(9159.8398, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  130 :  tensor(9411.0742, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  131 :  tensor(9627.5527, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  132 :  tensor(9320.7852, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  133 :  tensor(9327.5254, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  134 :  tensor(9151.1318, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  135 :  tensor(9258.1621, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  136 :  tensor(9320.6494, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  137 :  tensor(9193.9199, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  138 :  tensor(9169.5176, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  139 :  tensor(9189.1455, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  140 :  tensor(9212.9492, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  141 :  tensor(9066.2080, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  142 :  tensor(9305.9111, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  143 :  tensor(9007.0771, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  144 :  tensor(9460.1885, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  145 :  tensor(9529.1904, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  146 :  tensor(9631.0820, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  147 :  tensor(9280.7383, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  148 :  tensor(9579.0654, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  149 :  tensor(9463.7178, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  150 :  tensor(9015.5586, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  151 :  tensor(9059.4766, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  152 :  tensor(9473.8613, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  153 :  tensor(9474.0156, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  154 :  tensor(9364.3857, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  155 :  tensor(9233.3184, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  156 :  tensor(9578.6211, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  157 :  tensor(9204.1553, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  158 :  tensor(9354.0342, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  159 :  tensor(9766.3457, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  160 :  tensor(9259.2305, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  161 :  tensor(9286.4219, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  162 :  tensor(9367.2607, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  163 :  tensor(9163.9844, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  164 :  tensor(9154.7334, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  165 :  tensor(9373.7363, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  166 :  tensor(9654.2344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  167 :  tensor(9389.5156, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  168 :  tensor(9409.6016, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  169 :  tensor(9361.4688, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  170 :  tensor(9403.0391, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  171 :  tensor(9317.2324, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  172 :  tensor(9287.1270, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  173 :  tensor(9173.0547, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  174 :  tensor(8998.0469, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  175 :  tensor(9425.5410, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  176 :  tensor(8924.2656, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  177 :  tensor(9300.7422, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  178 :  tensor(9215.4316, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  179 :  tensor(9593.6143, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  180 :  tensor(9116.2412, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  181 :  tensor(9242.0400, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  182 :  tensor(9568.3613, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  183 :  tensor(8586.6260, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  184 :  tensor(8991.2617, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  185 :  tensor(9488.6289, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  186 :  tensor(9171.6621, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  187 :  tensor(9500.7812, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  188 :  tensor(9274.5898, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  189 :  tensor(9192.1230, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  190 :  tensor(9353.5254, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  191 :  tensor(9111.9902, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  192 :  tensor(9200.4424, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  193 :  tensor(9164.6025, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  194 :  tensor(9193.0596, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  195 :  tensor(9685.0596, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  196 :  tensor(9532.3828, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  197 :  tensor(9094.8887, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  198 :  tensor(9197.9561, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  199 :  tensor(9539.5859, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  200 :  tensor(9196.1533, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  201 :  tensor(9077.9121, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  202 :  tensor(9502.9824, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  203 :  tensor(9363.7305, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  204 :  tensor(9135.1416, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  205 :  tensor(9431.5713, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  206 :  tensor(9368.5742, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  207 :  tensor(9286.5479, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  208 :  tensor(9919.5176, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  209 :  tensor(9497.0254, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  210 :  tensor(8890.6836, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  211 :  tensor(9004.0869, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  212 :  tensor(9651.0938, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  213 :  tensor(9265.8105, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  214 :  tensor(9138.0703, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  215 :  tensor(9052.0254, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  216 :  tensor(9750.5527, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  217 :  tensor(9221.1875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  218 :  tensor(9127.1992, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  219 :  tensor(9414.6934, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  220 :  tensor(9393.7285, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  221 :  tensor(9359.5615, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  222 :  tensor(9117.0332, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  223 :  tensor(9306.8535, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  224 :  tensor(9061.4463, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  225 :  tensor(9617.8223, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  226 :  tensor(9443.2568, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  227 :  tensor(9279.7207, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  228 :  tensor(9497.6719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  229 :  tensor(9102.7100, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  230 :  tensor(9295.3057, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  231 :  tensor(9431.1484, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  232 :  tensor(9210.2305, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  233 :  tensor(9436.0039, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  234 :  tensor(9331.9512, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  235 :  tensor(8910.0811, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  236 :  tensor(9291.9277, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  237 :  tensor(9062.0781, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  238 :  tensor(9196.0137, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  239 :  tensor(9214.2188, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  240 :  tensor(9120.9160, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  241 :  tensor(9321.8027, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  242 :  tensor(9207.0635, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  243 :  tensor(9045.3770, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  244 :  tensor(9238.7217, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  245 :  tensor(9215.5420, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  246 :  tensor(9377.5215, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  247 :  tensor(9514.1582, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  248 :  tensor(9469.2754, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  249 :  tensor(9209.0566, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  250 :  tensor(9092.7061, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  251 :  tensor(9460.9082, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  252 :  tensor(10061.3633, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  253 :  tensor(9432.6768, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  254 :  tensor(9236.6602, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  255 :  tensor(9384.4707, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  256 :  tensor(9669.4902, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  257 :  tensor(9425.5029, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  258 :  tensor(9383.7109, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  259 :  tensor(9466.2158, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  260 :  tensor(9120.3350, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  261 :  tensor(9516.3623, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  262 :  tensor(9074.1182, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  263 :  tensor(9461.9502, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  264 :  tensor(9542.9639, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  265 :  tensor(9235.3555, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  266 :  tensor(9746.3799, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  267 :  tensor(9416.6328, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  268 :  tensor(9441.5176, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  269 :  tensor(9447.2207, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  270 :  tensor(9229.8535, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  271 :  tensor(9169.2910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  272 :  tensor(9574.4062, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  273 :  tensor(9200.0762, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  274 :  tensor(9433.9199, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  275 :  tensor(9410.0850, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  276 :  tensor(9281.6875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  277 :  tensor(9681.5977, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  278 :  tensor(9405.2891, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  279 :  tensor(9386.8105, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  280 :  tensor(9435.7891, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  281 :  tensor(9207.2070, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  282 :  tensor(9275.0234, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  283 :  tensor(9181.9746, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  284 :  tensor(9283.4580, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  285 :  tensor(9143.9404, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  286 :  tensor(9319.5781, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  287 :  tensor(9262.4102, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  288 :  tensor(8774.8350, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  289 :  tensor(9211.7754, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  290 :  tensor(9008.3516, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  291 :  tensor(9001.8633, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  292 :  tensor(9304.0205, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  293 :  tensor(9315.9590, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  294 :  tensor(9286.6562, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  295 :  tensor(9271.1738, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  296 :  tensor(8843.1504, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  297 :  tensor(9072.7090, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  298 :  tensor(9553.9023, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  299 :  tensor(9485.1875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  300 :  tensor(9394.3906, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  301 :  tensor(9524.2383, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  302 :  tensor(9528.5039, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  303 :  tensor(9466.3789, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  304 :  tensor(9534.5977, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  305 :  tensor(9481.7793, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  306 :  tensor(9175.4082, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  307 :  tensor(9578.1797, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  308 :  tensor(9382.4219, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  309 :  tensor(9402.8818, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  310 :  tensor(9102.6504, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  311 :  tensor(9345.4121, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  312 :  tensor(9472.9385, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  313 :  tensor(9243.4688, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  314 :  tensor(9207.0068, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  315 :  tensor(9222.6279, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  316 :  tensor(8884.2207, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  317 :  tensor(9290.1719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  318 :  tensor(9021.3887, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  319 :  tensor(9377.2803, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  320 :  tensor(9287.1660, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  321 :  tensor(9147.4639, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  322 :  tensor(9237.3457, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  323 :  tensor(9727.1875, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  324 :  tensor(9249.2959, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  325 :  tensor(9164.8652, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  326 :  tensor(9709.0312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  327 :  tensor(9112.3438, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  328 :  tensor(9396.4199, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  329 :  tensor(9399.3086, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  330 :  tensor(9370.0605, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  331 :  tensor(9150.8477, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  332 :  tensor(8843.4688, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  333 :  tensor(9233.5996, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  334 :  tensor(8883.4883, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  335 :  tensor(9698.3398, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  336 :  tensor(9397.5488, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  337 :  tensor(9205.4824, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  338 :  tensor(9155.1289, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  339 :  tensor(9370.6465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  340 :  tensor(9356.6035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  341 :  tensor(9566.6699, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  342 :  tensor(9660.0723, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  343 :  tensor(9309.9287, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  344 :  tensor(8960.4824, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  345 :  tensor(9293.3223, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  346 :  tensor(9179.2832, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  347 :  tensor(9473.1270, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  348 :  tensor(9319.1465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  349 :  tensor(8849.1758, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  350 :  tensor(9219.0996, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  351 :  tensor(9034.1973, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  352 :  tensor(9323.6768, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  353 :  tensor(9044.7500, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  354 :  tensor(9469.9355, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  355 :  tensor(9354.7207, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  356 :  tensor(9477.9395, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  357 :  tensor(9185.3711, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  358 :  tensor(9068.0918, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  359 :  tensor(9118.7012, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  360 :  tensor(9237.8145, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  361 :  tensor(9183.4678, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  362 :  tensor(9165.2129, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  363 :  tensor(9430.3281, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  364 :  tensor(9638.2383, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  365 :  tensor(9178.5166, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  366 :  tensor(9115.9629, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  367 :  tensor(8912.7324, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  368 :  tensor(9221.2383, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  369 :  tensor(9318.6465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  370 :  tensor(9492.8730, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  371 :  tensor(9478.3652, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  372 :  tensor(9043.8262, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  373 :  tensor(9284.8408, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  374 :  tensor(9038.2832, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  375 :  tensor(9580.8184, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  376 :  tensor(9554.6250, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  377 :  tensor(9331.5176, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  378 :  tensor(9084.1094, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  379 :  tensor(9219.6035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  380 :  tensor(9075.9531, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  381 :  tensor(9311.1621, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  382 :  tensor(9479.0391, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  383 :  tensor(9024.5469, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  384 :  tensor(9421.7578, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  385 :  tensor(9618.9688, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  386 :  tensor(9040.5391, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  387 :  tensor(9463.7822, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  388 :  tensor(9552.9805, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  389 :  tensor(8948.1396, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  390 :  tensor(9920.5742, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  391 :  tensor(9575.6035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  392 :  tensor(9286.3594, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  393 :  tensor(9161.1152, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  394 :  tensor(9741.9238, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  395 :  tensor(9333.8906, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  396 :  tensor(9356.7344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  397 :  tensor(9154.0098, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  398 :  tensor(9590.3135, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  399 :  tensor(9134.6582, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  400 :  tensor(9140.2598, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  401 :  tensor(9385.0684, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  402 :  tensor(9092.0156, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  403 :  tensor(9502.5723, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  404 :  tensor(9086.1279, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  405 :  tensor(9301.3652, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  406 :  tensor(9153.2344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  407 :  tensor(9381.8623, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  408 :  tensor(8708.8076, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  409 :  tensor(9416.3291, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  410 :  tensor(9353.6270, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  411 :  tensor(9502.1426, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  412 :  tensor(9312.8994, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  413 :  tensor(9394.4473, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  414 :  tensor(9496.5195, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  415 :  tensor(9055.9443, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  416 :  tensor(9150.2900, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  417 :  tensor(8971.8584, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  418 :  tensor(9624.7129, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  419 :  tensor(9253.1465, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  420 :  tensor(9154.3984, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  421 :  tensor(9697.6289, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  422 :  tensor(9481.2051, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  423 :  tensor(9391.4004, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  424 :  tensor(9395.7510, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  425 :  tensor(9294.0410, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  426 :  tensor(8801.0742, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  427 :  tensor(9476.8750, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  428 :  tensor(9125.8691, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  429 :  tensor(9213.8115, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  430 :  tensor(9219.6953, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  431 :  tensor(9030.6357, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  432 :  tensor(9072.2754, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  433 :  tensor(9456.1807, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  434 :  tensor(9111.0811, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  435 :  tensor(8911.1846, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  436 :  tensor(9342.4980, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  437 :  tensor(9460.5908, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  438 :  tensor(9571.5078, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  439 :  tensor(9260.4551, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  440 :  tensor(8970.0312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  441 :  tensor(9594.0723, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  442 :  tensor(9178.4795, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  443 :  tensor(9362.6855, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  444 :  tensor(9530.5342, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  445 :  tensor(9341.5957, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  446 :  tensor(9271.3877, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  447 :  tensor(9248.3711, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  448 :  tensor(9197.5605, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  449 :  tensor(9170.3311, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  450 :  tensor(8880.4102, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  451 :  tensor(9220.5771, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  452 :  tensor(9169.4844, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  453 :  tensor(9384.9619, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  454 :  tensor(9341.7627, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  455 :  tensor(9488.1963, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  456 :  tensor(8945.9209, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  457 :  tensor(9269.1143, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  458 :  tensor(9635.7715, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  459 :  tensor(9694.4531, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  460 :  tensor(9255.8691, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  461 :  tensor(8950.1289, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  462 :  tensor(9002.3887, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  463 :  tensor(9111.8711, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  464 :  tensor(9151.4180, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  465 :  tensor(9297.1260, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  466 :  tensor(9218.2705, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  467 :  tensor(8962.8467, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  468 :  tensor(8843.7695, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  469 :  tensor(9144.9492, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  470 :  tensor(9346.6973, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  471 :  tensor(9503.3135, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  472 :  tensor(9142.5020, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  473 :  tensor(9216.8379, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  474 :  tensor(9304.0361, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  475 :  tensor(9602.1035, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  476 :  tensor(9250.1943, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  477 :  tensor(9326.2734, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  478 :  tensor(8844.8184, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  479 :  tensor(9029.7344, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  480 :  tensor(9494.8496, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  481 :  tensor(9342.1680, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  482 :  tensor(9424.4814, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  483 :  tensor(9191.6113, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  484 :  tensor(9507.9844, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  485 :  tensor(9451.0674, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  486 :  tensor(9305.2354, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  487 :  tensor(9115.6367, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  488 :  tensor(9331.0840, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  489 :  tensor(9350.7305, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  490 :  tensor(9417.9707, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  491 :  tensor(9528.9785, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  492 :  tensor(9344.7148, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  493 :  tensor(9075.4482, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  494 :  tensor(9585.7910, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  495 :  tensor(9479.5400, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  496 :  tensor(9074.0322, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  497 :  tensor(9102.9238, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  498 :  tensor(9067.2559, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  499 :  tensor(9283.5215, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  500 :  tensor(9118.4395, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  501 :  tensor(9523.8359, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  502 :  tensor(9088.4551, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  503 :  tensor(9146.7227, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  504 :  tensor(9203.5879, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  505 :  tensor(9147.9795, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  506 :  tensor(9086.7656, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  507 :  tensor(9099.2227, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  508 :  tensor(9418.4668, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  509 :  tensor(8926.6055, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  510 :  tensor(9171.7979, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  511 :  tensor(9300.5723, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  512 :  tensor(9298.9648, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  513 :  tensor(9421.6924, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  514 :  tensor(9276.2695, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  515 :  tensor(9172.1504, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  516 :  tensor(9359.3037, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  517 :  tensor(9263.7480, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  518 :  tensor(9051.7324, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  519 :  tensor(9362.5254, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  520 :  tensor(9090.1211, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  521 :  tensor(9302.0156, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  522 :  tensor(9518.4199, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  523 :  tensor(9152.0078, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  524 :  tensor(9271.9043, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  525 :  tensor(9193.9375, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  526 :  tensor(9628.2930, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  527 :  tensor(9455.2285, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  528 :  tensor(9214.1846, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  529 :  tensor(9918.3730, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  530 :  tensor(9283.9902, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  531 :  tensor(9156.0605, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  532 :  tensor(9068.9170, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  533 :  tensor(8940.8271, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  534 :  tensor(9351.2754, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  535 :  tensor(9960.0391, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  536 :  tensor(9541.7246, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  537 :  tensor(9220.2812, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  538 :  tensor(9542.1816, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  539 :  tensor(8974.5762, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  540 :  tensor(9323.5068, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  541 :  tensor(9163.5518, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  542 :  tensor(9554.3877, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  543 :  tensor(9228.0127, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  544 :  tensor(9406.6699, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  545 :  tensor(9325.8672, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  546 :  tensor(9291.5068, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  547 :  tensor(9316.1719, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  548 :  tensor(9324.3232, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  549 :  tensor(9107.7939, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  550 :  tensor(9301.3613, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  551 :  tensor(9357.1133, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  552 :  tensor(9092.8369, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  553 :  tensor(9388.9199, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  554 :  tensor(9421.5957, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  555 :  tensor(9094.0283, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  556 :  tensor(9445.3418, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  557 :  tensor(9197.5762, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  558 :  tensor(8959.7676, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  559 :  tensor(9260.5957, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  560 :  tensor(9353.4492, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  561 :  tensor(9368.5684, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  562 :  tensor(9154.8809, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  563 :  tensor(9482.4473, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  564 :  tensor(9266.7764, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  565 :  tensor(9084.6953, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  566 :  tensor(9153.4834, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  567 :  tensor(9127.7451, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  568 :  tensor(8968.5273, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  569 :  tensor(8828.1787, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  570 :  tensor(9473.1523, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  571 :  tensor(8817.4912, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  572 :  tensor(9023.3525, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  573 :  tensor(9185.7832, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  574 :  tensor(9171.2314, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  575 :  tensor(8944.8252, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  576 :  tensor(9345.0293, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  577 :  tensor(9732.1963, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  578 :  tensor(9083.7275, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  579 :  tensor(9257.7188, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  580 :  tensor(9266.6572, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  581 :  tensor(9284.8291, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  582 :  tensor(8885.3965, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n",
            "   Loss batch:  583 :  tensor(9376.2412, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0611 GB\n",
            "   Loss batch:  584 :  tensor(9357.5312, device='cuda:0', grad_fn=<MeanBackward0>)           Memoria GPU utilizzata  ->  3.0619 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3jcP4QahQli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "kkUBSP_FkoJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "N=2\n",
        "input_shape_image = 50*50\n",
        "possible_pixel_values = 2+1\n",
        "x = torch.round(torch.rand((3,50,50))*(possible_pixel_values-1))\n",
        "print(\"Input shape\",x.shape)\n",
        "latent_space_dimension = 6\n",
        "number_of_hidden_neurons = 6\n",
        "L=2\n",
        "mog_components = 3\n",
        "\n",
        "\n",
        "model =  VAE( possible_pixel_values, input_shape_image, latent_space_dimension, number_of_hidden_neurons, L,number_of_flows=10,type_of_prior=1, mog_components=mog_components)\n",
        "model.initialize()\n",
        "\n",
        "model.forward(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MADD16NUMW7n",
        "outputId": "211b9cf0-04ef-4a45-ac8c-1389ed8fa442"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape torch.Size([3, 50, 50])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2880.0144, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=torch.tensor([ 1.6128, -0.7670,  0.7999,  0.1326, -0.3292])\n",
        "m = torch.tensor([[ 0.9719, -0.0809,  0.0633, -0.0105,  0.2117],\n",
        "         [-0.0809,  0.7677,  0.1819, -0.0303,  0.6084],\n",
        "         [ 0.0633,  0.1819,  0.8575,  0.0237, -0.4764],\n",
        "         [-0.0105, -0.0303,  0.0237,  0.9961,  0.0793],\n",
        "         [ 0.2117,  0.6084, -0.4764,  0.0793, -0.5931]])\n",
        "torch.matmul(m,z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ErHYvnMdxua",
        "outputId": "feaeed41-0e48-44fc-eaa0-a3de30141d0d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.6091, -0.7781,  0.8085,  0.1312, -0.3005])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_channels = 32\n",
        "kernel_size = 4\n",
        "latent_space_dimension = 64\n",
        "\n",
        "x = torch.rand((10,1,64,64))\n",
        "\n",
        "encoder = nn.Sequential(\n",
        "                   nn.Conv2d(1,out_channels,kernel_size, stride=2),\n",
        "                   nn.BatchNorm2d(out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "                   #nn.Dropout(0.25),\n",
        "\n",
        "                   nn.Conv2d(out_channels,2*out_channels,kernel_size, stride=2),\n",
        "                   nn.BatchNorm2d(2*out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "                   #nn.Dropout(0.25),\n",
        "\n",
        "                   nn.Conv2d(2*out_channels,2*out_channels,kernel_size,stride=2),\n",
        "                   nn.BatchNorm2d(2*out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "                   nn.Dropout(0.25),\n",
        "\n",
        "                   nn.Conv2d(2*out_channels,3*out_channels,kernel_size, stride=2),\n",
        "                   nn.BatchNorm2d(3*out_channels),\n",
        "                   nn.LeakyReLU(),\n",
        "\n",
        "                   nn.Flatten(),\n",
        "                   nn.LazyLinear(2*latent_space_dimension)\n",
        "\n",
        "                   ).to(torch.float32)\n",
        "\n",
        "z = torch.rand((10, 1, 64))\n",
        "\n",
        "decoder = nn.Sequential(nn.Linear(latent_space_dimension,4096),\n",
        "                          nn.Unflatten(2, (int(math.sqrt(4096)),int(math.sqrt(4096)))),\n",
        "                          nn.Upsample(size=[8,8], mode='bilinear', align_corners=False),\n",
        "                          nn.Conv2d(in_channels=1, out_channels=3*out_channels, kernel_size=kernel_size),\n",
        "                          nn.BatchNorm2d(3*out_channels),\n",
        "                          nn.LeakyReLU(),\n",
        "\n",
        "                          nn.Upsample(size=[16,16], mode='bilinear', align_corners=False),\n",
        "                          nn.Conv2d(in_channels=3*out_channels, out_channels=2*out_channels, kernel_size=kernel_size),\n",
        "                          nn.BatchNorm2d(2*out_channels),\n",
        "                          nn.LeakyReLU(),\n",
        "\n",
        "                          nn.Upsample(size=[16,16], mode='bilinear', align_corners=False),\n",
        "                          nn.Conv2d(in_channels=2*out_channels, out_channels=out_channels, kernel_size=kernel_size),\n",
        "                          nn.BatchNorm2d(out_channels),\n",
        "                          nn.LeakyReLU(),\n",
        "\n",
        "                          nn.Flatten(),\n",
        "                          nn.LazyLinear(input_shape_image*possible_pixel_values),\n",
        "                          nn.Unflatten(1,(input_shape_image,possible_pixel_values))\n",
        "\n",
        "                          )\n",
        "\n",
        "\n",
        "\n",
        "decoder(z).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zACbTBlvko_m",
        "outputId": "00df0d0b-217c-4e5f-9ece-51689017328e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 32, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LtaOEA12k_he"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
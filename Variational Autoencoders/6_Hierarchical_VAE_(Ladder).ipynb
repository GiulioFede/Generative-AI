{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Vl2iyPidU0Xd",
        "EuaGiyB8yTiI"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Questa è una implementazione non ufficiale del paper **\"Ladder Variational Autoencoders\"**  di *Casper Kaae Sønderby, Tapani Raiko, Lars Maaløe, Søren Kaae Sønderby, Ole Winther*\n",
        "(https://arxiv.org/pdf/1602.02282v3.pdf)"
      ],
      "metadata": {
        "id": "7HTH7E6fxSAQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aHh-DE1gxE4l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.datasets import load_digits\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "import math\n",
        "from torchvision import transforms\n",
        "from torch.linalg import multi_dot\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init\n",
        "\n"
      ],
      "metadata": {
        "id": "Vl2iyPidU0Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Controlla la disponibilità della GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Imposta il dispositivo sulla GPU\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Se la GPU non è disponibile, utilizza la CPU\n",
        "\n"
      ],
      "metadata": {
        "id": "of0uWRh0VBOO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUmfBgZZaHJR",
        "outputId": "ca6ffba1-a9c7-4746-cf7d-f23eb9d44e49"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ink originale: https://drive.google.com/file/d/0B7EVK8r0v71pZjFTYXZWM3FlRnM/view?usp=drive_link&resourcekey=0-dYn9z10tMJOBAkviAcfdyQ\n",
        "#spostatelo nel vostro drive e copiatelo in locale (perchè il dataloader carica più velocemente le immagini leggendo da qui che dal vostro drive)\n",
        "!cp '/content/drive/MyDrive/Generative_AI/datasets/celebA/img_align_celeba.zip' celebA.zip"
      ],
      "metadata": {
        "id": "6h5nQ953YpPL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"celebA.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')"
      ],
      "metadata": {
        "id": "jqEVBayxZTVg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "EuaGiyB8yTiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blocco che serve a approssimare le distribuzioni q e p"
      ],
      "metadata": {
        "id": "FGhlkZF-zSVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Tale blocco prende z_i in ingresso (oppure nel primo caso x) e cerca di approssimare\n",
        "    q(z_i+1| z_i) ( o q(z_1| x) nel primo caso). Nel paper tali distribuzione sono\n",
        "    delle Multivariate dove la media viene trovata come:\n",
        "\n",
        "                        mean = Linear(MLP(z_i))\n",
        "\n",
        "    mentre la varianza (elementi nella matrice di covarianza diagonale) come:\n",
        "\n",
        "                        cov = Softplus(Linear(MLP(z_i)))\n",
        "\n",
        "    NB: L'MLP è CONDIVISO tra i due\n",
        "\n",
        "    Tale blocco è usato anche nel ramo del DECODER in quanto da paper le distribuzioni\n",
        "    sono parametrizzate con la stessa logica\n",
        "\n",
        "'''\n",
        "\n",
        "# class Block(nn.Module):\n",
        "#   def __init__(self, input_shape, latent_space_dimension, hidden_neurons):\n",
        "#     super(Block, self).__init__()\n",
        "\n",
        "#     #MLP(z_i)\n",
        "#     self.MLP = nn.Sequential( nn.Linear(input_shape,8*hidden_neurons),\n",
        "#                               nn.BatchNorm1d(8*hidden_neurons),\n",
        "#                               nn.ReLU(),\n",
        "#                               nn.Linear(8*hidden_neurons,4*hidden_neurons),\n",
        "#                               nn.BatchNorm1d(4*hidden_neurons),\n",
        "#                               nn.ReLU(),\n",
        "#                               nn.Linear(4*hidden_neurons,2*hidden_neurons),\n",
        "#                               nn.BatchNorm1d(2*hidden_neurons),\n",
        "#                               nn.ReLU(),\n",
        "#                               nn.Linear(2*hidden_neurons,hidden_neurons)\n",
        "#                               )\n",
        "\n",
        "#     self.mean_net = nn.Sequential(\n",
        "#                               #Linear(MLP(z_i))\n",
        "#                               nn.Linear(hidden_neurons, latent_space_dimension),\n",
        "#                               nn.BatchNorm1d(latent_space_dimension),\n",
        "#                               nn.LeakyReLU()\n",
        "#                             )\n",
        "\n",
        "#     self.log_std_net = nn.Sequential(\n",
        "#                             #Linear(MLP(z_i))\n",
        "#                             nn.Linear(hidden_neurons, latent_space_dimension),\n",
        "#                             nn.BatchNorm1d(latent_space_dimension),\n",
        "\n",
        "#                             #Softplus(Linear(MLP(z_i)))\n",
        "#                             nn.Softplus()\n",
        "#                             )\n",
        "\n",
        "#   #input può essere x se è il primo blocco, z_i altrimenti (SE ENCODER)\n",
        "#   #input può essere z4 se è il primo blocco, z_i altrimenti (SE DECODER)\n",
        "#   def forward(self, input):\n",
        "\n",
        "#       d = self.MLP(input)\n",
        "\n",
        "#       mean = self.mean_net(d)\n",
        "\n",
        "#       log_std = self.log_std_net(d)\n",
        "\n",
        "#       return [mean, log_std]\n",
        "\n",
        "from torch.nn.modules.activation import LeakyReLU\n",
        "'''\n",
        "    Tale blocco prende z_i in ingresso (oppure nel primo caso x) e cerca di approssimare\n",
        "    q(z_i+1| z_i) ( o q(z_1| x) nel primo caso). Nel paper tali distribuzione sono\n",
        "    delle Multivariate dove la media viene trovata come:\n",
        "\n",
        "                        mean = Linear(MLP(z_i))\n",
        "\n",
        "    mentre la varianza (elementi nella matrice di covarianza diagonale) come:\n",
        "\n",
        "                        cov = Softplus(Linear(MLP(z_i)))\n",
        "\n",
        "    NB: L'MLP è CONDIVISO tra i due\n",
        "\n",
        "    Tale blocco è usato anche nel ramo del DECODER in quanto da paper le distribuzioni\n",
        "    sono parametrizzate con la stessa logica\n",
        "\n",
        "'''\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self, input_shape, latent_space_dimension, hidden_neurons):\n",
        "    super(Block, self).__init__()\n",
        "\n",
        "    #MLP(z_i)\n",
        "    # self.MLP = nn.Sequential( nn.Linear(input_shape,8*hidden_neurons),\n",
        "    #                           nn.BatchNorm1d(8*hidden_neurons),\n",
        "    #                           nn.ReLU(),\n",
        "    #                           nn.Linear(8*hidden_neurons,6*hidden_neurons),\n",
        "    #                           nn.BatchNorm1d(6*hidden_neurons),\n",
        "    #                           nn.Tanh(),\n",
        "    #                           nn.Linear(6*hidden_neurons,4*hidden_neurons),\n",
        "    #                           nn.BatchNorm1d(4*hidden_neurons),\n",
        "    #                           nn.ReLU(),\n",
        "    #                           nn.Linear(4*hidden_neurons,2*hidden_neurons),\n",
        "    #                           nn.BatchNorm1d(2*hidden_neurons),\n",
        "    #                           nn.ReLU(),\n",
        "    #                           nn.Linear(2*hidden_neurons,input_shape),\n",
        "    #                           nn.LeakyReLU()\n",
        "    #                           )\n",
        "\n",
        "    out_channels = 32\n",
        "    kernel_size = 4\n",
        "    self.MLP = nn.Sequential(\n",
        "                              #nn.BatchNorm1d(input_shape),\n",
        "\n",
        "                              nn.Conv2d(1,out_channels,kernel_size, stride=1, padding=\"same\"),\n",
        "                              nn.BatchNorm2d(out_channels),\n",
        "                              nn.ELU(),\n",
        "\n",
        "                              nn.Conv2d(out_channels,out_channels,kernel_size, stride=1,padding=\"same\"),\n",
        "                              nn.BatchNorm2d(out_channels),\n",
        "                              nn.ELU(),\n",
        "\n",
        "                              nn.Conv2d(out_channels,2*out_channels,kernel_size, stride=1,padding=\"same\"),\n",
        "                              nn.BatchNorm2d(2*out_channels),\n",
        "                              nn.ELU(),\n",
        "\n",
        "                              nn.Conv2d(2*out_channels,2*out_channels,kernel_size, stride=1,padding=\"same\"),\n",
        "                              nn.BatchNorm2d(2*out_channels),\n",
        "                              nn.ELU(),\n",
        "\n",
        "                              nn.Flatten(),\n",
        "                              nn.LazyLinear(input_shape)\n",
        "\n",
        "    )\n",
        "\n",
        "    self.mean_net = nn.Sequential(\n",
        "                              #Linear(MLP(z_i))\n",
        "                              nn.Linear(input_shape, input_shape),\n",
        "                              nn.BatchNorm1d(input_shape),\n",
        "                              nn.Linear(input_shape, latent_space_dimension),\n",
        "                              nn.BatchNorm1d(latent_space_dimension),\n",
        "                              nn.LeakyReLU()\n",
        "                            )\n",
        "\n",
        "    self.log_std_net = nn.Sequential(\n",
        "                            #Linear(MLP(z_i))\n",
        "                            nn.Linear(input_shape, input_shape),\n",
        "                            nn.BatchNorm1d(input_shape),\n",
        "                            nn.Linear(input_shape, latent_space_dimension),\n",
        "                            nn.BatchNorm1d(latent_space_dimension),\n",
        "\n",
        "                            #Softplus(Linear(MLP(z_i)))\n",
        "                            nn.Softplus()\n",
        "                            )\n",
        "\n",
        "  #input può essere x se è il primo blocco, z_i altrimenti (SE ENCODER)\n",
        "  #input può essere z4 se è il primo blocco, z_i altrimenti (SE DECODER)\n",
        "  def forward(self, input):\n",
        "\n",
        "      #da (N,W*H) a (N,1,W,H)\n",
        "      input = torch.reshape(input, (input.shape[0],1,int(math.sqrt(input.shape[1])),int(math.sqrt(input.shape[1])) ))\n",
        "\n",
        "      d = self.MLP(input)\n",
        "      d = d+torch.flatten(input,2,3).squeeze(1)\n",
        "\n",
        "      mean = self.mean_net(d)\n",
        "      log_std = self.log_std_net(d)\n",
        "\n",
        "      return [mean, log_std]"
      ],
      "metadata": {
        "id": "q8LdLpEszTfA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "0NgdT5_tYxdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_shape_image, latent_space_dimension, hidden_neurons,possible_pixel_values):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.possible_pixel_values = possible_pixel_values\n",
        "\n",
        "    #creo blocco che approssimerà q(z1|x)\n",
        "    self.q_z1_x = Block(input_shape_image, latent_space_dimension, hidden_neurons)\n",
        "\n",
        "    #creo funzione che combina Linear([x,z1])\n",
        "    self.combine_z1_x = nn.Linear(input_shape_image+latent_space_dimension, latent_space_dimension)\n",
        "\n",
        "    #creo blocco che approssimerà q(z2|z1,x)\n",
        "    self.q_z2_z1_x = Block(latent_space_dimension, latent_space_dimension, hidden_neurons)\n",
        "\n",
        "    #creo funzione che combina Linear([x,z1,z2])\n",
        "    self.combine_z2_z1_x = nn.Linear(input_shape_image+latent_space_dimension*2, latent_space_dimension)\n",
        "\n",
        "    #creo blocco che approssimerà q(z3|z2,z1,x)\n",
        "    self.q_z3_z2_z1_x = Block(latent_space_dimension, latent_space_dimension, hidden_neurons)\n",
        "\n",
        "    #creo funzione che combina Linear([x,z1,z2,z3])\n",
        "    self.combine_z3_z2_z1_x = nn.Linear(input_shape_image+latent_space_dimension*3, latent_space_dimension)\n",
        "\n",
        "    #creo blocco che approssimerà q(z4|z3,z2,z1,x)\n",
        "    self.q_z4_z3_z2_z1_x = Block(latent_space_dimension, latent_space_dimension, hidden_neurons)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    #normalizzo il batch\n",
        "    x_norm = x/(self.possible_pixel_values-1)\n",
        "\n",
        "    #flatto   da (N,W,H) a (N,W*H)\n",
        "    x = torch.flatten(x,start_dim=1, end_dim=2)\n",
        "\n",
        "\n",
        "    #:::::::::::::::::::::::: PARTE INFERENZIALE ::::::::::::::::::::::::::::::::::::::::::\n",
        "\n",
        "    #_____ q(z1|x)________________________________\n",
        "    #ottengo parametri della distribuzione in funzione dell'input x\n",
        "    [mean, log_std] = self.q_z1_x(x)\n",
        "    #creo la distribuzione\n",
        "    q = MultivariateNormal(mean, torch.diag_embed( torch.clamp( torch.exp(log_std),min=1e-8)).to(device))\n",
        "    #campiono z1 col reparametrization trick\n",
        "    z1 = q.rsample()\n",
        "    #calcolo ln(q(z1|x))\n",
        "    ln_q_z1_x = q.log_prob(z1)\n",
        "\n",
        "\n",
        "    #_____ q(z2|z1,x)________________________________\n",
        "    #dato che la distribuzione dipende sia da z1 che da x, creo un singolo input che è in funzione dei due\n",
        "    #(N, input_shape+latent_dimension)\n",
        "    input = torch.concat( (z1,x), dim=-1)\n",
        "    #(N, latent_dimension)\n",
        "    input = self.combine_z1_x(input)\n",
        "    #ottengo parametri della distribuzione in funzione dell'input z1 e x\n",
        "    [mean, log_std] = self.q_z2_z1_x(input)\n",
        "    #creo la distribuzione\n",
        "    q = MultivariateNormal(mean, torch.diag_embed( torch.clamp( torch.exp(log_std),min=1e-8)).to(device))\n",
        "    #campiono z2 col reparametrization trick\n",
        "    z2 = q.rsample()\n",
        "\n",
        "    #calcolo ln(q(z2|z1,x))\n",
        "    ln_q_z2_z1_x = q.log_prob(z2)\n",
        "\n",
        "    #_____ q(z3|z2,z1,x)________________________________\n",
        "    #dato che la distribuzione dipende sia da z2,z1 che da x, creo un singolo input che è in funzione dei tre\n",
        "    #(N, input_shape+latent_dimension*2)\n",
        "    input = torch.concat( (z2,z1,x), dim=-1)\n",
        "    #(N, latent_dimension)\n",
        "    input = self.combine_z2_z1_x(input)\n",
        "    #ottengo parametri della distribuzione in funzione dell'input z2,z1 e x\n",
        "    [mean, log_std] = self.q_z3_z2_z1_x(input)\n",
        "    #creo la distribuzione\n",
        "    q = MultivariateNormal(mean, torch.diag_embed( torch.clamp( torch.exp(log_std),min=1e-8)).to(device))\n",
        "    #campiono z3 col reparametrization trick\n",
        "    z3 = q.rsample()\n",
        "    #calcolo ln(q(z3|z2,z1,x))\n",
        "    ln_q_z3_z2_z1_x = q.log_prob(z3)\n",
        "\n",
        "    #_____ q(z4|z3,z2,z1,x)________________________________\n",
        "    #dato che la distribuzione dipende sia da z3,z2,z1 che da x, creo un singolo input che è in funzione dei quattro\n",
        "    #(N, input_shape+latent_dimension*3)\n",
        "    input = torch.concat( (z3,z2,z1,x), dim=-1)\n",
        "    #(N, latent_dimension)\n",
        "    input = self.combine_z3_z2_z1_x(input)\n",
        "    #ottengo parametri della distribuzione in funzione dell'input z3,z2,z1 e x\n",
        "    [mean, log_std] = self.q_z4_z3_z2_z1_x(input)\n",
        "    #creo la distribuzione\n",
        "    q = MultivariateNormal(mean, torch.diag_embed( torch.clamp( torch.exp(log_std),min=1e-8)).to(device))\n",
        "    #campiono z4 col reparametrization trick\n",
        "    z4 = q.rsample()\n",
        "    #calcolo ln(q(z4|z3,z2,z1,x))\n",
        "    ln_q_z4_z3_z2_z1_x = q.log_prob(z4)\n",
        "\n",
        "    #ritorno gli z campionati e i loro logaritmi\n",
        "    return z1,z2,z3,z4, ln_q_z1_x, ln_q_z2_z1_x, ln_q_z3_z2_z1_x, ln_q_z4_z3_z2_z1_x\n",
        "\n"
      ],
      "metadata": {
        "id": "do_1ExqE3oVt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder"
      ],
      "metadata": {
        "id": "KdFitlcYK4bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_shape_image, latent_space_dimension, hidden_neurons,possible_pixel_values):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.input_shape_image = input_shape_image\n",
        "    self.possible_pixel_values = possible_pixel_values\n",
        "\n",
        "    #prior p(z4)=N(0,I)\n",
        "    self.p_z4 = MultivariateNormal(torch.zeros(latent_space_dimension).to(device), torch.eye(latent_space_dimension).to(device))\n",
        "\n",
        "    self.p_z3_z4 =  Block(latent_space_dimension, latent_space_dimension, hidden_neurons)\n",
        "\n",
        "    self.p_z2_z3 =  Block(latent_space_dimension, latent_space_dimension, hidden_neurons)\n",
        "\n",
        "    self.p_z1_z2 =  Block(latent_space_dimension, latent_space_dimension, hidden_neurons)\n",
        "\n",
        "    self.p_x_z1 = nn.Sequential(nn.Linear(latent_space_dimension, hidden_neurons),\n",
        "                                nn.ReLU(),\n",
        "                                nn.BatchNorm1d(hidden_neurons),\n",
        "                                nn.Linear(hidden_neurons,2*hidden_neurons),\n",
        "                                nn.ReLU(),\n",
        "                                nn.BatchNorm1d(2*hidden_neurons),\n",
        "                                nn.Linear(2*hidden_neurons,2*hidden_neurons),\n",
        "                                nn.ReLU(),\n",
        "                                #produco media e log std per z1\n",
        "                                nn.Linear(2*hidden_neurons, input_shape_image*possible_pixel_values),\n",
        "                                nn.LeakyReLU()\n",
        "                                )\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "\n",
        "    #campiono dalla prior p(z_4)=N(0,I)\n",
        "    z4 = self.p_z4.sample()\n",
        "    z4 = z4.unsqueeze(0)\n",
        "\n",
        "    #lo utilizzo per calcolarmi i parametri di p(z3|z4) e campionare z3\n",
        "    [mean, log_std] = self.p_z3_z4(z4)\n",
        "    z3 = MultivariateNormal(mean, torch.diag_embed( torch.clamp( torch.exp(log_std),min=1e-8))).sample()\n",
        "    #lo utilizzo per calcolarmi i parametri di p(z2|z3) e campionare z2\n",
        "    [mean, log_std] = self.p_z2_z3(z3)\n",
        "    z2 = MultivariateNormal(mean, torch.diag_embed( torch.clamp( torch.exp(log_std),min=1e-8))).sample()\n",
        "    #lo utilizzo per calcolarmi i parametri di p(z1|z2) e campionare z1\n",
        "    [mean, log_std] = self.p_z1_z2(z2)\n",
        "    z1 = MultivariateNormal(mean, torch.diag_embed( torch.clamp( torch.exp(log_std),min=1e-8))).sample()\n",
        "\n",
        "    #calcolo p(x|1)\n",
        "    output = self.p_x_z1(z1)\n",
        "\n",
        "    #reshape in (1, input_shape, possible_pixel_values)\n",
        "    logits = output.reshape(1,self.input_shape_image, self.possible_pixel_values)\n",
        "\n",
        "    #eseguo la softmax sull'ultimo livello\n",
        "    probabilities = torch.softmax(logits,dim=-1)\n",
        "\n",
        "    probabilities = probabilities.view(-1, self.possible_pixel_values)\n",
        "\n",
        "\n",
        "    sample = torch.multinomial(probabilities, num_samples=1)\n",
        "\n",
        "    x = sample.view(self.input_shape_image)\n",
        "    return x\n",
        "\n",
        "\n",
        "  def forward(self, z1,z2,z3,z4,x):\n",
        "\n",
        "    #calcolo ln(p(z4)) usando la prior N(0,I)\n",
        "    ln_p_z4 = self.p_z4.log_prob(z4)\n",
        "\n",
        "    #_____ p(z3|z4)________________________________\n",
        "    #calcolo i parametri della distribuzione p in funzione di z4\n",
        "    [mean, log_std] = self.p_z3_z4(z4)\n",
        "    #creo la distribuzione\n",
        "    q = MultivariateNormal(mean, torch.diag_embed( torch.clamp( torch.exp(log_std),min=1e-8)).to(device))\n",
        "    #valuto z3 campionato nella fase inferenziale con la prior\n",
        "    ln_p_z3_z4 = q.log_prob(z3)\n",
        "\n",
        "    #_____ p(z2|z3)________________________________\n",
        "    #calcolo i parametri della distribuzione p in funzione di z3\n",
        "    [mean, log_std] = self.p_z2_z3(z3)\n",
        "    #creo la distribuzione\n",
        "    q = MultivariateNormal(mean, torch.diag_embed( torch.clamp( torch.exp(log_std),min=1e-8)).to(device))\n",
        "    #valuto z2 campionato nella fase inferenziale con la prior\n",
        "    ln_p_z2_z3 = q.log_prob(z2)\n",
        "\n",
        "    #_____ p(z1|z2)________________________________\n",
        "    #calcolo i parametri della distribuzione p in funzione di z2\n",
        "    [mean, log_std] = self.p_z1_z2(z2)\n",
        "    #creo la distribuzione\n",
        "    q = MultivariateNormal(mean, torch.diag_embed( torch.clamp( torch.exp(log_std),min=1e-8)).to(device))\n",
        "    #valuto z1 campionato nella fase inferenziale con la prior\n",
        "    ln_p_z1_z2 = q.log_prob(z1)\n",
        "\n",
        "    #_____Ricostruzione dell'input x_______________\n",
        "    x = torch.flatten(x, start_dim=1, end_dim=2)\n",
        "\n",
        "    #utilizzo la rete per ricostruire l'immagine (N, input_shape*possible_pixel_values)\n",
        "    output = self.p_x_z1(z1)\n",
        "\n",
        "    #reshape in (N, input_shape, possible_pixel_values)\n",
        "    logits = output.reshape(output.shape[0],self.input_shape_image, self.possible_pixel_values)\n",
        "\n",
        "    #eseguo la softmax sull'ultimo livello\n",
        "    output_probabilities = torch.softmax(logits,dim=-1)\n",
        "    EPS = 1.e-5\n",
        "    output_probabilities = torch.clamp(output_probabilities, EPS,1. - EPS)\n",
        "\n",
        "    #li converto in logaritmi\n",
        "    log_probabilities = torch.log(output_probabilities)\n",
        "\n",
        "    #trasformo x in one hot encoding\n",
        "    x_one_hot = F.one_hot(x.long(),num_classes=self.possible_pixel_values)\n",
        "\n",
        "    #li utilizzo per azzerare la probabilità relativa al valore del pixel\n",
        "    selected_probabilities = x_one_hot*log_probabilities\n",
        "\n",
        "    #li sommo (N,), ossia ogni cella contiene la somma dei ln(p(x|z1)) per gli N x\n",
        "    #Questo sarebbe il Reconstruction Error\n",
        "    ln_p_x_z1 = selected_probabilities.sum(-1).sum(-1)\n",
        "\n",
        "    #ritorno il reconstruction error e tutte le p(zi|zi+1)\n",
        "    return ln_p_x_z1, ln_p_z1_z2, ln_p_z2_z3, ln_p_z3_z4, ln_p_z4\n",
        "\n"
      ],
      "metadata": {
        "id": "yGAPSUZRLZgP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ladder VAE"
      ],
      "metadata": {
        "id": "uAcuHg6HzGux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Ladder_VAE(nn.Module):\n",
        "  def __init__(self, input_shape_image, latent_space_dimension, hidden_neurons, possible_pixel_values):\n",
        "    super(Ladder_VAE, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(input_shape_image,latent_space_dimension,hidden_neurons,possible_pixel_values)\n",
        "\n",
        "    self.decoder = Decoder(input_shape_image,latent_space_dimension,hidden_neurons,possible_pixel_values)\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "    return self.decoder.sample()\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    #do all'encoder l'immagine x e ottengo z1,z2,z3,z4 e i rispettivi logaritmi\n",
        "    z1,z2,z3,z4, ln_q_z1_x, ln_q_z2_z1_x, ln_q_z3_z2_z1_x, ln_q_z4_z3_z2_z1_x = self.encoder(x)\n",
        "\n",
        "    #do al decoder i vari z per calcolarne la log prob con le loro prior e ottenere il reconstruction error\n",
        "    RE,ln_p_z1_z2, ln_p_z2_z3, ln_p_z3_z4, ln_p_z4 = self.decoder(z1,z2,z3,z4,x)\n",
        "\n",
        "    '''\n",
        "      Avendo 4 spazi latenti allora l'ELBO sarà:\n",
        "        ELBO = RE - KL1 - KL2 - KL3 - KL4\n",
        "\n",
        "      dove:\n",
        "\n",
        "        RE = ln(p(x|z1))  --> ritornato solo dall' decoder\n",
        "\n",
        "        KL1 = ln( q(z1|x)/p(z1|z2) )  --> q ritornato dall'encoder, p dal decoder\n",
        "\n",
        "        KLi = ln( q(zi|z_<i , x)/p(zi|z_i+1))   per i=2,3,4\n",
        "\n",
        "      NB: Sarebbe opportuno valutare l'expected value con (per esempio) un Monte-Carlo\n",
        "      approach ma qui per semplicità l'ho omesso (quindi solo un campione per approssimare\n",
        "      ciascune expected value). Guardare i primi VAE che ho implementato se si volesse\n",
        "      avere una idea su come implementare Monte-Carlo.\n",
        "\n",
        "      NB: esiste una versione successiva in cui calcolo la KL in maniera precisa grazie a un teorema\n",
        "\n",
        "    '''\n",
        "\n",
        "    KL1 = ln_q_z1_x - ln_p_z1_z2\n",
        "    KL2 = ln_q_z2_z1_x - ln_p_z2_z3\n",
        "    KL3 = ln_q_z3_z2_z1_x - ln_p_z3_z4\n",
        "    KL4 = ln_q_z4_z3_z2_z1_x - ln_p_z4\n",
        "\n",
        "    ELBO = (RE - KL1 - KL2 - KL3 - KL4).mean()\n",
        "\n",
        "    return -ELBO"
      ],
      "metadata": {
        "id": "yCKx4uk5yUVe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "VwoaF43RVQp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################### GPU + Path ##########################################\n",
        "\n",
        "# Controlla la disponibilità della GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Imposta il dispositivo sulla GPU\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Se la GPU non è disponibile, utilizza la CPU\n",
        "\n",
        "print(\"Device utilizzato:\", device)\n",
        "print(\"Numero di GPU disponibili:\", torch.cuda.device_count())\n",
        "\n",
        "\n",
        "#path dove salvare il modello migliore e i vari output di ogni epoca valida\n",
        "path_to_model = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/model/model_Ladder_Hierarchical_VAE.pth\"\n",
        "path_to_output = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/output/Ladder_Hierarchical_VAE_\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################### Dataloader ##########################################\n",
        "\n",
        "#per motivi di efficienza, scegliere il rescaling e il massimo valore che ogni pixel può assumere\n",
        "resize_to = 45\n",
        "max_pixel_value = 30\n",
        "\n",
        "input_shape_image = resize_to*resize_to\n",
        "possible_pixel_values = max_pixel_value+1\n",
        "\n",
        "\n",
        "def load_data():\n",
        "\n",
        "\n",
        "    # Definisci le trasformazioni da applicare alle immagini durante il caricamento\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize( (resize_to, resize_to) ), #rescaling di ogni immagine\n",
        "        transforms.Grayscale(),  # Trasforma l'immagine in bianco e nero\n",
        "        transforms.ToTensor(),# Converte l'immagine in un tensore\n",
        "        transforms.Lambda(lambda x: torch.round(x*(max_pixel_value))), #normalizzo i valori dei pixel e li forzo ad essere interi\n",
        "        #transforms.Lambda(lambda x: x.to(torch.float32))\n",
        "    ])\n",
        "\n",
        "    # Crea un oggetto ImageFolder per caricare le immagini dalla cartella specificata e applica le trasformazioni definite\n",
        "    dataset = datasets.ImageFolder('/content/dataset/', transform=transform)\n",
        "\n",
        "    # Calcola l'indice per dividere il dataset tra training set e validation set\n",
        "    split_ratio = 0.8  # Ratio di suddivisione (80% per il training set, 20% per il validation set)\n",
        "    dataset_size = len(dataset)\n",
        "    split_index = int(split_ratio * dataset_size)\n",
        "\n",
        "    # Crea due sottoinsiemi distinti per il training set e il validation set\n",
        "    train_dataset = Subset(dataset, range(0, split_index))\n",
        "    val_dataset = Subset(dataset, range(split_index, dataset_size))\n",
        "\n",
        "    # Crea i DataLoader per il training set e il validation set\n",
        "    batch_size = 32\n",
        "    training_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "    validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return training_loader, validation_loader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################### Training + validation #####################################\n",
        "\n",
        "def train_model_on_given_gpu():\n",
        "\n",
        "    #definisco la dimensione dello spazio latente\n",
        "    latent_space_dimension = 36 #deve essere intera la sua radice quadrata\n",
        "    #nuumero di hidden neurons nell'encoder e decoder\n",
        "    hidden_neurons = 64\n",
        "\n",
        "\n",
        "    #---- creazione del modello\n",
        "\n",
        "    model = Ladder_VAE(input_shape_image, latent_space_dimension, hidden_neurons,possible_pixel_values)\n",
        "    model.to(device)\n",
        "\n",
        "    # Esegui un passaggio di inoltro dummy per il LazyLinear\n",
        "    inputs = torch.round(torch.rand((2, resize_to, resize_to),dtype=torch.float32)*max_pixel_value).to(device)\n",
        "    print(\"inputs\", inputs.shape)\n",
        "    dummy_output = model(inputs).item()\n",
        "\n",
        "    print(\"Numero parametri modello: \",sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    #parametri per il learning\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    parameters_to_optimize = [p for p in model.parameters() if p.requires_grad == True]\n",
        "\n",
        "    optimizer = torch.optim.Adamax(parameters_to_optimize, lr=learning_rate)\n",
        "\n",
        "\n",
        "    #------ Funzione per salvare una griglia di campioni decodificati dallo spazio latente ogni volta che la validation è migliore\n",
        "    def sample_and_save(model, name, input_shape):\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      #voglio campionare 16 immagini e le voglio in una griglia 4x4\n",
        "      n=4\n",
        "      number_of_grid_cells = n*n\n",
        "      #quindi dico al modello di campionarmi 16 immagini\n",
        "      xs = np.zeros((number_of_grid_cells,input_shape))\n",
        "      for i in np.arange(number_of_grid_cells):\n",
        "        generated_sample = model.sample().cpu() # il .module serve per andare oltre il wrapping di DataParallel\n",
        "        #lo stacco dal grafo di computazione\n",
        "        generated_sample = generated_sample.detach().numpy()\n",
        "        xs[i,:] = generated_sample\n",
        "\n",
        "\n",
        "      fig, ax = plt.subplots(n, n)\n",
        "      for i, ax in enumerate(ax.flatten()):\n",
        "          plottable_image = np.reshape(xs[i], (int(math.sqrt(input_shape)), int(math.sqrt(input_shape))))\n",
        "          ax.imshow(plottable_image, cmap='gray')\n",
        "          ax.axis('off')\n",
        "\n",
        "      plt.savefig(path_to_output+'epoca_' +str(name)+ '.pdf', bbox_inches='tight')\n",
        "      plt.close()\n",
        "\n",
        "\n",
        "\n",
        "    #---- Training e validation\n",
        "    number_of_epochs = 1000\n",
        "    #fisso il limite massimo di batch di training e validazione\n",
        "    max_batch_for_training = 800\n",
        "    max_batch_for_validation = 170\n",
        "\n",
        "\n",
        "    #qui salvo il migliore modello, ossia quello che ha la loss sulla validazione migliore\n",
        "    best_model = model\n",
        "    best_validation_loss = 1000000\n",
        "\n",
        "    patience = 0\n",
        "    max_patience = 30\n",
        "\n",
        "    training_loader, validation_loader = load_data()\n",
        "\n",
        "    grd_acc = 1\n",
        "\n",
        "    for epoch in range(number_of_epochs):\n",
        "      model.train()\n",
        "      print(\"Epoca \"+str(epoch)+\" _____________________________________________________________________\")\n",
        "\n",
        "      num_batch = 1\n",
        "      for batch, _ in training_loader:\n",
        "\n",
        "        #reshaping di ogni batch da (N, 1, W, H) a (N, W, H)\n",
        "        batch = batch.squeeze(1)\n",
        "\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        loss = model.forward(batch)\n",
        "\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        #calcolo le derivate parziali della loss rispetto ogni parametro NB: LA mean() E' PERCHE' UTILIZZO N GPU E CIASCUNA RITORNA LA SUA LOSS\n",
        "        (loss.mean()/grd_acc).backward(retain_graph=True)\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        #se ho accumulato il gradiente di un numero sufficiente di batch, allora backpropago\n",
        "        if ( (num_batch % grd_acc) == 0):\n",
        "            #adesso ogni parametro ha in .grad il gradiente. Aggiorno il suo valore\n",
        "            optimizer.step()\n",
        "\n",
        "            #resetto il .grad di ogni parametro (altrimenti sommo quello attuale al successivo che calcoleremo nell'epoca dopo)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(\"   Loss batch: \",str(num_batch),\": \", loss, \"          Memoria GPU utilizzata  -> \", round(torch.cuda.memory_allocated()*(1e-9),4), \"GB\")\n",
        "\n",
        "        #se ho superato il numero massimo di batch per il training, esco\n",
        "        if num_batch >= max_batch_for_training:\n",
        "            break\n",
        "        else:\n",
        "            num_batch = num_batch + 1\n",
        "\n",
        "      #alla fine di ogni epoca, valuto come si comporta la loss col validation set\n",
        "      print(\"   ___________________________\")\n",
        "      model.eval()\n",
        "      validation_loss = 0\n",
        "      N = 0\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      num_batch = 1\n",
        "      for batch, _ in validation_loader:\n",
        "\n",
        "        batch = batch.squeeze(1)\n",
        "        batch = batch.to(device)\n",
        "        #batch = batch.to(torch.float32)\n",
        "        loss_i = model.forward(batch)\n",
        "        validation_loss = validation_loss + loss_i.mean().item()# NB: .mean() SOLO PERCH' UTILIZZO N GPU E QUINDI VOGLIO LA MEDIA DI OGNI LOSS RITORNATA DA OGNI GPU\n",
        "        N = N +  1\n",
        "\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(\"   Loss validation batch \",str(num_batch),\": \",loss_i)\n",
        "        #se ho superato il numero massimo di batch per il validation, esco\n",
        "        if num_batch >= max_batch_for_validation:\n",
        "            break\n",
        "        else:\n",
        "            num_batch = num_batch + 1\n",
        "\n",
        "        del loss_i\n",
        "\n",
        "      validation_loss = validation_loss/N\n",
        "      print(\"   Loss media validation: \",str(validation_loss))\n",
        "\n",
        "      #se tale modello ha una loss migliore di quella attualmente migliore..\n",
        "      if validation_loss < best_validation_loss:\n",
        "        patience = 0\n",
        "        best_validation_loss = validation_loss\n",
        "        print(\"   la loss risulta essere migliore\")\n",
        "        torch.save(model.state_dict(), path_to_model)\n",
        "        #campiono e salvo\n",
        "        sample_and_save(model, epoch, input_shape_image)\n",
        "      else:\n",
        "        print(\"   patience= \"+ str(patience+1))\n",
        "        patience = patience + 1\n",
        "\n",
        "      if patience > max_patience:\n",
        "        print(\"\")\n",
        "        print(\"Patience massimo superato. Fine del training\")\n",
        "        break\n",
        "\n",
        "      del validation_loss\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "\n",
        "    train_model_on_given_gpu()"
      ],
      "metadata": {
        "id": "uBa71JKDVSPN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3eHIGurE7SVO",
        "Qoe94xCIT4Nl",
        "xzn0YrUaaWjx",
        "JSbtnul3nT1-",
        "8ei2LlGs5C2q",
        "cuc9qvyWWHUf",
        "s8rcWdkX9In4",
        "7iZsvZOfgOgW",
        "u_P94_AwVz8o"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YmxK034M6v7X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.datasets import load_digits\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Controlla la disponibilità della GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Imposta il dispositivo sulla GPU\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Se la GPU non è disponibile, utilizza la CPU\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "JbQBUpStOG34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46da3814-ec0d-48b9-b1af-b229ce73a406"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_model = \"/content/\"\n",
        "path_to_output = \"/content/my\" #crea la cartella \"my\""
      ],
      "metadata": {
        "id": "wM1JJIxd1Zan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 1"
      ],
      "metadata": {
        "id": "3eHIGurE7SVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Abbiamo 1797 campioni, ciascuno 8x8. Ogni immagine è organizzata come un vettore di 64 pixel\n",
        "fashioneMNIST = FashionMNIST(\"./\", download=True)\n",
        "fashioneMNIST\n",
        "\n",
        "print(fashioneMNIST)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYPMHwO6k3_R",
        "outputId": "28ba5259-4511-478a-b745-827a035cfe47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./\n",
            "    Split: Train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img1 = fashioneMNIST.data[1]\n",
        "print(img1.shape)\n",
        "\n",
        "plt.imshow(img1,cmap='Greys', interpolation='none')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "xOzMXbwxl_7X",
        "outputId": "a2fe8cf7-fa1f-4e37-eee9-7f2725e3789c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7b2e7409d0>"
            ]
          },
          "metadata": {},
          "execution_count": 270
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#essendo ogni riga una immagine allora prendo le prime 50000 come training set, 5000 come validation set e il resto come test set\n",
        "training_data = fashioneMNIST.data[0:50000].float()\n",
        "validation_data = fashioneMNIST.data[50000:55000].float()\n",
        "test_data = fashioneMNIST.data[55000:].float()"
      ],
      "metadata": {
        "id": "rH56FdMIlpbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "input_shape_image = 28*28\n",
        "possible_pixel_values = 256 # ossia {0,1,...,255}"
      ],
      "metadata": {
        "id": "V_vEwyTKa8ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 1 normalizzato tra 0 e 10"
      ],
      "metadata": {
        "id": "Qoe94xCIT4Nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Abbiamo 1797 campioni, ciascuno 8x8. Ogni immagine è organizzata come un vettore di 64 pixel\n",
        "fashioneMNIST = FashionMNIST(\"./\", download=True)\n",
        "fashioneMNIST\n",
        "\n",
        "print(fashioneMNIST)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e946bd-14d3-4af5-c067-49e94a366361",
        "id": "cYZWtrPhT-2i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./\n",
            "    Split: Train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = torch.round(((fashioneMNIST.data / 255) * 10))"
      ],
      "metadata": {
        "id": "YQY5VpZGT-2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img1 = d[1]\n",
        "print(img1.shape)\n",
        "\n",
        "plt.imshow(img1,cmap='Greys', interpolation='none')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "03943b43-af9c-458a-ba1c-bf32269170b3",
        "id": "Kw8GwqhzT-2j"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9290f53fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#essendo ogni riga una immagine allora prendo le prime 50000 come training set, 5000 come validation set e il resto come test set\n",
        "training_data = d.data[0:2000].float()\n",
        "validation_data = d.data[2000:3000].float()\n",
        "test_data = d.data[3000:4000].float()"
      ],
      "metadata": {
        "id": "yeTHbwS-T-2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "input_shape_image = 28*28\n",
        "possible_pixel_values = 11 # ossia {0,1,...,10}"
      ],
      "metadata": {
        "id": "grwmawsUT-2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 2 (digits)"
      ],
      "metadata": {
        "id": "xzn0YrUaaWjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Abbiamo 1797 campioni, ciascuno 8x8. Ogni immagine è organizzata come un vettore di 64 pixel\n",
        "digits_dataset = load_digits()\n",
        "\n",
        "print(digits_dataset.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d1cf37-6b2a-4ac2-a6e9-d24f5c4659c2",
        "id": "IWpMp1aOakYx"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#ogni riga è una immagine. Vediamo un esempio\n",
        "img1 = digits_dataset.data[0]\n",
        "#facciamo il reshape del vettore di 64 elementi in 8x8\n",
        "img1 = np.reshape(img1, (8,8))\n",
        "plt.imshow(img1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "687208e9-441b-4c05-872f-108c894ba948",
        "id": "zt0evHxEakYx"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faebec1b820>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#essendo ogni riga una immagine allora prendo le prime 1000 come training set, 350 come validation set e il resto come test set\n",
        "training_data = digits_dataset.data[0:1000].astype(np.float32)\n",
        "validation_data = digits_dataset.data[1000:1350].astype(np.float32)\n",
        "test_data = digits_dataset.data[1350:].astype(np.float32)"
      ],
      "metadata": {
        "id": "BQcWZ6-OakYy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "input_shape_image = 8*8\n",
        "possible_pixel_values = 17 # ossia {0,1,...,16}"
      ],
      "metadata": {
        "id": "hGkkAp-2a3u5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 3 (locale) Emoticons 72x72"
      ],
      "metadata": {
        "id": "JSbtnul3nT1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJQlaLFWnwh-",
        "outputId": "475d2834-c36c-41e5-b639-111dead9ed22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Generative_AI/datasets/Emoticons_72x72'\n",
        "\n",
        "image_data = []\n",
        "\n",
        "resize_to = 40\n",
        "max_value = 15\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    print(\"Carico \"+file_path)\n",
        "    # Carica l'immagine in bianco e nero utilizzando PIL\n",
        "    img = Image.open(file_path).convert('L')\n",
        "    # Ridimensiona l'immagine a 10x10 pixel utilizzando numpy\n",
        "    img_resized = np.array(img.resize((resize_to, resize_to)))\n",
        "    # Normalizza i valori dei pixel nell'intervallo da 0 a 10 utilizzando numpy\n",
        "    img_normalized = np.round((img_resized / 255) * max_value).astype(int)\n",
        "    # Aggiungi l'immagine normalizzata alla lista dei dati\n",
        "    image_data.append(img_normalized)\n",
        "\n",
        "# Converti la lista dei dati in un array numpy\n",
        "image_data = np.array(image_data)\n",
        "\n",
        "# Ottieni il numero totale di immagini lette\n",
        "N = image_data.shape[0]\n",
        "\n",
        "# Reshape dell'array delle immagini in (N, 10, 10)\n",
        "image_data_reshaped = image_data.reshape(N, resize_to, resize_to)\n",
        "\n",
        "print(image_data_reshaped.shape)\n"
      ],
      "metadata": {
        "id": "HwOn6Nd-oMRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#ogni riga è una immagine. Vediamo un esempio\n",
        "img1 = image_data_reshaped[35]\n",
        "plt.imshow(img1,cmap='Greys', interpolation='none')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "SiXgaK79osML",
        "outputId": "6d6e154f-0e99-4376-e7b2-bc54c643cb95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f40dc7e4820>"
            ]
          },
          "metadata": {},
          "execution_count": 243
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#essendo ogni riga una immagine allora prendo le prime 1000 come training set, 350 come validation set e il resto come test set\n",
        "training_data = image_data_reshaped[0:1000].astype(np.float32)\n",
        "validation_data = image_data_reshaped[1000:1800].astype(np.float32)\n",
        "test_data = image_data_reshaped[1800:].astype(np.float32)"
      ],
      "metadata": {
        "id": "ePUL64nBpfP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "input_shape_image = resize_to*resize_to\n",
        "possible_pixel_values = max_value+1 # ossia {0,1,...,max_value}"
      ],
      "metadata": {
        "id": "zapmO6HNpfQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 4 (locale) Emoticons 15x15"
      ],
      "metadata": {
        "id": "8ei2LlGs5C2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948a2710-f4ed-4152-9661-245de8363b90",
        "id": "lpyr_3RG5HZT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Generative_AI/datasets/Emoticons_15x15'\n",
        "\n",
        "image_data = []\n",
        "\n",
        "resize_to = 15\n",
        "max_value = 20\n",
        "\n",
        "#emoticons with a smile\n",
        "index_of_example = -1\n",
        "i=0\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename==\"9.png\":\n",
        "      index_of_example = i\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    print(\"Carico \"+file_path)\n",
        "    # Carica l'immagine in bianco e nero utilizzando PIL\n",
        "    img = Image.open(file_path).convert('L')\n",
        "    # Ridimensiona l'immagine a 10x10 pixel utilizzando numpy\n",
        "    img_resized = np.array(img.resize((resize_to, resize_to)))\n",
        "    # Normalizza i valori dei pixel nell'intervallo da 0 a 10 utilizzando numpy\n",
        "    img_normalized = np.round((img_resized / 255) * max_value).astype(int)\n",
        "    # Aggiungi l'immagine normalizzata alla lista dei dati\n",
        "    image_data.append(img_normalized)\n",
        "    i=i+1\n",
        "\n",
        "# Converti la lista dei dati in un array numpy\n",
        "image_data = np.array(image_data)\n",
        "\n",
        "# Ottieni il numero totale di immagini lette\n",
        "N = image_data.shape[0]\n",
        "\n",
        "# Reshape dell'array delle immagini in (N, 10, 10)\n",
        "image_data_reshaped = image_data.reshape(N, resize_to, resize_to)\n",
        "\n",
        "print(image_data_reshaped.shape)\n"
      ],
      "metadata": {
        "id": "QaFA44QC5HZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#ogni riga è una immagine. Vediamo un esempio\n",
        "img1 = image_data_reshaped[index_of_example]\n",
        "plt.imshow(img1,cmap='Greys', interpolation='none')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "23010a30-ff13-4107-8580-758eaed14c00",
        "id": "eaEyn-tB5HZU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f40e94d7f40>"
            ]
          },
          "metadata": {},
          "execution_count": 193
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#essendo ogni riga una immagine allora prendo le prime 1000 come training set, 350 come validation set e il resto come test set\n",
        "training_data = image_data_reshaped[0:1000].astype(np.float32)\n",
        "validation_data = image_data_reshaped[1000:1500].astype(np.float32)\n",
        "test_data = image_data_reshaped[1500:].astype(np.float32)"
      ],
      "metadata": {
        "id": "8gKEXWaI5HZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "input_shape_image = resize_to*resize_to\n",
        "possible_pixel_values = max_value+1 # ossia {0,1,...,max_value}"
      ],
      "metadata": {
        "id": "8Ot7M3oz5HZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 5 (Frey Face)"
      ],
      "metadata": {
        "id": "cuc9qvyWWHUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAR-zlTeWXRo",
        "outputId": "99ec9943-b432-4572-ae7f-e181b7282173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "\n",
        "# Carica il file .mat\n",
        "data = scipy.io.loadmat('/content/drive/MyDrive/Generative_AI/datasets/frey_rawface.mat')"
      ],
      "metadata": {
        "id": "9FVLK-OdWJ81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data['ff'].T\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5fY0RULWy61",
        "outputId": "db5720ed-84e8-40f4-bb63-3c04c1db2b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 81, 136, 167, ..., 152, 158, 164],\n",
              "       [ 85, 138, 165, ..., 167, 178, 184],\n",
              "       [ 87, 139, 166, ..., 172, 177, 183],\n",
              "       ...,\n",
              "       [ 80,  84, 155, ..., 111, 186, 182],\n",
              "       [ 73,  86, 131, ..., 135, 167, 177],\n",
              "       [ 58,  89, 110, ..., 166, 177, 184]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.reshape(1965,28,20)"
      ],
      "metadata": {
        "id": "f-Yh3DqEXmDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "# Converte la matrice in un oggetto immagine di tipo Pillow\n",
        "image_list = [Image.fromarray(data[i]) for i in range(data.shape[0])]\n",
        "\n",
        "# Ridimensiona tutte le immagini nella lista all'altezza e larghezza desiderate\n",
        "new_image_list = [image.resize((28, 28)) for image in image_list]\n",
        "\n",
        "# Converti le immagini ridimensionate in una nuova matrice\n",
        "resized_data = np.array([np.array(image) for image in new_image_list])\n",
        "\n",
        "max_value = 20\n",
        "#normalizza\n",
        "img_normalized = np.round((resized_data / 255) * max_value).astype(int)"
      ],
      "metadata": {
        "id": "XVUkf3TTaOxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (5, 5) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "#ogni riga è una immagine. Vediamo un esempio\n",
        "img1 = img_normalized[1120]\n",
        "print(img1.shape)\n",
        "plt.imshow(img1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "4352e611-3c75-4d67-b127-e37a46bbbfa1",
        "id": "wrA4figkX0fm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f40dde291e0>"
            ]
          },
          "metadata": {},
          "execution_count": 309
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#essendo ogni riga una immagine allora prendo le prime 1000 come training set, 350 come validation set e il resto come test set\n",
        "training_data = img_normalized[0:1300].astype(np.float32)\n",
        "validation_data = img_normalized[1300:1800].astype(np.float32)\n",
        "test_data = img_normalized[1800:].astype(np.float32)"
      ],
      "metadata": {
        "id": "JfhOkC2FX0fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "resize_to = 28\n",
        "input_shape_image = resize_to*resize_to\n",
        "possible_pixel_values = max_value+1 # ossia {0,1,...,max_value}"
      ],
      "metadata": {
        "id": "9csDpf8KX0fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 6 (Celeb face)"
      ],
      "metadata": {
        "id": "-Q97vaC3NlqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5H0sxy_4QYm",
        "outputId": "1bf55cd9-3a7f-44de-f314-e04c5e79b8b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_model = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/model\"\n",
        "path_to_output = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/output\""
      ],
      "metadata": {
        "id": "rnxO1SFI4UQn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing"
      ],
      "metadata": {
        "id": "QzT5im-Dog4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# Imposta il percorso della cartella contenente le immagini\n",
        "#scarica prima img_align_celeba.zip da https://drive.google.com/drive/u/0/folders/0B7EVK8r0v71pWEZsZE9oNnFzTm8?resourcekey=0-5BR16BdXnb8hVj6CNHKzLg\n",
        "folder_path = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/all\"\n",
        "\n",
        "# Imposta le dimensioni di resize desiderate\n",
        "resize_to = 100  # Specifica la larghezza (W) e l'altezza (H)\n",
        "max_value = 20\n",
        "\n",
        "# Crea una lista per salvare le immagini pre-elaborate\n",
        "processed_images = []\n",
        "\n",
        "# Crea una trasformazione di pre-elaborazione utilizzando torchvision.transforms.Compose\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((resize_to,resize_to)),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0, max_value),\n",
        "])\n",
        "\n",
        "# Itera sui file nella cartella\n",
        "i=0\n",
        "for file_name in os.listdir(folder_path):\n",
        "    print(i+1,\" -> \",file_name)\n",
        "    i=i+1\n",
        "    # Crea il percorso completo del file\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "    # Carica l'immagine utilizzando PIL\n",
        "    image = Image.open(file_path)\n",
        "\n",
        "    # Applica le trasformazioni di pre-elaborazione all'immagine\n",
        "    processed_image = preprocess(image)\n",
        "\n",
        "    # Aggiungi l'immagine pre-elaborata alla lista\n",
        "    processed_images.append(processed_image)\n",
        "\n",
        "# Converte la lista di immagini in una matrice numpy\n",
        "image_matrix = np.stack(processed_images)\n",
        "\n",
        "# Ottieni le dimensioni della matrice delle immagini\n",
        "N, W, H = image_matrix.shape[0], image_matrix.shape[1], image_matrix.shape[2]\n",
        "\n",
        "# Visualizza le dimensioni della matrice delle immagini\n",
        "print(\"Dimensioni della matrice delle immagini:\", (N, W, H))\n"
      ],
      "metadata": {
        "id": "xRd1dvr1oh3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Imposta il percorso del file di output\n",
        "file_path = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/celebA.npy\"\n",
        "\n",
        "# Salva l'array nel file utilizzando np.save()\n",
        "np.save(file_path, processed_images)\n",
        "\n",
        "print(\"Array salvato correttamente.\")\n"
      ],
      "metadata": {
        "id": "jyQ99tm5c1WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/celebA.npy\"\n",
        "dataset = np.load(file_path,allow_pickle=True)\n",
        "\n",
        "dataset.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE6ExjRUeg7x",
        "outputId": "8a94399a-7800-464d-a04a-16a0f29d1a3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28638"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_matrix = np.stack(dataset)\n",
        "image_matrix.squeeze(1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OpykpldjH3M",
        "outputId": "6e36d82f-3e0b-44f2-ef5d-77d57b7241d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28638, 100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import ndimage\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "resize_to = 90\n",
        "\n",
        "# Converti ndarray in tensor PyTorch\n",
        "input_tensor = torch.from_numpy(image_matrix)\n",
        "\n",
        "\n",
        "# Crea una trasformazione per il ridimensionamento\n",
        "resize = transforms.Resize((resize_to, resize_to))\n",
        "\n",
        "\n",
        "# Applica la trasformazione al tensor\n",
        "output_tensor = resize(input_tensor)\n",
        "\n",
        "# Converti il tensor in ndarray\n",
        "image_matrix = output_tensor.numpy()\n",
        "\n"
      ],
      "metadata": {
        "id": "32Jg1CjUlIvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d7663f-9333-478f-abe7-7b5097d0e3ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_value = 20\n",
        "image_matrix = (image_matrix*20*max_value).astype(int)"
      ],
      "metadata": {
        "id": "sSE9KKbx-ObA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = (5, 5) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "#ogni riga è una immagine. Vediamo un esempio\n",
        "img1= image_matrix[100].squeeze(0)\n",
        "print(img1.shape)\n",
        "plt.imshow(img1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "5SPZNe28cDbm",
        "outputId": "168a5ab5-0349-43a5-93a7-6497b95da9b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 100)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f43e5d22e90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#essendo ogni riga una immagine allora prendo le prime 50000 come training set, 5000 come validation set e il resto come test set\n",
        "training_data = image_matrix.squeeze(1)[0:26000]\n",
        "validation_data = image_matrix.squeeze(1)[26000:]\n",
        "#test_data = d.data[3000:4000]"
      ],
      "metadata": {
        "id": "GZJWw1YHd4A-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "resize_to = 100 # se hai fatto il resize prima, commenta\n",
        "input_shape_image = resize_to*resize_to\n",
        "possible_pixel_values = max_value+1 # ossia {0,1,...,20}"
      ],
      "metadata": {
        "id": "hw4SGPg8d4BJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "#elimino per liberare memoria\n",
        "del image_matrix\n",
        "del dataset\n",
        "#forzo il garbage collector a operare adesso\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-MNHWtvm2N_",
        "outputId": "735afa9c-830a-437a-db3c-c1c52b774540"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "TrqW_O67as26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non alleneremo la rete dandole tutti i dati, ma batch dopo batch. Creiamo quindi un DataLoader che semplicemente dividerà i dati in batch da 64 immagini (dopo averli mischiati) e ci restituirà, quando richiesto, un batch alla volta."
      ],
      "metadata": {
        "id": "mIp49CvLncr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "validation_loader = DataLoader(validation_data, batch_size=16, shuffle=True)\n",
        "#test_loader = DataLoader(test_data, batch_size=256, shuffle=True)"
      ],
      "metadata": {
        "id": "QO_kV43ulD3w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model (no-gpu ma più chiaro da comprendere) (Vedi sotto per la versione gpu)"
      ],
      "metadata": {
        "id": "s8rcWdkX9In4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "hyperparameters"
      ],
      "metadata": {
        "id": "8lQp7sWb9vC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#definisco la dimensione dello spazio latente\n",
        "latent_space_dimension = 32\n",
        "#nuumero di hidden neurons nell'encoder e decoder\n",
        "number_of_hidden_neurons = 256"
      ],
      "metadata": {
        "id": "5kwFVRrP9wHH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "bbcqmHWzzXTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_shape_image, latent_space_dimension, number_of_hidden_neurons, L):\n",
        "    super(Encoder,self).__init__()\n",
        "\n",
        "    #numero di campioni per l'approssimazione Monte-Carlo dell'Expected Value\n",
        "    self.L = L\n",
        "\n",
        "    self.input_shape_image = input_shape_image\n",
        "\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "\n",
        "    self.encoder = nn.Sequential(nn.Linear(input_shape_image,number_of_hidden_neurons*2),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 nn.Linear(number_of_hidden_neurons*2,number_of_hidden_neurons),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 #moltiplico per 2 perchè voglio sia il vettore di media che std (diagonale)\n",
        "                                 nn.Linear(number_of_hidden_neurons,2*latent_space_dimension))\n",
        "    \n",
        "  def KL_loss(self,log_std_vector,mean_vector, batch_length):\n",
        "\n",
        "    '''\n",
        "      Per approssimare l'expected value E[ln(q|z)]-E[ln(p(z))] utilizzo un approccio \n",
        "      Monte-Carlo approssimando ciascun expected value con L volte le quantità interne\n",
        "      che ottengo per L campionamenti di z\n",
        "    '''\n",
        "    print(\"ENCODER: Calcolo KL_loss e ritorno dei vettori z\")\n",
        "    L = self.L\n",
        "\n",
        "    #contiene le KL_loss ottenute da ogni immagine\n",
        "    KL_loss = torch.zeros(batch_length)\n",
        "\n",
        "    #creo la prior p(z)=N(z|0,I), è sempre la stessa\n",
        "    p_z = MultivariateNormal(torch.zeros(self.latent_space_dimension), torch.eye(self.latent_space_dimension))\n",
        "\n",
        "    #nota che ho un vettore di medie e std per ogni immagine, quindi devo calcolare\n",
        "    #KL_loss diverse volte e poi alla fine ottenere un unico KL_loss per media\n",
        "    #print(\"Per \",batch_length, \" immagini...\")\n",
        "\n",
        "    #siccome al decoder serviranno gli stessi z che io qui sto campionando, allora me li salvo\n",
        "    z_sampled_per_image = torch.zeros(batch_length,L,self.latent_space_dimension)\n",
        "\n",
        "    for x_i in np.arange(batch_length):\n",
        "      print(\"   Considero immagine \"+str(x_i))\n",
        "      \n",
        "      mean_vector_i = mean_vector[x_i]\n",
        "      log_std_vector_i = log_std_vector[x_i]\n",
        "      print(\"     mean-vector \",mean_vector_i)\n",
        "      print(\"     std-vector \",log_std_vector_i)\n",
        "      #print(\"dimensione vettore medie: \",mean_vector_i.shape)\n",
        "      #print(\"dimensione vettore ln std: \",log_std_vector_i.shape)\n",
        "\n",
        "      #calcolo la distribuzione multivariata q(z|x) creata da quell'x\n",
        "      q_z_x = MultivariateNormal(mean_vector_i, torch.eye(self.latent_space_dimension)*torch.exp(log_std_vector_i))\n",
        "\n",
        "      #KL per l'immagine corrente\n",
        "      KL_per_image = 0\n",
        "      #le due due quantità che andranno sottratte per calcolare KL_per_image\n",
        "      quantity1 = 0\n",
        "      quantity2 = 0\n",
        "\n",
        "      print(\"     Campiono  \",L,\" vettori z\")\n",
        "      #campiono L vettori z\n",
        "      for i in np.arange(L):\n",
        "\n",
        "        #Campiono z^(i)\n",
        "\n",
        "        #campiono le 64 componenti z^(i)_j con la tecnica della reparametrizzazione\n",
        "        #converto il logaritmo della deviazione standard in deviazione standard pura\n",
        "        std = torch.exp(0.5*log_std_vector_i)\n",
        "        #print(std.shape)\n",
        "        #campiono N eps dove N è la dimensione del vettore eps (64) da una N(0,1)\n",
        "        eps = torch.randn_like(std)\n",
        "        #print(eps.shape)\n",
        "        #campiono le 64 componenti diz da N(u,E) che equivale a campionare \n",
        "        #ciascuna componente z_i come z_i = u_i + std_i*eps_i\n",
        "        z = mean_vector_i + std*eps\n",
        "        #z è una vettore (1,64)\n",
        "        #me lo salvo (servirà dopo al decoder)\n",
        "        z_sampled_per_image[x_i,i,:] = z\n",
        "        \n",
        "\n",
        "        #calcolo ln(q(z|x))\n",
        "        ln_q_z_x = q_z_x.log_prob(z)\n",
        "        \n",
        "        #da eliminare (TODO)\n",
        "        da_eliminare1 = -0.5 * z.shape[0] * torch.log(2. * PI) - 0.5 * log_std_vector_i - 0.5 * torch.exp(-log_std_vector_i) * (z - mean_vector_i)**2.\n",
        "        print(\"****** Confronto tra la mia ln(q(z|x) e quella del libro: \",ln_q_z_x, \"  VS  \",da_eliminare1.sum(-1), \"   con D=\",z.shape[0])\n",
        "        \n",
        "        #calcolo ln(p(z))\n",
        "        ln_p_z = p_z.log_prob(z)\n",
        "\n",
        "        #print(ln_q_z_x,\"   \",ln_p_z)\n",
        "        print(\"       Inserisco nella matrice di vettori campionati \",z_sampled_per_image, \" con ln(q(z|x))= \",ln_q_z_x, \" e ln(p(z))=\",ln_p_z)\n",
        "\n",
        "        quantity1 = quantity1 + ln_q_z_x #Sommatoria(ln(q(z|x)))\n",
        "        quantity2 = quantity2 + ln_p_z   #Sommatoria(ln(p(z)))\n",
        "        print(\"       Aggiorno le sommatorie -->Sommatoria(ln(q(z|x)))=\",quantity1,\"   Sommatoria(ln(p(z)))=\",quantity2)\n",
        "\n",
        "      #calcolo KL (Monte-Carlo) per la corrente immagine di input\n",
        "      # SUM(ln(q(z|x))) - SUM(ln(p(z)))\n",
        "      KL_per_image = quantity1/L - quantity2/L\n",
        "      print(\" Calcolo il KL_per_image=\", KL_per_image)\n",
        "      \n",
        "      #Terminato, ho la KL dell'immagine corrente, la salvo nel vettore\n",
        "      KL_loss[x_i] = KL_per_image\n",
        "      print(\" Aggiorno il KL_loss=\", KL_loss)\n",
        "    \n",
        "    #Terminato, avremo una KL_loss che conterrà le KL_loss di ogni immagine (sommate).\n",
        "    # Non ne calcolo la media adesso, ma dopo perchè ho bisogno del RE\n",
        "\n",
        "    return KL_loss,z_sampled_per_image\n",
        "\n",
        "\n",
        "    #La rete ritorna il vettore di media, std (diagonale) e la z campionata\n",
        "  def forward(self, x):\n",
        "    #flatto il batch (64, 28, 28) in (64, 784)\n",
        "    x = torch.flatten(x,1)\n",
        "    #print(x.shape)\n",
        "    #do alla rete x e prelevo vettore di media e std (diagonale)\n",
        "    output = self.encoder(x)\n",
        "    #print(output.shape)\n",
        "    #divido il risultato in due parti: media e std (diagonale)(logaritmica)\n",
        "    mean_vector, log_std_vector = torch.chunk(output, 2, dim=1)\n",
        "    #print(mean_vector.shape)\n",
        "    #print(log_std_vector.shape)\n",
        "\n",
        "\n",
        "    #Calcoliamo la prima parte della Loss, chiamata KL(q(u,E)||p(z)) dove per semplicità\n",
        "    #approssimiamo l'expected value con un Monte-Carlo approach di L pari a L.\n",
        "    #La loss ottenuta è un vettore contenente la KL per ogni immagine\n",
        "    KL_loss_vector, z_samples_per_image = self.KL_loss(log_std_vector,mean_vector, x.shape[0])\n",
        "    #print(\"KL_loss \",KL_loss)\n",
        "    print(\"Encoder (forward): ritorno quanto ottenuto\")\n",
        "    print(\" Kl-loss  -> \",KL_loss_vector)\n",
        "    print(\" z-samples  ->\",z_samples_per_image)\n",
        "    return KL_loss_vector,z_samples_per_image\n",
        "\n"
      ],
      "metadata": {
        "id": "xsTiW9ZP9JSi"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder"
      ],
      "metadata": {
        "id": "29J5G_vGzZSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_shape_image,latent_space_dimension, number_of_hidden_neurons, possible_pixel_values, L):\n",
        "    super(Decoder,self).__init__()\n",
        "\n",
        "    self.L = L\n",
        "\n",
        "    self.input_shape_image = input_shape_image\n",
        "\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "\n",
        "    self.possible_pixel_values = possible_pixel_values\n",
        "\n",
        "    self.decoder = nn.Sequential(nn.Linear(latent_space_dimension,number_of_hidden_neurons),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 nn.Linear(number_of_hidden_neurons,number_of_hidden_neurons*2),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 nn.Linear(number_of_hidden_neurons*2, input_shape_image*possible_pixel_values),\n",
        "                                 )\n",
        "    \n",
        "  \n",
        "  def sample(self):\n",
        "    #creo la prior p(z)=N(z|0,I), è sempre la stessa\n",
        "    p_z = MultivariateNormal(torch.zeros(self.latent_space_dimension), torch.eye(self.latent_space_dimension))\n",
        "    z_sample = p_z.sample()\n",
        "\n",
        "\n",
        "    #inietto nel decoder:\n",
        "    z_sample = z_sample.unsqueeze(0)\n",
        "\n",
        "    #(1,1,784*256)\n",
        "    logits = self.decoder(z_sample)\n",
        "\n",
        "    #(1,784,256)\n",
        "    logits = logits.reshape(1, self.input_shape_image, self.possible_pixel_values )\n",
        "\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    #non applico la softmax per convertirli in probabilità perchè\n",
        "    #la multinomial di torch accetta anche le logits\n",
        "    probabilities = probabilities.view(-1, self.possible_pixel_values)\n",
        "\n",
        "    sample = torch.multinomial(probabilities, num_samples=1)\n",
        "\n",
        "    x = sample.view(self.input_shape_image) \n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "  #alla rete inietto lo z campionato da q(z|x) ma anche l'x che deve ricostruire\n",
        "  def forward(self, z, x):\n",
        "    \n",
        "    x = torch.flatten(x,1)\n",
        "    '''\n",
        "      il decoder da in output 784*256 probabilità per ciascuna z\n",
        "      Avendo (N, L, 64) con N numero di immagini, L=10 z campionati e 64 \n",
        "      ciascuna lunghezza, allora il decoder produrrà (N,L, 784*256), ossia\n",
        "      per ogni immagine le probabilità che ha x per ogni z campionato\n",
        "    '''\n",
        "    output_probabilities = self.decoder(z)\n",
        "\n",
        "    '''\n",
        "      Voglio calcolare la discrepanza tra l'x predetto dallo z^(i) e l'x vero.\n",
        "      Siccome ho L vettori z e per ciscuno le pseudo probabilità, allora \n",
        "    '''\n",
        "    batch_size = x.shape[0]\n",
        "\n",
        "    L = self.L\n",
        "\n",
        "    #qui salvo il reconstruction error finale\n",
        "    RE = 0\n",
        "    #per ogni batch di immagini calcolo la discrepanza tra loro e ciò che il \n",
        "    #vettore z^(i) ha prodotto\n",
        "    #print(x.shape)\n",
        "    for i in np.arange(L):\n",
        "\n",
        "      #prendo per ogni immagine, le pseudo probabilità che ha generato z^(i)\n",
        "      #quindi ho (N, 784*256)\n",
        "      output_probabilities_zi = output_probabilities[:,i,:]\n",
        "      #faccio il reshape in maniera tale da avere (N, 784, 256), quindi\n",
        "      #per ciascuno dei 784 pixel i 256 valori di pseudo probabilità\n",
        "      output_probabilities_zi = output_probabilities_zi.reshape(batch_size, self.input_shape_image, self.possible_pixel_values )\n",
        "      #applico la softmax per convertirli in probabilità\n",
        "      output_probabilities_zi = torch.softmax(output_probabilities_zi,2)\n",
        "\n",
        "      EPS = 1.e-5\n",
        "      #Per ogni immagine calcolo ln(p(x|z^i))=ln(p(x1|z^i))+..+ln(p(x784|z^i))\n",
        "      #trasformo ogni pixel di ogni immagine in one hot encoding\n",
        "      x_one_hot = F.one_hot(x.long(), num_classes = self.possible_pixel_values)\n",
        "      #calcolo il logaritmo delle probabilità e seleziono solo quelle che mi interessano\n",
        "      log_p = x_one_hot * torch.log(torch.clamp(output_probabilities_zi, EPS,1. - EPS))\n",
        "      #per ogni pixel di una immagine isolo solo la probabilità finale di accadere\n",
        "      vector_of_probabilities_per_image = torch.sum(log_p, dim=2) \n",
        "      #per ogni immagine sommo tutti i logaritmi di probabilità dei pixel\n",
        "      RE_per_image = vector_of_probabilities_per_image.sum(dim=1)\n",
        "      \n",
        "      #ogni RE_per_image ha dimensione (N), ossia contiene per un certo x degli N\n",
        "      # la ln(p(x|z^i)). La sommo a quella ottenuta con i precedenti z^i\n",
        "      RE = RE + RE_per_image\n",
        "      \n",
        "      \n",
        "      '''\n",
        "      print(output_probabilities_zi.shape)\n",
        "      print(output_probabilities_zi.sum(2).shape)\n",
        "      print(log_p.shape)\n",
        "      print(RE_per_image.shape)\n",
        "      print(RE_per_image)\n",
        "      '''\n",
        "    \n",
        "    '''\n",
        "      Per ogni immagine x io volevo come reconstruction error (RE) una approssimazione\n",
        "      dell'expected value E[p(x|z^i)], ossia 1/L*Sum(ln(p(x|z^i))). Il vettore mle contiene\n",
        "      nella posizione i-esima proprio tale Sum relativa all'immagine i-esima. Dividiamo\n",
        "      quindi il vettore per L cosi da ottenerne la media\n",
        "    '''\n",
        "    RE = RE / L\n",
        "\n",
        "    #Ho un RE per ogni immagine. Non ne calcolo la media perchè devo considerare il KL\n",
        "\n",
        "    return RE\n",
        "\n",
        "\n",
        "    \n",
        "    #converto il batch x nel formato (N,1,28,28) cosi da applicare un codice che \n",
        "    #conosco già per un rapido calcolo della sparse cross entropy\n",
        "  \n"
      ],
      "metadata": {
        "id": "_GF1-JrRzZ9t"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VAE"
      ],
      "metadata": {
        "id": "OBFIha8nSBwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self, possible_pixel_values, input_shape_image, latent_space_dimension, number_of_hidden_neurons,L ):\n",
        "    super(VAE, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(input_shape_image,latent_space_dimension,number_of_hidden_neurons,L)\n",
        "    self.decoder = Decoder(input_shape_image,latent_space_dimension,number_of_hidden_neurons,possible_pixel_values,L)\n",
        "\n",
        "  def sample(self):\n",
        "    return self.decoder.sample()\n",
        "\n",
        "  def forward(self, x):\n",
        "    #inietto x nell'encoder per ottenere la KL loss e i vettori z campionati (Monte-Carlo)\n",
        "    KL_loss, z_samples_per_image = self.encoder.forward(x)\n",
        "\n",
        "    #inietto nel decoder x per essere ricostruito attraverso gli stessi campioni z\n",
        "    #e per ottenere il reconstruction error\n",
        "    RE_loss = self.decoder.forward(z_samples_per_image,x)\n",
        "\n",
        "    #sommo per ottenere una approssimazione del ln(p(x))\n",
        "    ln_p = KL_loss - RE_loss\n",
        "\n",
        "    #calcolo la media del batch\n",
        "    ln_p_mean = ln_p.mean()\n",
        "\n",
        "    return ln_p_mean"
      ],
      "metadata": {
        "id": "-rQHftd-SC0D"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model (adattato per gpu)"
      ],
      "metadata": {
        "id": "7iZsvZOfgOgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "hyperparameters"
      ],
      "metadata": {
        "id": "ddzRWuW7gSUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#definisco la dimensione dello spazio latente\n",
        "latent_space_dimension = 45\n",
        "#nuumero di hidden neurons nell'encoder e decoder\n",
        "number_of_hidden_neurons = 128"
      ],
      "metadata": {
        "id": "AlmydjlygSUI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "AHj2x6M4gSUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_shape_image, latent_space_dimension, number_of_hidden_neurons, L,type_of_encoder = 2):\n",
        "    super(Encoder,self).__init__()\n",
        "\n",
        "    #numero di campioni per l'approssimazione Monte-Carlo dell'Expected Value\n",
        "    self.L = L\n",
        "\n",
        "    self.type_of_encoder = type_of_encoder\n",
        "\n",
        "    self.input_shape_image = input_shape_image\n",
        "\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "\n",
        "    self.encoder = nn.Sequential(nn.Linear(input_shape_image,number_of_hidden_neurons*2),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 nn.Linear(number_of_hidden_neurons*2,number_of_hidden_neurons),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 #moltiplico per 2 perchè voglio sia il vettore di media che std (diagonale)\n",
        "                                 nn.Linear(number_of_hidden_neurons,2*latent_space_dimension))\n",
        "    \n",
        "    self.encoder2 = nn.Sequential()\n",
        "    '''nn.Sequential(nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
        "                                  nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
        "                                  nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
        "                                  nn.Conv2d(16, 1, kernel_size=3, stride=1, padding=1),\n",
        "                                  nn.Flatten(),\n",
        "                                  nn.Linear(input_shape_image*1,2*latent_space_dimension),\n",
        "                                  nn.LeakyReLU())'''\n",
        "\n",
        "  def KL_loss(self,log_std_vector,mean_vector, batch_length):\n",
        "\n",
        "    L = self.L \n",
        "\n",
        "    #print(\"Mean-vector\", str(mean_vector), \"  shape:\",mean_vector.shape)\n",
        "    #print(\"log-Std-vector\", str(log_std_vector), \"  shape:\",log_std_vector.shape)\n",
        "\n",
        "    #trasformo i logaritmi delle std in std\n",
        "    std_vector = torch.exp(log_std_vector)\n",
        "\n",
        "    #print(\"Std vectors: \",std_vector.device)\n",
        "\n",
        "    #siccome devo avere una matrice positiva definita (cholesky decomposition) devo\n",
        "    #assicurarmi che i valori nelle diagonali non siano proprio zero\n",
        "    EPS = 1.e-5\n",
        "    std_vector = torch.clamp(std_vector, EPS,1. - EPS)\n",
        "\n",
        "    #trasformo le sequenze di varianze in matrici diagonali (covarianza)\n",
        "    covariance_matrixes = torch.diag_embed(std_vector)\n",
        "\n",
        "    #print(\"Matrici di covarianza\",covariance_matrixes.device, \"  di shape \", covariance_matrixes.shape )\n",
        "\n",
        "    #calcolo N distribuzioni  multivariate q(z|x) creata da ognuno degli N x\n",
        "    q_z_x = MultivariateNormal(mean_vector, covariance_matrixes)\n",
        "\n",
        "    '''\n",
        "      per ciascuna distribuzione campiono L vettori z\n",
        "      Nota però che anche se campiono L vettori da ciascuna, il risultato\n",
        "      conterrà i primi N vettori z campionati, poi i secondi N e cosi via fino\n",
        "      agli L-esimi. Per esempio i primi due z1 e z2 sono stati campionati da due\n",
        "      distribuzioni diverse! Quindi non ho blocchi da L vettori z appartenenti \n",
        "      alla stessa distribuzione!\n",
        "    '''\n",
        "    #dimensione (L, num_distribuzioni, dim_latente)\n",
        "    z_samples = q_z_x.rsample((L,)) #r sta per \"reparametrization trick\"\n",
        "    #print(\"samples: \", z_samples.device)\n",
        "    #print(\"Shape samples: \", z_samples.shape)\n",
        "\n",
        "    '''\n",
        "      calcolo per ciascuno e sulla rispettiva distribuzione il log della prob\n",
        "      Ho una matrice (L, N), dove ogni \"colonna\" contiene le probabilità degli\n",
        "      z campionati dalla \"stessa\" distribuzione. \n",
        "    '''\n",
        "    z_log_probs = q_z_x.log_prob(z_samples)\n",
        "    #print(\"log q(z|x)\",z_log_probs.device)\n",
        "    #print(\"Shape q(z|x): \", z_log_probs.shape)\n",
        "\n",
        "    '''\n",
        "      Per ogni sample z calcolo la p(z). Otterrò una matrice (L, N), dove ogni \n",
        "      \"colonna\" contiene le probabilità degli z campionati dalla \"stessa\" distribuzione q(z|x)\n",
        "    '''\n",
        "    #creo la prior p(z)=N(z|0,I), è sempre la stessa\n",
        "    p_z = MultivariateNormal(torch.zeros(self.latent_space_dimension).to(device), torch.eye(self.latent_space_dimension).to(device))\n",
        "\n",
        "    ln_p_z = p_z.log_prob(z_samples)\n",
        "\n",
        "    #print(\"ln_p(z)=\",ln_p_z.device)\n",
        "    #print(\"Shape di ln(p(z)) \",ln_p_z.shape)\n",
        "\n",
        "    '''\n",
        "      Ora per ogni immagine x io ho campionato L vettori z e per ciascuno ho\n",
        "      valutato sia ln(q(z|x)) che ln(p(z)). Per ogni immagine io volevo calcolare\n",
        "      l'expected value approssimandolo (Monte Carlo) come:\n",
        "\n",
        "                        KL = [Sum(ln(q(z|x)))/L - Sum(ln(p(z))/L)\n",
        "\n",
        "      Per ottenere la prima sommatoria, sommo le colonne di z_log_probs, mentre\n",
        "      per la seconda sommo le colonne della matrice ln_p_z. Dopodichè, ottenuti\n",
        "      due vettori, li divido per L e li sottraggo tra cosi da ottenere l'approssimazione\n",
        "      della KL per ogni immagine x in ingresso\n",
        "    '''\n",
        "\n",
        "    KL_per_image = z_log_probs.sum(0)/L - ln_p_z.sum(0)/L\n",
        "    #print(\"KL_per_image\",KL_per_image.device)\n",
        "    \n",
        "    return KL_per_image,z_samples\n",
        "  \n",
        "\n",
        "    #La rete ritorna il vettore di media, std (diagonale) e la z campionata\n",
        "  def forward(self, x):\n",
        "    if (self.type_of_encoder == 1 or self.type_of_encoder == 2):\n",
        "      #flatto il batch (64, 28, 28) in (64, 784)\n",
        "      x = torch.flatten(x,1)#.to(device)\n",
        "      #do alla rete x e prelevo vettore di media e std (diagonale)\n",
        "      output = self.encoder(x)#.to(device)\n",
        "    else:\n",
        "      x = x.unsqueeze(1)\n",
        "      #do alla rete x e prelevo vettore di media e std (diagonale)\n",
        "      output = self.encoder2(x)#.to(device)\n",
        "\n",
        "\n",
        "    #print(output.device)\n",
        "    #print(output.shape)\n",
        "    #divido il risultato in due parti: media e std (diagonale)(logaritmica)\n",
        "    mean_vector, log_std_vector = torch.chunk(output, 2, dim=1)\n",
        "    #print(mean_vector.device)\n",
        "    #print(log_std_vector.device)\n",
        "\n",
        "\n",
        "    '''\n",
        "      Ottengo un KL_error (N,) contenente per ogni immagine il relativo KL_error,\n",
        "      e poi una matrice z_samples (L, N, dim_latente)\n",
        "    '''\n",
        "    KL_per_image, z_samples = self.KL_loss(log_std_vector,mean_vector, x.shape[0])\n",
        "    #print(\"KL_per_image: \",KL_per_image)\n",
        "    #print(\"Z-samples:\", z_samples)\n",
        "\n",
        "    return KL_per_image,z_samples\n",
        "\n"
      ],
      "metadata": {
        "id": "RW_qKC6tgSUJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder"
      ],
      "metadata": {
        "id": "8XD2UZLYgSUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_shape_image,latent_space_dimension, number_of_hidden_neurons, possible_pixel_values, L, type_of_decoder = 2):\n",
        "    super(Decoder,self).__init__()\n",
        "\n",
        "    self.L = L\n",
        "\n",
        "    self.type_of_decoder = type_of_decoder\n",
        "\n",
        "    self.input_shape_image = input_shape_image\n",
        "\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "\n",
        "    self.possible_pixel_values = possible_pixel_values\n",
        "\n",
        "    self.decoder = nn.Sequential(nn.Linear(latent_space_dimension,number_of_hidden_neurons),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 nn.Linear(number_of_hidden_neurons,number_of_hidden_neurons*2),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 nn.Linear(number_of_hidden_neurons*2,number_of_hidden_neurons*3),\n",
        "                                 nn.LeakyReLU(),\n",
        "                                 nn.Linear(number_of_hidden_neurons*3, input_shape_image*possible_pixel_values),\n",
        "                                 )\n",
        "    \n",
        "    self.decoder2 = nn.Sequential()\n",
        "    '''\n",
        "                                nn.Linear(latent_space_dimension, input_shape_image * 16),\n",
        "                                nn.Unflatten(2, (input_shape_image, 16)),\n",
        "                                nn.ConvTranspose2d(input_shape_image, 16, kernel_size=3, stride=1, padding=1),\n",
        "                                nn.ConvTranspose2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "                                nn.ConvTranspose2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                                nn.ConvTranspose2d(64, 1, kernel_size=3, stride=1, padding=1),\n",
        "                                nn.Flatten(),\n",
        "                                nn.Linear(input_shape_image*16, input_shape_image*possible_pixel_values)\n",
        "                            )'''\n",
        "\n",
        "  \n",
        "  def sample(self):\n",
        "    #creo la prior p(z)=N(z|0,I), è sempre la stessa\n",
        "    p_z = MultivariateNormal(torch.zeros(self.latent_space_dimension), torch.eye(self.latent_space_dimension))\n",
        "    z_sample = p_z.sample().to(device)\n",
        "    #print(\"z_sample \",z_sample.device)\n",
        "\n",
        "\n",
        "    #inietto nel decoder:\n",
        "    z_sample = z_sample.unsqueeze(0)\n",
        "\n",
        "    if self.type_of_decoder == 1:\n",
        "          #(1,1,784*256)\n",
        "      logits = self.decoder(z_sample)\n",
        "    else:\n",
        "      logits = self.decoder(z_sample)\n",
        "\n",
        "\n",
        "    #(1,784,256)\n",
        "    logits = logits.reshape(1, self.input_shape_image, self.possible_pixel_values )\n",
        "\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    #non applico la softmax per convertirli in probabilità perchè\n",
        "    #la multinomial di torch accetta anche le logits\n",
        "    probabilities = probabilities.view(-1, self.possible_pixel_values)\n",
        "\n",
        "    sample = torch.multinomial(probabilities, num_samples=1)\n",
        "\n",
        "    x = sample.view(self.input_shape_image) \n",
        "    return x\n",
        "\n",
        "\n",
        "  def forward(self, z, x):\n",
        "    #z è una matrice (L, N, dim_latente), la inietto nel decoder per ottenere\n",
        "    #le logits \n",
        "    #print(\"Decoder forward\")\n",
        "    \n",
        "    #Le logits hanno forma (L,N, numero_pixel*possibili_valori)\n",
        "    #print(\"Z dimension: \", z.shape)\n",
        "    if self.type_of_decoder == 1:\n",
        "      logits = self.decoder(z).to(device)\n",
        "    else:\n",
        "      logits = self.decoder(z).to(device)\n",
        "    #print(\"Logits\",logits.device)\n",
        "\n",
        "    '''\n",
        "      Prima di convertire le logits in probabilità, ciascun vettore del tensore\n",
        "      contiene i logits di TUTTI i pixel [px1-v=v1,...,px1-v=vk, px2-v=1,....], quindi\n",
        "      devo prima fare un reshape del genere [[px1-v=v1,...,px1-v=vk], [...]] isolando\n",
        "      solo le probabilità di ogni pixel\n",
        "    \n",
        "    '''\n",
        "    #(L, N, numero_pixel, possibili_valori)\n",
        "    logits = logits.reshape((logits.shape[0],logits.shape[1],self.input_shape_image,self.possible_pixel_values))\n",
        "    #applico la softmax per convertire le logits in probabilità\n",
        "    probabilities = torch.softmax(logits,3)\n",
        "    #print(\"probabilities\",probabilities.device)\n",
        "\n",
        "    #correggo (per questioni di stabilità) le probabilità troppo basse \n",
        "    #Devono stare tra 0+EPS < p < 1-EPS\n",
        "    EPS = 1.e-5\n",
        "    probabilities = torch.clamp(probabilities, EPS,1. - EPS)\n",
        "    #print(\"probabilities \",probabilities.device)\n",
        "    '''\n",
        "      Per ogni z iniettato ho ottenuto delle probabilità. Siccome voglio valutare\n",
        "      l'expected value seguente:\n",
        "                              E[ln(p(x|z))]\n",
        "      e sicome lo voglio approssimare con gli L ln(p(x|z)) ottenuti, ossia:\n",
        "                              E[ln(p(x|z))] = 1/L*Sum(ln(p(x|z)))\n",
        "      allora tutti i calcoli seguenti servono solo a poter ottenere per ciascuna\n",
        "      immagine x tutti i ln(p(x|z)), in particolare:\n",
        "      1) Per ogni z ho una matrice di dimensione(numero_pixel, probabilità_valori) \n",
        "         e quindi estraggo la probabilità che ha quella particolare componente xi\n",
        "         in ingresso.\n",
        "      2) Alla fine per ogni coppia x e z ho un vettore di probabilità per xi, quindi\n",
        "         quella di x è calcolabile come:\n",
        "                              p(x|z)=p(x1|z)*p(x2|z)*...*p(xk|z)\n",
        "         Se però calcolo il logaritmo, che è quello che voglio posso sommarli:\n",
        "                              ln(p(x|z))=ln(p(x1|z))+ln(p(x2|z))+...+ln(p(xk|z))\n",
        "      3) Avendone L li sommo e li divido per L\n",
        "\n",
        "    '''\n",
        "    #converto ogni pixel in un vettore one_hot\n",
        "    x_one_hot = F.one_hot(x.long(), num_classes = self.possible_pixel_values)\n",
        "    #print(\"ONE-HOT\", x_one_hot.device)\n",
        "    x_one_hot = x_one_hot.reshape(x_one_hot.shape[0],x_one_hot.shape[1]*x_one_hot.shape[2]*x_one_hot.shape[3])\n",
        "    #print(\"ONE-HOT reshaped \",x_one_hot.device)\n",
        "    probabilities = probabilities.reshape(probabilities.shape[0],probabilities.shape[1],probabilities.shape[2]*probabilities.shape[3])\n",
        "    #li converto in logaritmi\n",
        "    log_probabilities = torch.log(probabilities)\n",
        "    #print(\"Probabilities \", probabilities.device)\n",
        "    selected_log_probabilities = x_one_hot * log_probabilities\n",
        "    #adesso in un unico vettore ho tutti le ln(p(x_i|z)) per lo z. \n",
        "    #print(\"Log Selected probabilities \", selected_log_probabilities.device)\n",
        "    #li sommo (L,N), ossia ogni vettore contiene gli ln(p(x|z)) per gli N x\n",
        "    ln_p_x_z = selected_log_probabilities.sum(2)\n",
        "    #print(\"ln(p(x|z) \", ln_p_x_z.device)\n",
        "    #ogni colonna contiene quindi gli ln(p(x|z)) per lo stesso x.\n",
        "    #li sommo e li divido per L ottenenedo il reconstruction error per ogni x\n",
        "    RE_per_image = ln_p_x_z.sum(0) / self.L\n",
        "    #print(\"RE_per_image\",RE_per_image.device)\n",
        "\n",
        "    return RE_per_image\n",
        "  \n"
      ],
      "metadata": {
        "id": "hRYe21JJgSUJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VAE"
      ],
      "metadata": {
        "id": "M_VcPGCMgSUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self, possible_pixel_values, input_shape_image, latent_space_dimension, number_of_hidden_neurons,L, type_of ):\n",
        "    super(VAE, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(input_shape_image,latent_space_dimension,number_of_hidden_neurons,L,type_of)\n",
        "    self.decoder = Decoder(input_shape_image,latent_space_dimension,number_of_hidden_neurons,possible_pixel_values,L,type_of)\n",
        "\n",
        "  def sample(self):\n",
        "    return self.decoder.sample()\n",
        "\n",
        "  def forward(self, x):\n",
        "    #inietto x nell'encoder per ottenere la KL loss e i vettori z campionati (Monte-Carlo)\n",
        "    KL_loss_per_image, z_samples_per_image = self.encoder.forward(x)\n",
        "\n",
        "    #inietto nel decoder x per essere ricostruito attraverso gli stessi campioni z\n",
        "    #e per ottenere il reconstruction error\n",
        "    RE_loss_per_image = self.decoder.forward(z_samples_per_image,x)\n",
        "\n",
        "    #sommo per ottenere una approssimazione del ln(p(x)) per ogni immagine\n",
        "    ln_p = KL_loss_per_image - RE_loss_per_image\n",
        "\n",
        "    #calcolo la media del batch\n",
        "    ln_p_mean = ln_p.mean()\n",
        "\n",
        "    return ln_p_mean"
      ],
      "metadata": {
        "id": "2v7SZ8r8gSUK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "u_P94_AwVz8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L=3 #for Monte Carlo"
      ],
      "metadata": {
        "id": "SVL6n1H4gYJd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE( possible_pixel_values, input_shape_image, latent_space_dimension, number_of_hidden_neurons, L, type_of = 1).to(device)"
      ],
      "metadata": {
        "id": "sJc48paqV04o"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "#i parametri che l'optimizer deve ottimizzare sono tutti quelli del modello\n",
        "parameters_to_optimize = [p for p in model.parameters() if p.requires_grad == True]\n",
        "\n",
        "optimizer = torch.optim.Adamax(parameters_to_optimize, lr=learning_rate)"
      ],
      "metadata": {
        "id": "58k7uDJ-WLID"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def sample_and_save(model, name, input_shape):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  #voglio campionare 16 immagini e le voglio in una griglia 4x4\n",
        "  n=4\n",
        "  number_of_grid_cells = n*n\n",
        "  #quindi dico al modello di campionarmi 16 immagini\n",
        "  xs = np.zeros((number_of_grid_cells,input_shape))\n",
        "  for i in np.arange(number_of_grid_cells):\n",
        "    generated_sample = model.sample().cpu()\n",
        "    #lo stacco dal grafo di computazione\n",
        "    generated_sample = generated_sample.detach().numpy()\n",
        "    xs[i,:] = generated_sample\n",
        "\n",
        "  \n",
        "  fig, ax = plt.subplots(n, n)\n",
        "  for i, ax in enumerate(ax.flatten()):\n",
        "      plottable_image = np.reshape(xs[i], (int(math.sqrt(input_shape)), int(math.sqrt(input_shape))))\n",
        "      ax.imshow(plottable_image, cmap='gray')\n",
        "      ax.axis('off')\n",
        "\n",
        "  plt.savefig(path_to_output+'/epoca_' +str(name)+ '.pdf', bbox_inches='tight')\n",
        "  plt.close()\n"
      ],
      "metadata": {
        "id": "K0kD3JWPAdpi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "number_of_epochs = 1000\n",
        "\n",
        "#qui salvo il migliore modello, ossia quello che ha la loss sulla validazione migliore\n",
        "best_model = model\n",
        "best_validation_loss = 1000000\n",
        "\n",
        "patience = 0\n",
        "max_patience = 25\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "  model.train()\n",
        "  print(\"Epoca \"+str(epoch)+\" _____________________________________________________________________\")\n",
        "  i=1\n",
        "  for index_batch, batch in enumerate(training_loader):\n",
        "\n",
        "    if len(batch.shape)==2:\n",
        "      batch = batch.reshape(batch.shape[0],int(math.sqrt(batch.shape[1])),int(math.sqrt(batch.shape[1])))\n",
        "    batch = batch.to(device)\n",
        "    \n",
        "    batch = batch.to(torch.float32)\n",
        "\n",
        "    loss = model.forward(batch)\n",
        "\n",
        "    #calcolo le derivate parziali della loss rispetto ogni parametro\n",
        "    loss.backward()\n",
        "\n",
        "    #adesso ogni parametro ha in .grad il gradiente. Aggiorno il suo valore\n",
        "    optimizer.step()\n",
        "\n",
        "    #resetto il .grad di ogni parametro (altrimenti sommo quello attuale al successivo che calcoleremo nell'epoca dopo)\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    print(\"   Loss batch: \",str(i),\": \", loss)\n",
        "    i=i+1\n",
        "\n",
        "  #alla fine di ogni epoca, valuto come si comporta la loss col validation set\n",
        "  print(\"   ___________________________\")\n",
        "  model.eval()\n",
        "  validation_loss = 0\n",
        "  N = 0\n",
        "  \n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "\n",
        "  for index_batch, batch in enumerate(validation_loader):\n",
        "    if len(batch.shape)==2:\n",
        "      batch = batch.reshape(batch.shape[0],int(math.sqrt(batch.shape[1])),int(math.sqrt(batch.shape[1])))\n",
        "    batch = batch.to(device)\n",
        "    batch = batch.to(torch.float32)\n",
        "    loss_i = model.forward(batch)\n",
        "    validation_loss = validation_loss + loss_i.item()#.to(\"cpu\")\n",
        "    N = N +  1#batch.shape[0]\n",
        "    print(\"   Loss validation batch \",str(N),\": \",loss_i)\n",
        "\n",
        "  validation_loss = validation_loss/N\n",
        "  print(\"   Loss media validation: \",str(validation_loss))\n",
        "\n",
        "  #se tale modello ha una loss migliore di quella attualmente migliore..\n",
        "  if validation_loss < best_validation_loss:\n",
        "    patience = 0\n",
        "    best_validation_loss = validation_loss\n",
        "    print(\"   la loss risulta essere migliore\")\n",
        "    torch.save(model.state_dict(), path_to_model+\"/model.pth\")\n",
        "    #campiono e salvo\n",
        "    sample_and_save(model, epoch, input_shape_image)\n",
        "  else:\n",
        "    print(\"   patience= \"+ str(patience+1))\n",
        "    patience = patience + 1\n",
        "  \n",
        "  if patience > max_patience:\n",
        "    print(\"\")\n",
        "    print(\"Patience massimo superato. Fine del training\")\n",
        "    break\n"
      ],
      "metadata": {
        "id": "wHHcmhvqWftP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}

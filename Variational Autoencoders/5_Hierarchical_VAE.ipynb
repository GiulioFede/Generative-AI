{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Vl2iyPidU0Xd",
        "VwoaF43RVQp8"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yUS14gOoVqUX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.datasets import load_digits\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "import math\n",
        "from torchvision import transforms\n",
        "from torch.linalg import multi_dot\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init\n",
        "\n"
      ],
      "metadata": {
        "id": "Vl2iyPidU0Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Controlla la disponibilità della GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Imposta il dispositivo sulla GPU\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Se la GPU non è disponibile, utilizza la CPU\n",
        "\n"
      ],
      "metadata": {
        "id": "of0uWRh0VBOO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUmfBgZZaHJR",
        "outputId": "25ed8414-60c7-4677-c8cb-a6090cb58e90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ink originale: https://drive.google.com/file/d/0B7EVK8r0v71pZjFTYXZWM3FlRnM/view?usp=drive_link&resourcekey=0-dYn9z10tMJOBAkviAcfdyQ\n",
        "#spostatelo nel vostro drive e copiatelo in locale (perchè il dataloader carica più velocemente le immagini leggendo da qui che dal vostro drive)\n",
        "!cp '/content/drive/MyDrive/Generative_AI/datasets/celebA/img_align_celeba.zip' celebA.zip"
      ],
      "metadata": {
        "id": "6h5nQ953YpPL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"celebA.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')"
      ],
      "metadata": {
        "id": "jqEVBayxZTVg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "kx_irQR-WxZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gaussian Error Linear Unit (gelus)\n",
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,x):\n",
        "    return x*torch.sigmoid(1.702*x)"
      ],
      "metadata": {
        "id": "6aIqKsbwYVUY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HierarchicalVAE(nn.Module):\n",
        "  def __init__(self, input_shape_image, latent_space_dimension, hidden_neurons,possible_pixel_values):\n",
        "    super(HierarchicalVAE, self).__init__()\n",
        "\n",
        "    self.input_shape_image = input_shape_image #es. (8,8) immagine -> 64\n",
        "    self.latent_space_dimension = latent_space_dimension\n",
        "    self.hidden_neurons = hidden_neurons\n",
        "    self.possible_pixel_values = possible_pixel_values\n",
        "\n",
        "\n",
        "    self.r1_net = nn.Sequential(\n",
        "                                nn.Linear(input_shape_image, 2*hidden_neurons),\n",
        "                                GELU(),\n",
        "                                nn.BatchNorm1d(2*hidden_neurons),\n",
        "                                nn.Linear(2*hidden_neurons, hidden_neurons),\n",
        "                                GELU())\n",
        "\n",
        "    self.r2_net = nn.Sequential(\n",
        "                                nn.Linear(hidden_neurons, 2*hidden_neurons),\n",
        "                                GELU(),\n",
        "                                nn.BatchNorm1d(2*hidden_neurons),\n",
        "                                nn.Linear(2*hidden_neurons, hidden_neurons),\n",
        "                                nn.LeakyReLU())\n",
        "\n",
        "    #rete che genera i delta di media e varianza per la variabile z2\n",
        "    #avendo solo due variabili latenti, non avremo una delta per z2, ma direttamente la rete\n",
        "    #che genera la sua media e varianza\n",
        "    self.net_z2 = nn.Sequential(\n",
        "                            nn.Linear(hidden_neurons, 2*hidden_neurons),\n",
        "                            GELU(),\n",
        "                            nn.BatchNorm1d(2*hidden_neurons),\n",
        "                            #produco media e log std per z2\n",
        "                            nn.Linear(2*hidden_neurons, 2*latent_space_dimension),\n",
        "                            nn.Hardtanh(-7,2)\n",
        "                            )\n",
        "\n",
        "    ##rete che genera media e varianza per la variabile z1\n",
        "    self.net_z1 = nn.Sequential(\n",
        "                            nn.Linear(latent_space_dimension, 2*hidden_neurons),\n",
        "                            GELU(),\n",
        "                            nn.BatchNorm1d(2*hidden_neurons),\n",
        "                            #produco media e log std per z1\n",
        "                            nn.Linear(2*hidden_neurons, 4*latent_space_dimension),\n",
        "                            nn.Hardtanh(-7,2)\n",
        "                            )\n",
        "\n",
        "    #rete che genera i delta di media e varianza per la variabile z1\n",
        "    self.net_delta_z1 = nn.Sequential(\n",
        "                                nn.Linear(hidden_neurons, 2*hidden_neurons),\n",
        "                                GELU(),\n",
        "                                nn.BatchNorm1d(2*hidden_neurons),\n",
        "                                #produco delta per media e log std di z1\n",
        "                                nn.Linear(2*hidden_neurons, 4*latent_space_dimension),\n",
        "                                )\n",
        "\n",
        "    self.net_reconstruction = nn.Sequential(\n",
        "                                nn.Linear(2*latent_space_dimension, hidden_neurons),\n",
        "                                GELU(),\n",
        "                                nn.BatchNorm1d(hidden_neurons),\n",
        "                                nn.Linear(hidden_neurons,2*hidden_neurons),\n",
        "                                GELU(),\n",
        "                                nn.BatchNorm1d(2*hidden_neurons),\n",
        "                                #produco media e log std per z1\n",
        "                                nn.Linear(2*hidden_neurons, input_shape_image*possible_pixel_values)\n",
        "                                )\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "    #creo la prior p(z2)=N(z|0,I), è sempre la stessa\n",
        "    p_z2 = MultivariateNormal(torch.zeros(self.latent_space_dimension).to(device), torch.eye(self.latent_space_dimension).to(device))\n",
        "    z2_sample = p_z2.sample()\n",
        "    z2_sample = z2_sample.unsqueeze(0)\n",
        "\n",
        "    #inietto nella net_z1\n",
        "    #utilizzo z2 per ottenere i parametri della distribuzione di z1\n",
        "    mean_and_log_std_z1 = self.net_z1(z2_sample)\n",
        "    mean_z1, log_std_z1 = torch.chunk(mean_and_log_std_z1, 2, dim=1)\n",
        "\n",
        "\n",
        "    #creo la distribuzione da cui campionare z1 e campiono z1\n",
        "    z1_distribution = MultivariateNormal(mean_z1, torch.diag_embed( torch.clamp( torch.exp(log_std_z1),min=1e-8)))\n",
        "    z1_sample = z1_distribution.sample()\n",
        "\n",
        "    #inietto z1 nella rete di ricostruzione\n",
        "    output = self.net_reconstruction(z1_sample)\n",
        "\n",
        "    #reshape in (1,input_shape, possible_pixel_values)\n",
        "    logits = output.reshape(1,self.input_shape_image, self.possible_pixel_values)\n",
        "    probabilities = torch.softmax(logits, dim=-1)\n",
        "    probabilities = probabilities.view(-1, self.possible_pixel_values)\n",
        "\n",
        "\n",
        "    sample = torch.multinomial(probabilities, num_samples=1)\n",
        "\n",
        "    x = sample.view(self.input_shape_image)\n",
        "    return x\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    #reshape da (N, W, H) a (N,W*H)\n",
        "    x = torch.flatten(x,1,2)\n",
        "\n",
        "    #normalizzo il batch\n",
        "    x_norm = x/(self.possible_pixel_values-1)\n",
        "\n",
        "    #elaboro x per ottenere R1\n",
        "    r1 = self.r1_net(x_norm)\n",
        "\n",
        "    #elaboro r1 per ottenere R2\n",
        "    r2 = self.r2_net(r1)\n",
        "\n",
        "    #elaboro R1 per creare i delta medie e log std da aggiungere a z1\n",
        "    delta_z1 = self.net_delta_z1(r1)\n",
        "    #splitto in due delta, uno per media e uno per log std\n",
        "    delta_mean_z1, delta_log_std_z1 = torch.chunk(delta_z1, 2, dim=1)\n",
        "\n",
        "    #elaboro R2 per trovarmi i parametri della distribuzione di z2\n",
        "    mean_and_log_std_z2 = self.net_z2(r2)\n",
        "    #splitto in media e log std\n",
        "    mean_z2, log_std_z2 = torch.chunk(mean_and_log_std_z2, 2, dim=1)\n",
        "\n",
        "    #campiono dalla distribuzione di z2 per ottenere z2 (con reparametrization trick)\n",
        "    z2_distribution = MultivariateNormal(mean_z2, torch.diag_embed( torch.clamp( torch.exp(log_std_z2),min=1e-8)))\n",
        "    z2 = z2_distribution.rsample()\n",
        "\n",
        "    #utilizzo z2 per ottenere i parametri della distribuzione di z1\n",
        "    mean_and_log_std_z1 = self.net_z1(z2)\n",
        "    mean_z1, log_std_z1 = torch.chunk(mean_and_log_std_z1, 2, dim=1)\n",
        "\n",
        "    #campiono z1 (correggendo la media e la log std con i delta)\n",
        "    z1_distribution = MultivariateNormal(mean_z1 +  delta_mean_z1, torch.diag_embed( torch.clamp( torch.exp(log_std_z1*delta_log_std_z1),min=1e-8)))\n",
        "    z1 = z1_distribution.rsample()\n",
        "\n",
        "    #utilizzo la rete per ricostruire l'immagine (N, input_shape*possible_pixel_values)\n",
        "    output = self.net_reconstruction(z1)\n",
        "\n",
        "    #reshape in (N, input_shape, possible_pixel_values)\n",
        "    logits = output.reshape(output.shape[0],self.input_shape_image, self.possible_pixel_values)\n",
        "\n",
        "    #eseguo la softmax sull'ultimo livello\n",
        "    output_probabilities = torch.softmax(logits,dim=-1)\n",
        "    EPS = 1.e-5\n",
        "    output_probabilities = torch.clamp(output_probabilities, EPS,1. - EPS)\n",
        "    #li converto in logaritmi\n",
        "    log_probabilities = torch.log(output_probabilities)\n",
        "\n",
        "    #trasformo x in one hot encoding\n",
        "    x_one_hot = F.one_hot(x.long(),num_classes=self.possible_pixel_values)\n",
        "\n",
        "    #li utilizzo per azzerare la probabilità relativa al valore del pixel\n",
        "    selected_probabilities = x_one_hot*log_probabilities\n",
        "\n",
        "    #li sommo (N,), ossia ogni cella contiene la somma dei ln(p(x|z1)) per gli N x\n",
        "    #Questo sarebbe il Reconstruction Error\n",
        "    RE = selected_probabilities.sum(-1).sum(-1)\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "      Per calcolare il KL error so dalla teoria che:\n",
        "              KL = E[ln(q(z1|x)/(p(z1|z2))) + ln(q(z2|z1)/p(z2))]\n",
        "      Avendo cambiato le dipendenze per unire il cuore dell'encoder con quello\n",
        "      del decoder, allora:\n",
        "\n",
        "              KL = E[ln(q(z1|z2)/(p(z1|z2))) + ln(q(z2|x)/p(z2))] = KL1 + KL2\n",
        "\n",
        "      dove:\n",
        "      - q(z1|z2) sarebbe la z1_distribution\n",
        "      - q(z2|x)  sarebbe la z2_distribution\n",
        "      - p(z1|z2) sarebbe la N(u,var) dove u e var sono quelli che ha prodotto la net_z1\n",
        "      - p(z2) sarebbe la N(0,I)\n",
        "\n",
        "      (NB: non sto eseguendo alcun Monte-Carlo per approssimare l'expected value)\n",
        "      Inoltre essendo p e q gaussiane esiste una formula chiusa:\n",
        "                KLi = [delta_mean^2/var^2 + delta_var^2 - ln(delta_var^2) - 1]\n",
        "      NB: il \"quadrato\" per le varianze è da mettere se le distribuzioni sono state\n",
        "      create \"passando\" la varianza quadra (in quanto quando do alla Multivariate la covariance\n",
        "      matrix questa la intende con elementi nella diagonale al quadrato); noi abbiamo passato\n",
        "      solo le varianze (niente quadrato) e quindi saranno da intendere già al quadrato.\n",
        "    '''\n",
        "    #SE LE PRIOR NON SONO GAUSSIANE\n",
        "    # p_z2 = MultivariateNormal(torch.zeros(z2.shape[1]).to(device), torch.eye(z2.shape[1]).to(device))\n",
        "    # p_z1_z2 = MultivariateNormal(mean_z1, torch.diag_embed( torch.clamp( torch.exp(log_std_z1),min=1e-8)))\n",
        "\n",
        "    # KL_z1 = z1_distribution.log_prob(z1) - p_z1_z2.log_prob(z1)\n",
        "\n",
        "    # KL_z2 = z2_distribution.log_prob(z2) - p_z2.log_prob(z2)\n",
        "\n",
        "    #SE LE PRIOR SONO GAUSSIANE ESISTE UNA FORMULA CHIUSA\n",
        "    KL_z2 = 0.5 * (mean_z2**2 + torch.exp(log_std_z2) - log_std_z2 - 1).sum(-1)\n",
        "    KL_z1 = 0.5 * (mean_z1**2 / torch.exp(log_std_z1) + torch.exp(log_std_z1) -log_std_z1 - 1).sum(-1)\n",
        "\n",
        "    KL = KL_z1 + KL_z2\n",
        "\n",
        "    #ELBO (medio l'ELBO di ogni immagine)\n",
        "    ELBO = (KL-RE).mean()\n",
        "\n",
        "    return ELBO\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wzN0HV7hWwbR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "VwoaF43RVQp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################### GPU + Path ##########################################\n",
        "\n",
        "# Controlla la disponibilità della GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Imposta il dispositivo sulla GPU\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Se la GPU non è disponibile, utilizza la CPU\n",
        "\n",
        "print(\"Device utilizzato:\", device)\n",
        "print(\"Numero di GPU disponibili:\", torch.cuda.device_count())\n",
        "\n",
        "\n",
        "#path dove salvare il modello migliore e i vari output di ogni epoca valida\n",
        "path_to_model = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/model/model_Hierarchical_VAE.pth\"\n",
        "path_to_output = \"/content/drive/MyDrive/Generative_AI/datasets/celebA/output/Hierarchical_VAE_\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################### Dataloader ##########################################\n",
        "\n",
        "#per motivi di efficienza, scegliere il rescaling e il massimo valore che ogni pixel può assumere\n",
        "resize_to = 64\n",
        "max_pixel_value = 20\n",
        "\n",
        "input_shape_image = resize_to*resize_to\n",
        "possible_pixel_values = max_pixel_value+1\n",
        "\n",
        "\n",
        "def load_data():\n",
        "\n",
        "\n",
        "    # Definisci le trasformazioni da applicare alle immagini durante il caricamento\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize( (resize_to, resize_to) ), #rescaling di ogni immagine\n",
        "        transforms.Grayscale(),  # Trasforma l'immagine in bianco e nero\n",
        "        transforms.ToTensor(),# Converte l'immagine in un tensore\n",
        "        transforms.Lambda(lambda x: torch.round(x*(max_pixel_value))), #normalizzo i valori dei pixel e li forzo ad essere interi\n",
        "        #transforms.Lambda(lambda x: x.to(torch.float32))\n",
        "    ])\n",
        "\n",
        "    # Crea un oggetto ImageFolder per caricare le immagini dalla cartella specificata e applica le trasformazioni definite\n",
        "    dataset = datasets.ImageFolder('/content/dataset/', transform=transform)\n",
        "\n",
        "    # Calcola l'indice per dividere il dataset tra training set e validation set\n",
        "    split_ratio = 0.8  # Ratio di suddivisione (80% per il training set, 20% per il validation set)\n",
        "    dataset_size = len(dataset)\n",
        "    split_index = int(split_ratio * dataset_size)\n",
        "\n",
        "    # Crea due sottoinsiemi distinti per il training set e il validation set\n",
        "    train_dataset = Subset(dataset, range(0, split_index))\n",
        "    val_dataset = Subset(dataset, range(split_index, dataset_size))\n",
        "\n",
        "    # Crea i DataLoader per il training set e il validation set\n",
        "    batch_size = 32\n",
        "    training_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "    validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return training_loader, validation_loader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################### Training + validation #####################################\n",
        "\n",
        "def train_model_on_given_gpu():\n",
        "\n",
        "    #definisco la dimensione dello spazio latente\n",
        "    latent_space_dimension = 32 #deve essere pari se utilizzi il Flow-based\n",
        "    #nuumero di hidden neurons nell'encoder e decoder\n",
        "    hidden_neurons = 64\n",
        "\n",
        "\n",
        "    #---- creazione del modello\n",
        "\n",
        "    model = HierarchicalVAE(input_shape_image, latent_space_dimension, hidden_neurons,possible_pixel_values)\n",
        "    model.to(device)\n",
        "\n",
        "    print(\"Numero parametri modello: \",sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    #parametri per il learning\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    parameters_to_optimize = [p for p in model.parameters() if p.requires_grad == True]\n",
        "\n",
        "    optimizer = torch.optim.Adamax(parameters_to_optimize, lr=learning_rate)\n",
        "\n",
        "\n",
        "    #------ Funzione per salvare una griglia di campioni decodificati dallo spazio latente ogni volta che la validation è migliore\n",
        "    def sample_and_save(model, name, input_shape):\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      #voglio campionare 16 immagini e le voglio in una griglia 4x4\n",
        "      n=4\n",
        "      number_of_grid_cells = n*n\n",
        "      #quindi dico al modello di campionarmi 16 immagini\n",
        "      xs = np.zeros((number_of_grid_cells,input_shape))\n",
        "      for i in np.arange(number_of_grid_cells):\n",
        "        generated_sample = model.sample().cpu() # il .module serve per andare oltre il wrapping di DataParallel\n",
        "        #lo stacco dal grafo di computazione\n",
        "        generated_sample = generated_sample.detach().numpy()\n",
        "        xs[i,:] = generated_sample\n",
        "\n",
        "\n",
        "      fig, ax = plt.subplots(n, n)\n",
        "      for i, ax in enumerate(ax.flatten()):\n",
        "          plottable_image = np.reshape(xs[i], (int(math.sqrt(input_shape)), int(math.sqrt(input_shape))))\n",
        "          ax.imshow(plottable_image, cmap='gray')\n",
        "          ax.axis('off')\n",
        "\n",
        "      plt.savefig(path_to_output+'epoca_' +str(name)+ '.pdf', bbox_inches='tight')\n",
        "      plt.close()\n",
        "\n",
        "\n",
        "\n",
        "    #---- Training e validation\n",
        "    number_of_epochs = 1000\n",
        "    #fisso il limite massimo di batch di training e validazione\n",
        "    max_batch_for_training = 800\n",
        "    max_batch_for_validation = 170\n",
        "\n",
        "\n",
        "    #qui salvo il migliore modello, ossia quello che ha la loss sulla validazione migliore\n",
        "    best_model = model\n",
        "    best_validation_loss = 1000000\n",
        "\n",
        "    patience = 0\n",
        "    max_patience = 30\n",
        "\n",
        "    training_loader, validation_loader = load_data()\n",
        "\n",
        "    grd_acc = 1 #significa che prima di backpropagare l'errore accumulerò il gradiente di batch_size*grd_acc (ees. 8*4=32 è come se processassi batch da 32)\n",
        "\n",
        "    for epoch in range(number_of_epochs):\n",
        "      model.train()\n",
        "      print(\"Epoca \"+str(epoch)+\" _____________________________________________________________________\")\n",
        "\n",
        "      num_batch = 1\n",
        "      for batch, _ in training_loader:\n",
        "\n",
        "        #reshaping di ogni batch da (N, 1, W, H) a (N, W, H)\n",
        "        batch = batch.squeeze(1)\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        #print(\"             Memoria GPU utilizzata prima loss per batch:\",num_batch,\"  -> \", round(torch.cuda.memory_allocated()*(1e-9),5),\" GB\")\n",
        "        #batch = batch.to(torch.float32)\n",
        "\n",
        "        loss = model.forward(batch)\n",
        "        #print(\"             Memoria GPU utilizzata dopo loss per batch:\",num_batch,\"  -> \", round(torch.cuda.memory_allocated()*(1e-9),5),\" GB\")\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        #calcolo le derivate parziali della loss rispetto ogni parametro NB: LA mean() E' PERCHE' UTILIZZO N GPU E CIASCUNA RITORNA LA SUA LOSS\n",
        "        (loss.mean()/grd_acc).backward(retain_graph=True)\n",
        "        torch.cuda.empty_cache()\n",
        "        #print(\"             Memoria GPU utilizzata dopo backward per batch:\",num_batch,\"  -> \", round(torch.cuda.memory_allocated()*(1e-9),5),\" GB\")\n",
        "        #se ho accumulato il gradiente di un numero sufficiente di batch, allora backpropago\n",
        "        if ( (num_batch % grd_acc) == 0):\n",
        "            #adesso ogni parametro ha in .grad il gradiente. Aggiorno il suo valore\n",
        "            optimizer.step()\n",
        "\n",
        "            #resetto il .grad di ogni parametro (altrimenti sommo quello attuale al successivo che calcoleremo nell'epoca dopo)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(\"   Loss batch: \",str(num_batch),\": \", loss, \"          Memoria GPU utilizzata  -> \", round(torch.cuda.memory_allocated()*(1e-9),4), \"GB\")\n",
        "\n",
        "            #se ho superato il numero massimo di batch per il training, esco\n",
        "        if num_batch >= max_batch_for_training:\n",
        "            break\n",
        "        else:\n",
        "            num_batch = num_batch + 1\n",
        "\n",
        "      #alla fine di ogni epoca, valuto come si comporta la loss col validation set\n",
        "      print(\"   ___________________________\")\n",
        "      model.eval()\n",
        "      validation_loss = 0\n",
        "      N = 0\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      num_batch = 1\n",
        "      for batch, _ in validation_loader:\n",
        "\n",
        "        batch = batch.squeeze(1)\n",
        "        batch = batch.to(device)\n",
        "        #batch = batch.to(torch.float32)\n",
        "        loss_i = model.forward(batch)\n",
        "        validation_loss = validation_loss + loss_i.mean().item()# NB: .mean() SOLO PERCH' UTILIZZO N GPU E QUINDI VOGLIO LA MEDIA DI OGNI LOSS RITORNATA DA OGNI GPU\n",
        "        N = N +  1\n",
        "\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(\"   Loss validation batch \",str(num_batch),\": \",loss_i)\n",
        "        #se ho superato il numero massimo di batch per il validation, esco\n",
        "        if num_batch >= max_batch_for_validation:\n",
        "            break\n",
        "        else:\n",
        "            num_batch = num_batch + 1\n",
        "\n",
        "        del loss_i\n",
        "\n",
        "      validation_loss = validation_loss/N\n",
        "      print(\"   Loss media validation: \",str(validation_loss))\n",
        "\n",
        "      #se tale modello ha una loss migliore di quella attualmente migliore..\n",
        "      if validation_loss < best_validation_loss:\n",
        "        patience = 0\n",
        "        best_validation_loss = validation_loss\n",
        "        print(\"   la loss risulta essere migliore\")\n",
        "        torch.save(model.state_dict(), path_to_model)\n",
        "        #campiono e salvo\n",
        "        sample_and_save(model, epoch, input_shape_image)\n",
        "      else:\n",
        "        print(\"   patience= \"+ str(patience+1))\n",
        "        patience = patience + 1\n",
        "\n",
        "      if patience > max_patience:\n",
        "        print(\"\")\n",
        "        print(\"Patience massimo superato. Fine del training\")\n",
        "        break\n",
        "\n",
        "      del validation_loss\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "\n",
        "    train_model_on_given_gpu()"
      ],
      "metadata": {
        "id": "uBa71JKDVSPN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}